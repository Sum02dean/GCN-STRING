{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob \n",
    "from tqdm import tqdm\n",
    "from collections import Counter as C\n",
    "import Bio.PDB\n",
    "import Bio.PDB.StructureBuilder\n",
    "from Bio.PDB.Residue import Residue\n",
    "from multiprocessing import Pool\n",
    "from Bio.PDB import PDBParser\n",
    "import networkx as nx\n",
    "\n",
    "# Torch \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.utils import convert\n",
    "from torch_geometric.data import InMemoryDataset, download_url, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SloppyStructureBuilder(Bio.PDB.StructureBuilder.StructureBuilder):\n",
    "    \"\"\"Cope with resSeq < 10,000 limitation by just incrementing internally.\n",
    "    # Q: What's wrong here??\n",
    "    #   Some atoms or residues will be missing in the data structure.\n",
    "    #   WARNING: Residue (' ', 8954, ' ') redefined at line 74803.\n",
    "    #   PDBConstructionException: Blank altlocs in duplicate residue SOL\n",
    "    #   (' ', 8954, ' ') at line 74803.\n",
    "    #\n",
    "    # A: resSeq only goes to 9999 --> goes back to 0 (PDB format is not really\n",
    "    #    good here)\n",
    "    \"\"\"\n",
    "\n",
    "    # NOTE/TODO:\n",
    "    # - H and W records are probably not handled yet (don't have examples\n",
    "    #   to test)\n",
    "\n",
    "    def __init__(self, verbose=False):\n",
    "        Bio.PDB.StructureBuilder.StructureBuilder.__init__(self)\n",
    "        self.max_resseq = -1\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def init_residue(self, resname, field, resseq, icode):\n",
    "        \"\"\"Initiate a new Residue object.\n",
    "        Arguments:\n",
    "        o resname - string, e.g. \"ASN\"\n",
    "        o field - hetero flag, \"W\" for waters, \"H\" for\n",
    "            hetero residues, otherwise blanc.\n",
    "        o resseq - int, sequence identifier\n",
    "        o icode - string, insertion code\n",
    "        \"\"\"\n",
    "        if field != \" \":\n",
    "            if field == \"H\":\n",
    "                # The hetero field consists of\n",
    "                # H_ + the residue name (e.g. H_FUC)\n",
    "                field = \"H_\" + resname\n",
    "        res_id = (field, resseq, icode)\n",
    "\n",
    "        if resseq > self.max_resseq:\n",
    "            self.max_resseq = resseq\n",
    "\n",
    "        if field == \" \":\n",
    "            fudged_resseq = False\n",
    "            while self.chain.has_id(res_id) or resseq == 0:\n",
    "                # There already is a residue with the id (field, resseq, icode)\n",
    "                # resseq == 0 catches already wrapped residue numbers which\n",
    "                # do not trigger the has_id() test.\n",
    "                #\n",
    "                # Be sloppy and just increment...\n",
    "                # (This code will not leave gaps in resids... I think)\n",
    "                #\n",
    "                # XXX: shouldn't we also do this for hetero atoms and water??\n",
    "                self.max_resseq += 1\n",
    "                resseq = self.max_resseq\n",
    "                res_id = (field, resseq, icode)  # use max_resseq!\n",
    "                fudged_resseq = True\n",
    "\n",
    "            if fudged_resseq and self.verbose:\n",
    "                sys.stderr.write(\n",
    "                    \"Residues are wrapping (Residue \"\n",
    "                    + \"('%s', %i, '%s') at line %i).\"\n",
    "                    % (field, resseq, icode, self.line_counter)\n",
    "                    + \".... assigning new resid %d.\\n\" % self.max_resseq\n",
    "                )\n",
    "        residue = Residue(res_id, resname, self.segid)\n",
    "        self.chain.add(residue)\n",
    "        self.residue = residue\n",
    "\n",
    "class SloppyPDBIO(Bio.PDB.PDBIO):\n",
    "    \"\"\"PDBIO class that can deal with large pdb files as used in MD simulations\n",
    "    - resSeq simply wrap and are printed modulo 10,000.\n",
    "    - atom numbers wrap at 99,999 and are printed modulo 100,000\n",
    "    \"\"\"\n",
    "\n",
    "    # The format string is derived from the PDB format as used in PDBIO.py\n",
    "    # (has to be copied to the class because of the package layout it is not\n",
    "    # externally accessible)\n",
    "    _ATOM_FORMAT_STRING = (\n",
    "        \"%s%5i %-4s%c%3s %c%4i%c   \" + \"%8.3f%8.3f%8.3f%6.2f%6.2f      %4s%2s%2s\\n\"\n",
    "    )\n",
    "\n",
    "    def _get_atom_line(\n",
    "        self,\n",
    "        atom,\n",
    "        hetfield,\n",
    "        segid,\n",
    "        atom_number,\n",
    "        resname,\n",
    "        resseq,\n",
    "        icode,\n",
    "        chain_id,\n",
    "        element=\"  \",\n",
    "        charge=\"  \",\n",
    "    ):\n",
    "        \"\"\"Returns an ATOM string that is guaranteed to fit the ATOM format.\n",
    "        - Resid (resseq) is wrapped (modulo 10,000) to fit into %4i (4I) format\n",
    "        - Atom number (atom_number) is wrapped (modulo 100,000) to fit into\n",
    "          %5i (5I) format\n",
    "        \"\"\"\n",
    "        if hetfield != \" \":\n",
    "            record_type = \"HETATM\"\n",
    "        else:\n",
    "            record_type = \"ATOM  \"\n",
    "        name = atom.get_fullname()\n",
    "        altloc = atom.get_altloc()\n",
    "        x, y, z = atom.get_coord()\n",
    "        bfactor = atom.get_bfactor()\n",
    "        occupancy = atom.get_occupancy()\n",
    "        args = (\n",
    "            record_type,\n",
    "            atom_number % 100000,\n",
    "            name,\n",
    "            altloc,\n",
    "            resname,\n",
    "            chain_id,\n",
    "            resseq % 10000,\n",
    "            icode,\n",
    "            x,\n",
    "            y,\n",
    "            z,\n",
    "            occupancy,\n",
    "            bfactor,\n",
    "            segid,\n",
    "            element,\n",
    "            charge,\n",
    "        )\n",
    "        return self._ATOM_FORMAT_STRING % args\n",
    "        \n",
    "def generate_graphs(adjacency_matrix, show=False, self_loops=False):\n",
    "        \"\"\"Generates the initial graphs from provided adjacency matrices.\n",
    "        :param adjacency_matrix_1: proximity matrix for protein 1\n",
    "        :type adjacency_matrix_1: np.array\n",
    "        :param adjacency_matrix_2: proximity matrix for protein 2\n",
    "        :type adjacency_matrix_2: np.array\n",
    "        :param show: plot graphs, defaults to False\n",
    "        :type show: bool, optional\n",
    "        :return: returns networkX graphs corrresponding to each adjacency matrix\n",
    "        :rtype: tuple of networkX objects\n",
    "        \"\"\"\n",
    "        # Generate graphs\n",
    "        G = nx.from_numpy_matrix(adjacency_matrix)\n",
    "        \n",
    "        if self_loops == False:\n",
    "            # Remove self loops on residues\n",
    "            G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "\n",
    "        if show:\n",
    "            # Plot the graphs\n",
    "            plt.subplots(figsize=(12, 8))\n",
    "            pos = nx.spring_layout(G)\n",
    "            nx.draw(G, with_labels=False, edge_color=\"black\",\n",
    "                    node_size=10, width=0.2)\n",
    "            plt.show()\n",
    "\n",
    "        return G\n",
    "\n",
    "def get_structure(pdbfile, pdbid=\"system\"):\n",
    "\n",
    "    # convenience functions\n",
    "    sloppyparser = Bio.PDB.PDBParser(\n",
    "        PERMISSIVE=True, structure_builder=SloppyStructureBuilder()\n",
    "    )\n",
    "\n",
    "    return sloppyparser.get_structure(pdbid, pdbfile)\n",
    "\n",
    "def generate_alpha_fold_structures(string_to_af, pair_1):\n",
    "        \"\"\"Queries alpha-fold predictions for a given protein sequnece and returns\n",
    "         alpha-fold predicted structures.\n",
    "\n",
    "        :param string_to_af: mapping path between string-alphaFold\n",
    "        :type string_to_af: string\n",
    "        :param pair_1: protein name 1\n",
    "        :type pair_1: string\n",
    "        :param pair_2: protein name 2\n",
    "        :type pair_2: string\n",
    "        :return: alphaFold structures for each protein\n",
    "        :rtype: objects\n",
    "        \"\"\"\n",
    "\n",
    "        # Map from STRING to Alpha-Fold\n",
    "        ecoli_maps = pd.read_csv(\n",
    "            string_to_af, sep='\\t', engine='python', header=None)\n",
    "        map_1 = ecoli_maps[ecoli_maps[0] == pair_1]\n",
    "\n",
    "        # Save and import map files\n",
    "        test_file_1 = map_1.iloc[0, -1]\n",
    "        test_file_1 = test_file_1.replace('.gz', '')\n",
    "    \n",
    "\n",
    "        # Create sloppy parser\n",
    "        sloppy_parser = PDBParser(structure_builder=SloppyStructureBuilder())\n",
    "        protein_1 = sloppy_parser.get_structure(id=None, file=test_file_1)\n",
    "\n",
    "        # Structure 1\n",
    "        sloppyio_1 = SloppyPDBIO()\n",
    "        sloppyio_1.set_structure(protein_1)\n",
    "\n",
    "        # Get protein residue structures\n",
    "        residues_1 = [x for x in sloppyio_1.structure.get_residues()]\n",
    "        return residues_1\n",
    "\n",
    "def calculate_residue_dist(seq_1, seq_2):\n",
    "    \"\"\"Calculates the euclidean distance between two residues in 3D space.\n",
    "    :param residue_one: reference residue\n",
    "    :type residue_one:  object\n",
    "    :param residue_two: target residue\n",
    "    :type residue_two: object\n",
    "    :return: sqaured euclidean distance\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    diff_vector = seq_1[\"CA\"].coord - seq_2[\"CA\"].coord\n",
    "    sq_dist = np.sqrt(np.sum(diff_vector * diff_vector))\n",
    "    return sq_dist\n",
    "\n",
    "def calculate_dist_matrix(seq_1, seq_2):\n",
    "        \"\"\"Calculates the distance matrix for all pairwise residues\n",
    "        :param seq_1: protein sequence 1\n",
    "        :type seq_1: string\n",
    "        :param seq_2: protein sequence 2\n",
    "        :type seq_2: string\n",
    "        :return: an nd array which encodes pairwise residue distances\n",
    "        :rtype: np.array\n",
    "        \"\"\"\n",
    "        d_mat = np.zeros((len(seq_1), len(seq_2)), float)\n",
    "        for row, residue_one in enumerate(seq_1):\n",
    "            for col, residue_two in enumerate(seq_2):\n",
    "                euclidean_dist = calculate_residue_dist(\n",
    "                    residue_one, residue_two)\n",
    "                d_mat[row, col] = euclidean_dist\n",
    "        return d_mat\n",
    "\n",
    "def generate_proximity_matrix(seq_1, seq_2, angstroms=10, show=False):\n",
    "        \"\"\"Creates an adacency matrix for points within n angstroms of each other\n",
    "        :param seq_1: protein sequence 1\n",
    "        :type seq_1: string\n",
    "        :param seq_2: protein sequence 2\n",
    "        :type seq_2: sting\n",
    "        :param angstroms: max distance threshold , defaults to 10\n",
    "        :type angstroms: int, optional\n",
    "        :param show: to plot matrix, defaults to False\n",
    "        :type show: bool, optional\n",
    "        :return: a proximity matrix for points considered less than n angstroms apart\n",
    "        :rtype: np.array\n",
    "        \"\"\"\n",
    "\n",
    "        # Select the residues from maps that are less than 'n' angstoms apart\n",
    "        contact_map = calculate_dist_matrix(seq_1, seq_2)\n",
    "        adjacency_matrix = np.zeros(np.shape(contact_map))\n",
    "        adjacency_matrix[contact_map < angstroms] = 1\n",
    "\n",
    "        if show:\n",
    "            plt.subplots(figsize=(12, 12))\n",
    "            sns.heatmap(adjacency_matrix)\n",
    "            plt.show()\n",
    "        return adjacency_matrix\n",
    "        \n",
    "def populate_graph_features(graph, x_net_surf):\n",
    "        \"\"\" Populates each node (residue) with its respective net-surf feature vector\n",
    "        :param graph_1: graph for protein 1\n",
    "        :type graph_1: networkX graph object\n",
    "        \n",
    "        :param x_net_surf_1: net-surf feautures for protein 1\n",
    "        :type x_net_surf_1: pandas dataframe\n",
    "\n",
    "        :return: a graph populated with node features\n",
    "        :rtype: tuple of networkX graphs\n",
    "        \"\"\"\n",
    "\n",
    "        # Protein netsurfp\n",
    "        vars_to_keep = [x for x in x_net_surf.columns if x not in [\n",
    "            'id', 'seq', 'n', 'q3', 'q8']]        \n",
    "        features = x_net_surf.loc[:, vars_to_keep]\n",
    "\n",
    "        # Populate node features \n",
    "        G_features = {}\n",
    "        for i, node in enumerate(graph.nodes):\n",
    "            feature_array = {'x': features.iloc[i, :].values}\n",
    "            G_features[node] = feature_array\n",
    "\n",
    "        # Set the node attributes\n",
    "        nx.set_node_attributes(graph, G_features)\n",
    "        return graph\n",
    "\n",
    "def get_node_features(graph, node_number):\n",
    "    # Get a nodes features\n",
    "    return nx.get_node_attributes(G, 'x')[node_number]\n",
    "\n",
    "def read_fasta(path):\n",
    "    # Read in the file\n",
    "    with open(sequences[0]) as f:\n",
    "        lines = f.readlines()\n",
    "    # Format the string as list\n",
    "    for line in lines:\n",
    "        x = list(line.strip())\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotation file\n",
    "anndata_path = ('/mnt/mnemo6/tao/PPI_Coevolution/CoEvo_data_STRING11.5/'\n",
    "                '511145_EggNOGmaxLevel1224_eggNOGfilteredData/STRINPhyPPI_Benchmark/allPPI_allInfo_frame.csv')\n",
    "\n",
    "# Netsurf data\n",
    "netsurf_path = (\"/mnt/mnemo6/tao/PPI_Coevolution/STRING_data_11.5/511145_netsurfp2_output/\")\n",
    "\n",
    "# Specify sequence data\n",
    "sequence_path = (\"/mnt/mnemo6/tao/PPI_Coevolution/STRING_data_11.5/511145ByProteins/\")\n",
    "\n",
    "# ALPHA-Fold paths\n",
    "string_to_af = \"/mnt/mnemo6/damian/STRING_derived_v11.5/alphafold/mapping/83333.511145.tsv\"\n",
    "string_to_pdb = '/mnt/mnemo6/damian/STRING_derived_v11.5/pdb/pdb2string.blastp.best_score.tsv'\n",
    "pdb_files_for_PDB = '/mnt/mnemo6/damian/STRING_freeze_v11.5/pdb/data/biounit/coordinates/divided/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netsurf outputs\n",
    "netsurf = glob.glob(os.path.join(netsurf_path, \"*.csv\"))\n",
    "sequences = glob.glob(os.path.join(sequence_path, \"*.csv\"))\n",
    "\n",
    "# Sort the files\n",
    "netsurf.sort()\n",
    "sequences.sort()\n",
    "\n",
    "# Generate map between protein names and netsurfp file paths\n",
    "seq_names = [x.split(\"/\")[-1].replace(\".csv\", \"\") for x in netsurf]\n",
    "netsurf_d = dict(zip(seq_names, netsurf))\n",
    "\n",
    "# Load anndata object\n",
    "anndata = pd.read_csv(anndata_path, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/18492 [00:07<14:27:40,  2.82s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Itstantiate graph collections\n",
    "graphs_1 = []\n",
    "graphs_2 = []\n",
    "graph_labels = []\n",
    "\n",
    "# Generate all graphs\n",
    "rows, cols = np.shape(anndata)\n",
    "for i in tqdm(range(rows)):\n",
    "    # Grab protein names\n",
    "    protein_1, protein_2 = anndata.loc[i, ['STRING_ID1', 'STRING_ID2']]\n",
    "\n",
    "    # Pull out path for each protein\n",
    "    p1_path, p2_path = netsurf_d[protein_1], netsurf_d[protein_2]\n",
    "\n",
    "    # Get raw protein data\n",
    "    p1_x, p2_x = pd.read_csv(p1_path), pd.read_csv(p2_path)\n",
    "    seq_1, seq_2 = \"\".join(p1_x['seq'].values), \"\".join(p2_x['seq'].values)\n",
    "\n",
    "    # Get interaction label\n",
    "    interact_meta = anndata[(anndata['STRING_ID1'] == protein_1) & (anndata['STRING_ID2'] == protein_2)]\n",
    "    interact_stataus = interact_meta['benchmark_status'].values\n",
    "    interact_label = 1 if interact_stataus == 'P' else 0\n",
    "    graph_labels.append(interact_label)\n",
    "    \n",
    "\n",
    "    # Extract alpha-fold structure based on protein names\n",
    "    residues_1 = generate_alpha_fold_structures(string_to_af, protein_1)\n",
    "    residues_2 = generate_alpha_fold_structures(string_to_af, protein_2)\n",
    "\n",
    "    # Generate proximitty matrices\n",
    "    prox_1 = generate_proximity_matrix(\n",
    "        residues_1, residues_1, angstroms=10, show=False)\n",
    "    prox_2 = generate_proximity_matrix(\n",
    "        residues_2, residues_2, angstroms=10, show=False)\n",
    "\n",
    "    # Remove self-loops from graphs\n",
    "    G_1 = generate_graphs(prox_1, show=False, self_loops=False)\n",
    "    G_2 = generate_graphs(prox_2, show=False, self_loops=False)\n",
    "\n",
    "    # Populate each node with netsurfp features\n",
    "    G_1 = populate_graph_features(G_1, x_net_surf=p1_x)\n",
    "    G_2 = populate_graph_features(G_2, x_net_surf=p2_x)\n",
    "\n",
    "    # Append graphs\n",
    "    graphs_1.append(G_1)\n",
    "    graphs_2.append(G_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91480398e29c201d85f830141776dbac7675dbf1ea4e71a85e6e607707f70528"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
