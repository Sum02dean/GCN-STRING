{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "import os \n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.utils import convert\n",
    "from torch_geometric.data import InMemoryDataset, download_url, Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in label by name\n",
    "def get_label(file, labels):\n",
    "    pair_1 = file.split('/')[-1]\n",
    "    pair_1, pair_2 = pair_1.split(\"and\")\n",
    "    pair_1 = pair_1.replace(\".gpickle\", \"\")\n",
    "    pair_2 = pair_2.replace(\".gpickle\", \"\")\n",
    "    l = int(labels.loc[(labels.protein_1 == pair_1) & (labels.protein_2 == pair_2)].label)\n",
    "    return file, l\n",
    "\n",
    "def read_graphs(file_set):\n",
    "    g_list = []\n",
    "    for i, file in enumerate(file_set):\n",
    "        G = nx.read_gpickle(file)\n",
    "        g_list.append(G)\n",
    "    return g_list\n",
    "    \n",
    "def format_graphs(graphs, label=1):\n",
    "    graph_list = []\n",
    "    # Convert into pytorch geoetric dataset: Positive\n",
    "    for i, x in enumerate(tqdm(graphs)):\n",
    "        F = nx.convert_node_labels_to_integers(x)\n",
    "        for (n1, n2, d) in F.edges(data=True):\n",
    "            d.clear()\n",
    "        data = convert.from_networkx(F, group_edge_attrs=None)\n",
    "        data.y = torch.FloatTensor(np.array([label]))\n",
    "        graph_list.append(data)\n",
    "    return graph_list\n",
    "\n",
    "def binary_acc(y_pred, y_test):\n",
    "    probas = torch.sigmoid(y_pred)\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc, y_pred_tag, probas\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, datasetA, datasetB):\n",
    "        self.datasetA = datasetA\n",
    "        self.datasetB = datasetB\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        xA = self.datasetA[index]\n",
    "        xB = self.datasetB[index]\n",
    "        return xA, xB\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.datasetA)\n",
    "\n",
    "# Develop model structure\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels=64):\n",
    "        \"\"\"\n",
    "        This class takes in 2 inputs. Each input is a graph representing a single protein structure in a protein pair.\n",
    "        Each graph is processed by seperate nerual networks, the outputs of which are then concatenated into a single\n",
    "        hiddden state. Finally this hidden state is passed through a simple dense layer for feature extraction, and then \n",
    "        returned for use with a BCEWithLogitLoss (recommended for binary classificatio) method inside the main training loop.\n",
    "\n",
    "        :param hidden_channels: the number of hidden neurons to use, defaults to 64\n",
    "        :type hidden_channels: int, optional\n",
    "\n",
    "        \"\"\"\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # Parameters\n",
    "        self.num_node_features = 16\n",
    "        self.num_classes = 1\n",
    "        self.hidden_channels = hidden_channels\n",
    "\n",
    "        #### Graph 1 ####\n",
    "        # Layers (consider using class SAGEConv instead)\n",
    "        self.g1_conv_1 = GATConv(self.num_node_features, self.hidden_channels, heads=2)\n",
    "        self.g1_linear_1 = Linear(self.hidden_channels, self.hidden_channels)\n",
    "\n",
    "        # Paramteric RelU (prelu)\n",
    "        self.g1_act_1 = torch.nn.ELU()\n",
    "        self.g1_act_2 = torch.nn.ELU()\n",
    "\n",
    "        #### Graph 2 ####\n",
    "        self.g2_conv_1 = GATConv(self.num_node_features, self.hidden_channels, heads=2)\n",
    "        self.g2_linear_1 = Linear(self.hidden_channels, self.hidden_channels)\n",
    "        self.g2_act_1 = torch.nn.ELU()\n",
    "        self.g2_act_2 = torch.nn.ELU()\n",
    "\n",
    "        #### Concatenated graphs ####\n",
    "        self.cat_linear = Linear(self.hidden_channels * 2, self.num_classes)\n",
    "        self.cat_act = torch.nn.ELU()\n",
    "\n",
    "\n",
    "    def forward(self, x_1, x_2, edge_index_1, edge_index_2, batch_1, batch_2):\n",
    "\n",
    "        #### Graph 1 ####\n",
    "        # Conv block graph 1\n",
    "        x_1 = self.g1_conv_1(x_1, edge_index_1)\n",
    "        x_1 = global_max_pool(x_1, batch_1) \n",
    "        x_1 = self.g1_act_1(x_1)\n",
    "        \n",
    "        # Linear block graph 1\n",
    "        x_1 = self.g1_linear_1(x_1)\n",
    "        x_1 = self.g1_act_2(x_1)\n",
    "\n",
    "\n",
    "        #### Graph 2 ####\n",
    "        # Conv block graph 2\n",
    "        x_2 = self.g2_conv_1(x_2, edge_index_2)\n",
    "        x_2 = global_max_pool(x_2, batch_2) \n",
    "        x_2 = self.g2_act_1(x_2)\n",
    "        \n",
    "\n",
    "        # Linear block graph 2\n",
    "        x_2 = self.g2_linear_1(x_2)\n",
    "        x_2 = self.g2_act_2(x_2)\n",
    "        ################\n",
    "\n",
    "\n",
    "        #### di_graph ####\n",
    "        print(x.shape)\n",
    "        x = torch.concat((x_1, x_2), dim=1)\n",
    "        x = self.cat_linear(x)\n",
    "        print(x.shape)\n",
    "        x = self.cat_act(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify data paths\n",
    "path_to_g1 = \"/mnt/mnemo5/sum02dean/sl_projects/GCN/GCN-STRING/src/scripts/di_graphs_1\"\n",
    "path_to_g2 = \"/mnt/mnemo5/sum02dean/sl_projects/GCN/GCN-STRING/src/scripts/di_graphs_2\"\n",
    "graph_labels = \"/mnt/mnemo5/sum02dean/sl_projects/GCN/GCN-STRING/src/scripts/di_graph_labels\"\n",
    "\n",
    "# Load in the labels path\n",
    "label_path = glob.glob(os.path.join(graph_labels, '*.csv'))\n",
    "labels = pd.read_csv(label_path[0])\n",
    "\n",
    "# Some rows are duplcated - need to drop them...\n",
    "labels.drop_duplicates(subset=None, keep='first', inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_files = glob.glob(os.path.join(path_to_g1, '*.gpickle'))\n",
    "g2_files = glob.glob(os.path.join(path_to_g2, '*.gpickle'))\n",
    "\n",
    "protein_1 = g1_files[0].split('/')[-1].split('_')[-1].replace('.gpickle', '')\n",
    "protein_2 = g2_files[0].split('/')[-1].split('_')[-1].replace('.gpickle', '')\n",
    "interact_label = int(labels[(labels['protein_1'] == protein_1) & (labels['protein_2'] == protein_2)]['label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18257/18257 [02:19<00:00, 130.64it/s]\n"
     ]
    }
   ],
   "source": [
    "DRAW = False\n",
    "graph_1 = []\n",
    "graph_2 = []\n",
    "l = []\n",
    "\n",
    "for i in tqdm(range(len(g1_files))):\n",
    "\n",
    "    # Get the graphs\n",
    "    G_1 = nx.read_gpickle(g1_files[i])\n",
    "    G_2 = nx.read_gpickle(g2_files[i])\n",
    "\n",
    "    # Get the labels\n",
    "    protein_1 = g1_files[i].split('/')[-1].split('_')[-1].replace('.gpickle', '')\n",
    "    protein_2 = g2_files[i].split('/')[-1].split('_')[-1].replace('.gpickle', '')\n",
    "    interact_label = labels[(labels['protein_1'] == protein_1) & (labels['protein_2'] == protein_2)]['label'].values\n",
    "    l.append(int(interact_label))\n",
    "\n",
    "\n",
    "    # Create the graph lists\n",
    "    graph_1.append(G_1)\n",
    "    graph_2.append(G_2)\n",
    "    \n",
    "    if DRAW:\n",
    "        # Graph 1\n",
    "        nx.draw(G_1, with_labels=False, edge_color=\"black\",\n",
    "                    node_size=10, width=0.2, node_color='blue')\n",
    "        plt.show()\n",
    "\n",
    "        # Graph 2\n",
    "        nx.draw(G_2, with_labels=False, edge_color=\"black\",\n",
    "                        node_size=10, width=0.2, node_color='green')\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = np.array(l)\n",
    "graph_1_array = np.array(graph_1, object)\n",
    "graph_2_array = np.array(graph_2, object)\n",
    "\n",
    "# Pull out the positives\n",
    "g1_positives = graph_1_array[label_array == 1]\n",
    "g2_positives = graph_2_array[label_array == 1]\n",
    "\n",
    "# Pull out the negatives\n",
    "g1_negatives = graph_1_array[label_array == 0]\n",
    "g2_negatives = graph_2_array[label_array == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random indicies to balance negatives to size of positives\n",
    "r = list(range(len(g1_positives)))\n",
    "random_index = np.random.choice(r, size=len(g1_positives), replace=False)\n",
    "g1_negatives = g1_negatives[random_index]\n",
    "g2_negatives = g2_negatives[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5417 [00:00<?, ?it/s]/mnt/mnemo5/sum02dean/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch_geometric/utils/convert.py:170: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  data[key] = torch.tensor(value)\n",
      "100%|██████████| 5417/5417 [02:15<00:00, 40.11it/s] \n",
      "100%|██████████| 5417/5417 [02:05<00:00, 43.33it/s] \n",
      "100%|██████████| 5417/5417 [03:07<00:00, 28.82it/s] \n",
      "100%|██████████| 5417/5417 [02:52<00:00, 31.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Format graphs\n",
    "g1_positive_graphs = format_graphs(g1_positives, label=1)\n",
    "g2_positive_graphs = format_graphs(g2_positives, label=1)\n",
    "\n",
    "g1_negative_graphs = format_graphs(g1_negatives, label=0)\n",
    "g2_negative_graphs = format_graphs(g2_negatives, label=0)\n",
    "\n",
    "# Combine positives with negatives into 2 sets\n",
    "graph_batch_1 = g1_positive_graphs + g1_negative_graphs\n",
    "graph_batch_2 = g2_positive_graphs + g2_negative_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "train_idx = np.random.choice(a=[False, True], size=len(graph_batch_1))\n",
    "test_idx = ~train_idx\n",
    "\n",
    "# Convert range to array \n",
    "full_idx = np.array(range(len(graph_batch_1)))\n",
    "\n",
    "# Grab indices using Boolean array\n",
    "tr_idx = full_idx[train_idx]\n",
    "te_idx = full_idx[test_idx]\n",
    "\n",
    "# Slice train and test data for batch 1 (graphs 1)\n",
    "train_batch_1 = [graph_batch_1[x] for x in tr_idx]\n",
    "test_batch_1 = [graph_batch_1[x] for x in te_idx]\n",
    "\n",
    "# Slice train and test data for batch 2 (graphs 2)\n",
    "train_batch_2 = [graph_batch_2[x] for x in tr_idx]\n",
    "test_batch_2 = [graph_batch_2[x] for x in te_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.192599</td>\n",
       "      <td>2.816448</td>\n",
       "      <td>-0.944031</td>\n",
       "      <td>-0.566769</td>\n",
       "      <td>1.550938</td>\n",
       "      <td>-0.338477</td>\n",
       "      <td>-0.867875</td>\n",
       "      <td>-0.159146</td>\n",
       "      <td>-0.269403</td>\n",
       "      <td>-0.549558</td>\n",
       "      <td>-0.508703</td>\n",
       "      <td>-0.485843</td>\n",
       "      <td>2.595845</td>\n",
       "      <td>-0.244605</td>\n",
       "      <td>1.215671</td>\n",
       "      <td>4.435360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.311013</td>\n",
       "      <td>1.812328</td>\n",
       "      <td>-0.940621</td>\n",
       "      <td>-0.559956</td>\n",
       "      <td>1.541135</td>\n",
       "      <td>-0.330893</td>\n",
       "      <td>-0.867098</td>\n",
       "      <td>-0.159096</td>\n",
       "      <td>-0.248275</td>\n",
       "      <td>-0.545098</td>\n",
       "      <td>-0.422099</td>\n",
       "      <td>-0.445963</td>\n",
       "      <td>2.521223</td>\n",
       "      <td>-0.297926</td>\n",
       "      <td>0.969255</td>\n",
       "      <td>2.552999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.734905</td>\n",
       "      <td>1.193080</td>\n",
       "      <td>-0.940139</td>\n",
       "      <td>-0.476638</td>\n",
       "      <td>1.467187</td>\n",
       "      <td>-0.326760</td>\n",
       "      <td>-0.867208</td>\n",
       "      <td>-0.158966</td>\n",
       "      <td>-0.065698</td>\n",
       "      <td>-0.479998</td>\n",
       "      <td>-0.119414</td>\n",
       "      <td>-0.428863</td>\n",
       "      <td>2.287537</td>\n",
       "      <td>-0.410561</td>\n",
       "      <td>1.153916</td>\n",
       "      <td>0.467769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.722818</td>\n",
       "      <td>-0.578272</td>\n",
       "      <td>-0.943621</td>\n",
       "      <td>-0.081473</td>\n",
       "      <td>1.122884</td>\n",
       "      <td>-0.337435</td>\n",
       "      <td>-0.867748</td>\n",
       "      <td>-0.158986</td>\n",
       "      <td>-0.089174</td>\n",
       "      <td>-0.073049</td>\n",
       "      <td>-0.224795</td>\n",
       "      <td>-0.475418</td>\n",
       "      <td>1.899090</td>\n",
       "      <td>-0.390519</td>\n",
       "      <td>1.261339</td>\n",
       "      <td>-0.255505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.313526</td>\n",
       "      <td>0.955059</td>\n",
       "      <td>-0.943980</td>\n",
       "      <td>1.763267</td>\n",
       "      <td>-0.502125</td>\n",
       "      <td>-0.337900</td>\n",
       "      <td>-0.867894</td>\n",
       "      <td>-0.159109</td>\n",
       "      <td>-0.059955</td>\n",
       "      <td>1.829889</td>\n",
       "      <td>-0.418372</td>\n",
       "      <td>-0.483991</td>\n",
       "      <td>-0.219479</td>\n",
       "      <td>-0.663335</td>\n",
       "      <td>1.125562</td>\n",
       "      <td>-0.314984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  2.192599  2.816448 -0.944031 -0.566769  1.550938 -0.338477 -0.867875   \n",
       "1  2.311013  1.812328 -0.940621 -0.559956  1.541135 -0.330893 -0.867098   \n",
       "2  1.734905  1.193080 -0.940139 -0.476638  1.467187 -0.326760 -0.867208   \n",
       "3 -0.722818 -0.578272 -0.943621 -0.081473  1.122884 -0.337435 -0.867748   \n",
       "4  0.313526  0.955059 -0.943980  1.763267 -0.502125 -0.337900 -0.867894   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -0.159146 -0.269403 -0.549558 -0.508703 -0.485843  2.595845 -0.244605   \n",
       "1 -0.159096 -0.248275 -0.545098 -0.422099 -0.445963  2.521223 -0.297926   \n",
       "2 -0.158966 -0.065698 -0.479998 -0.119414 -0.428863  2.287537 -0.410561   \n",
       "3 -0.158986 -0.089174 -0.073049 -0.224795 -0.475418  1.899090 -0.390519   \n",
       "4 -0.159109 -0.059955  1.829889 -0.418372 -0.483991 -0.219479 -0.663335   \n",
       "\n",
       "         14        15  \n",
       "0  1.215671  4.435360  \n",
       "1  0.969255  2.552999  \n",
       "2  1.153916  0.467769  \n",
       "3  1.261339 -0.255505  \n",
       "4  1.125562 -0.314984  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.857760</td>\n",
       "      <td>0.762143</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>3.911555e-08</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.999018</td>\n",
       "      <td>0.262367</td>\n",
       "      <td>0.869233</td>\n",
       "      <td>0.900200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.885981</td>\n",
       "      <td>0.575915</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.995905</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>1.618173e-06</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>0.976530</td>\n",
       "      <td>0.256126</td>\n",
       "      <td>0.812879</td>\n",
       "      <td>0.543780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.748677</td>\n",
       "      <td>0.461066</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.031615</td>\n",
       "      <td>0.966487</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>5.767215e-06</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>0.024284</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.906106</td>\n",
       "      <td>0.242942</td>\n",
       "      <td>0.855110</td>\n",
       "      <td>0.148946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.162927</td>\n",
       "      <td>0.132542</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.170130</td>\n",
       "      <td>0.829514</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>5.137641e-06</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>0.166316</td>\n",
       "      <td>0.037031</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.789042</td>\n",
       "      <td>0.245288</td>\n",
       "      <td>0.879677</td>\n",
       "      <td>0.011996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.409920</td>\n",
       "      <td>0.416921</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.816759</td>\n",
       "      <td>0.183045</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.226086e-06</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>0.830471</td>\n",
       "      <td>0.011959</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.150585</td>\n",
       "      <td>0.213354</td>\n",
       "      <td>0.848625</td>\n",
       "      <td>0.000734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.857760  0.762143  0.000174  0.000022  0.999805  0.000046  0.000033   \n",
       "1  0.885981  0.575915  0.001685  0.002410  0.995905  0.000809  0.000372   \n",
       "2  0.748677  0.461066  0.001898  0.031615  0.966487  0.001225  0.000324   \n",
       "3  0.162927  0.132542  0.000356  0.170130  0.829514  0.000151  0.000089   \n",
       "4  0.409920  0.416921  0.000197  0.816759  0.183045  0.000104  0.000025   \n",
       "\n",
       "             7         8         9         10        11        12        13  \\\n",
       "0  3.911555e-08  0.000035  0.000007  0.000259  0.000610  0.999018  0.262367   \n",
       "1  1.618173e-06  0.000667  0.001563  0.011476  0.008809  0.976530  0.256126   \n",
       "2  5.767215e-06  0.006133  0.024284  0.050680  0.012325  0.906106  0.242942   \n",
       "3  5.137641e-06  0.005430  0.166316  0.037031  0.002753  0.789042  0.245288   \n",
       "4  1.226086e-06  0.006305  0.830471  0.011959  0.000990  0.150585  0.213354   \n",
       "\n",
       "         14        15  \n",
       "0  0.869233  0.900200  \n",
       "1  0.812879  0.543780  \n",
       "2  0.855110  0.148946  \n",
       "3  0.879677  0.011996  \n",
       "4  0.848625  0.000734  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ss = MinMaxScaler()\n",
    "train_x_1 = np.vstack([d.x for d in train_batch_1])\n",
    "train_x_1 = pd.DataFrame(train_x_1)\n",
    "\n",
    "train_x_2 = np.vstack([d.x for d in train_batch_2])\n",
    "train_x_2 = pd.DataFrame(train_x_2)\n",
    "train_x = pd.concat((train_x_1, train_x_2), ignore_index=True, axis=0)\n",
    "display(train_x.head())\n",
    "train_x = pd.DataFrame(ss.fit_transform(train_x))\n",
    "display(train_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1926,  2.8164, -0.9440,  ..., -0.2446,  1.2157,  4.4354],\n",
      "        [ 2.3110,  1.8123, -0.9406,  ..., -0.2979,  0.9693,  2.5530],\n",
      "        [ 1.7349,  1.1931, -0.9401,  ..., -0.4106,  1.1539,  0.4678],\n",
      "        ...,\n",
      "        [ 1.6586,  1.3951, -0.9202,  ..., -0.4498,  0.9068,  3.9311],\n",
      "        [ 2.0161,  0.9956, -0.9255,  ..., -0.5365,  1.2301,  3.9370],\n",
      "        [ 2.5773,  2.6782, -0.9434,  ..., -0.4779,  1.0087,  4.1868]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[8.5776e-01, 7.6214e-01, 1.7373e-04,  ..., 2.6237e-01, 8.6923e-01,\n",
       "         9.0020e-01],\n",
       "        [8.8598e-01, 5.7591e-01, 1.6851e-03,  ..., 2.5613e-01, 8.1288e-01,\n",
       "         5.4378e-01],\n",
       "        [7.4868e-01, 4.6107e-01, 1.8985e-03,  ..., 2.4294e-01, 8.5511e-01,\n",
       "         1.4895e-01],\n",
       "        ...,\n",
       "        [7.3049e-01, 4.9854e-01, 1.0747e-02,  ..., 2.3835e-01, 7.9860e-01,\n",
       "         8.0472e-01],\n",
       "        [8.1570e-01, 4.2445e-01, 8.3802e-03,  ..., 2.2819e-01, 8.7254e-01,\n",
       "         8.0583e-01],\n",
       "        [9.4946e-01, 7.3650e-01, 4.3916e-04,  ..., 2.3505e-01, 8.2191e-01,\n",
       "         8.5313e-01]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to trnsform the dat\n",
    "print(train_batch_1[0].x)\n",
    "\n",
    "for i in range(len(train_batch_1)):\n",
    "    train_batch_1[i].x = torch.FloatTensor(ss.transform(train_batch_1[i].x))\n",
    "    train_batch_2[i].x = torch.FloatTensor(ss.transform(train_batch_2[i].x))\n",
    "\n",
    "train_batch_1[0].x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "BATCH_SIZE = 250\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# Optimizers & Criterion\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Try making a duel dataloader\n",
    "train_dataset = MyDataset(train_batch_1, train_batch_2)\n",
    "test_dataset = MyDataset(test_batch_1, test_batch_2)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop model structure\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels=64):\n",
    "        \"\"\"\n",
    "        This class takes in 2 inputs. Each input is a graph representing a single protein structure in a protein pair.\n",
    "        Each graph is processed by seperate nerual networks, the outputs of which are then concatenated into a single\n",
    "        hiddden state. Finally this hidden state is passed through a simple dense layer for feature extraction, and then \n",
    "        returned for use with a BCEWithLogitLoss (recommended for binary classificatio) method inside the main training loop.\n",
    "\n",
    "        :param hidden_channels: the number of hidden neurons to use, defaults to 64\n",
    "        :type hidden_channels: int, optional\n",
    "\n",
    "        \"\"\"\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # Parameters\n",
    "        self.num_node_features = 16\n",
    "        self.num_classes = 1\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.n_heads = 2\n",
    "\n",
    "        #### Graph 1 ####\n",
    "        # Layers (consider using class SAGEConv instead)\n",
    "        self.g1_conv_1 = GCNConv(self.num_node_features, self.hidden_channels)\n",
    "        self.g1_linear_1 = Linear(self.hidden_channels, self.hidden_channels)\n",
    "\n",
    "        # Paramteric RelU (prelu)\n",
    "        self.g1_act_1 = torch.nn.ReLU()\n",
    "        self.g1_act_2 = torch.nn.ReLU()\n",
    "\n",
    "        #### Graph 2 ####\n",
    "        self.g2_conv_1 = GCNConv(self.num_node_features,self.hidden_channels)\n",
    "        self.g2_linear_1 = Linear(self.hidden_channels, self.hidden_channels)\n",
    "        self.g2_act_1 = torch.nn.ReLU()\n",
    "        self.g2_act_2 = torch.nn.ReLU()\n",
    "\n",
    "        #### Concatenated graphs ####\n",
    "        self.cat_linear = Linear(self.hidden_channels * 2, self.num_classes)\n",
    "        self.cat_act = torch.nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x_1, x_2, edge_index_1, edge_index_2, batch_1, batch_2):\n",
    "\n",
    "        #### Graph 1 ####\n",
    "        # Conv block graph 1\n",
    "        x_1 = self.g1_conv_1(x_1, edge_index_1)\n",
    "        x_1 = global_max_pool(x_1, batch_1) \n",
    "        x_1 = self.g1_act_1(x_1)\n",
    "        \n",
    "        # Linear block graph 1\n",
    "        x_1 = self.g1_linear_1(x_1)\n",
    "        x_1 = self.g1_act_2(x_1)\n",
    "\n",
    "\n",
    "        #### Graph 2 ####\n",
    "        # Conv block graph 2\n",
    "        x_2 = self.g2_conv_1(x_2, edge_index_2)\n",
    "        x_2 = global_max_pool(x_2, batch_2) \n",
    "        x_2 = self.g2_act_1(x_2)\n",
    "        \n",
    "\n",
    "        # Linear block graph 2\n",
    "        x_2 = self.g2_linear_1(x_2)\n",
    "        x_2 = self.g2_act_2(x_2)\n",
    "        ################\n",
    "\n",
    "\n",
    "        #### di_graph ####\n",
    "        x = torch.concat((x_1, x_2), dim=1)\n",
    "        x = self.cat_linear(x)\n",
    "        x = self.cat_act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [02:46<2:15:44, 166.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5006, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5013, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5014, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5001, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5002, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5024,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5032, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5002, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5002, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Epoch: 0, loss:  15.991550922393799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [05:32<2:12:58, 166.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([0.5000, 0.5024, 0.5000, 0.5003, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5017, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5001, 0.5000, 0.5000,\n",
      "        0.5012, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5032, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5013, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5010, 0.5000, 0.5000, 0.5000, 0.5000, 0.5006,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5011, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5020, 0.5007, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5019, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5018],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Epoch: 1, loss:  15.983703970909119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [08:08<2:06:25, 161.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5011, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5008, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5013, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5014, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5028, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5011, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5024, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5010, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5002, 0.5000, 0.5000, 0.5000, 0.5021, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5001, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Epoch: 2, loss:  15.97581535577774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [08:43<2:16:39, 174.45s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/mnemo5/sum02dean/sl_projects/GCN/GCN-STRING/src/notebooks/di_graph_network.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blphobos/mnt/mnemo5/sum02dean/sl_projects/GCN/GCN-STRING/src/notebooks/di_graph_network.ipynb#ch0000019vscode-remote?line=34'>35</a>\u001b[0m     epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blphobos/mnt/mnemo5/sum02dean/sl_projects/GCN/GCN-STRING/src/notebooks/di_graph_network.ipynb#ch0000019vscode-remote?line=36'>37</a>\u001b[0m     \u001b[39m# Backpropogate the loss\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blphobos/mnt/mnemo5/sum02dean/sl_projects/GCN/GCN-STRING/src/notebooks/di_graph_network.ipynb#ch0000019vscode-remote?line=37'>38</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward() \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blphobos/mnt/mnemo5/sum02dean/sl_projects/GCN/GCN-STRING/src/notebooks/di_graph_network.ipynb#ch0000019vscode-remote?line=38'>39</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blphobos/mnt/mnemo5/sum02dean/sl_projects/GCN/GCN-STRING/src/notebooks/di_graph_network.ipynb#ch0000019vscode-remote?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(Y_1)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/mnemo5/sum02dean/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///mnt/mnemo5/sum02dean/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///mnt/mnemo5/sum02dean/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///mnt/mnemo5/sum02dean/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/mnemo5/sum02dean/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///mnt/mnemo5/sum02dean/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///mnt/mnemo5/sum02dean/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/mnemo5/sum02dean/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///mnt/mnemo5/sum02dean/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///mnt/mnemo5/sum02dean/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///mnt/mnemo5/sum02dean/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///mnt/mnemo5/sum02dean/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = GCN(hidden_channels=100)\n",
    "\n",
    "# Training loop;\n",
    "print(\"Begining training!\")\n",
    "model.train()\n",
    "model = model.float()\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (graph_1, graph_2) in enumerate(train_loader):\n",
    "        # Grab graph 1 inputs\n",
    "        X_1, Y_1, EI_1  = graph_1.x, graph_1.y, graph_1.edge_index\n",
    "        B_1 = graph_1.batch\n",
    "\n",
    "        # Grab graph 2 inputs\n",
    "        X_2, Y_2, EI_2  = graph_2.x, graph_2.y, graph_2.edge_index\n",
    "        B_2 = graph_2.batch\n",
    "                \n",
    "    \n",
    "        # Zero the gradient\n",
    "        optimizer.zero_grad()  \n",
    "\n",
    "        # Compute model outputs\n",
    "        logits = model(\n",
    "            x_1=X_1, x_2=X_2, edge_index_1=EI_1, edge_index_2=EI_2,\n",
    "            batch_1=B_1, batch_2=B_2).flatten()\n",
    "\n",
    "        probas = torch.sigmoid(logits)\n",
    "        \n",
    "\n",
    "        # Grab the loss and step gradients\n",
    "        loss = criterion(probas, Y_1)  \n",
    "        epoch_loss += loss.item() \n",
    "\n",
    "        # Backpropogate the loss\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "    \n",
    "    print(Y_1)\n",
    "    print(probas)\n",
    "    # Print the epochs\n",
    "    print(\"Epoch: {}, loss: \".format(epoch), epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 541/541 [00:41<00:00, 12.97it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHFCAYAAAAe+pb9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB0aElEQVR4nO3dd1QU198G8GcpSwcFpFkAC3YsoCh2o6jYE6PG3nssWNFE7CRWYiwYC8beNWrQSIy9REGsmIiKYgEVVFDp7H3/yMv+XAFlcWEoz+ecPcnenfLMzrL79c6dGZkQQoCIiIioGNKSOgARERGRVFgIERERUbHFQoiIiIiKLRZCREREVGyxECIiIqJii4UQERERFVsshIiIiKjYYiFERERExRYLISIiIiq2WAgVEBs3boRMJlM+dHR0YGtri549eyI8PFzqeAAABwcHDBgwQOoYRcqqVauwcePGTO0PHjyATCbL8rWCICPf4sWLpY6itoSEBMyaNQsnT57Mk+WfPHkSMplM7eUX1s9CQSSTyTBr1iyNLS8lJQUjRoyAra0ttLW1Ubt2bY0t+2MOHz6Mzp07w87ODnK5HCYmJqhTpw58fHwQGRmZaXqFQoHNmzejVatWsLS0hK6uLqysrNChQwccOnQICoUCwP8+UzKZDDt27Mi0nFmzZkEmkyEmJibPt7Eg0JE6AKkKCAhAlSpVkJSUhHPnzmH+/Pk4ceIE/vnnH5QsWVLSbPv374epqamkGYqaVatWwdLSMlOBaWtriwsXLqBChQrSBCvCEhISMHv2bABA8+bNNb78unXr4sKFC6hWrZpa8/GzUHCtXr0aa9aswc8//wwXFxcYGxvn6foUCgUGDhyITZs2oV27dvD19YWDgwMSExNx+fJlBAQEYMOGDXj06JFynqSkJHTp0gXHjh1Dz549sXr1atjY2ODFixc4evQovv76a+zcuROdO3dWWdeMGTPw1VdfQVdXN0+3qSBjIVTA1KhRA66urgD++5JOT0+Hj48PDhw4gIEDB0qarU6dOvm+zvT0dKSlpUFPTy/f160uIQSSkpJgYGDw2cvS09NDgwYNNJCqcEtMTIS+vj5kMpnUUT4pNTUVMpkMpqamGt13/CxI7+bNmzAwMMCYMWM0tszExMRsvyt+/PFHbNq0Cb6+vpg2bZrKa23btoW3tzfWrFmj0u7l5YU//vgDv/76K/r166fy2pdffonJkycjMTFRpb1du3Y4cuQI/P398e2332pgqwonHhor4DKKomfPnqm0BwcHo1OnTjA3N4e+vj7q1KmDXbt2ZZr/yZMnGDZsGMqWLQu5XA47Ozt069ZNZXnx8fGYNGkSHB0dIZfLUbp0aYwfPx7v3r1TWdb7h8ZevHgBuVyO77//PtM6//nnH8hkMixfvlzZFh0djeHDh6NMmTKQy+VwdHTE7NmzkZaWppwmo7t24cKFmDdvHhwdHaGnp4cTJ05k+/4kJSXB29tbJfvo0aPx+vXrTNk7dOiA/fv3w9nZGfr6+ihfvrxKRnXfD5lMhjFjxsDf3x9Vq1aFnp4efv31VwDA7Nmz4ebmBnNzc5iamqJu3bpYv3493r/HsYODA27duoVTp04pu6kdHBxU3ov3D4dkdFffunUL33zzDczMzGBtbY1BgwYhLi5OJdvr168xePBgmJubw9jYGO3bt8f9+/dzfMjg9evXmDhxIsqXLw89PT1YWVnB09MT//zzT6Zply5dCkdHRxgbG6Nhw4a4ePGiyuvBwcHo2bMnHBwcYGBgAAcHB3zzzTd4+PChynQZh4ePHTuGQYMGoVSpUjA0NERycjLu3r2LgQMHolKlSjA0NETp0qXRsWNH3LhxQ63sDx48QKlSpZT7KON9f78XJjw8HL169YKVlRX09PRQtWpVrFy5UmUdGYe/Nm/ejIkTJ6J06dLQ09PD3bt3szw0dv/+ffTs2RN2dnbQ09ODtbU1vvjiC1y9ehWA+p8F4L+/s2+++QbW1tbQ09NDuXLl0K9fPyQnJ39s1yIlJQXz5s1DlSpVoKenh1KlSmHgwIF48eKFcpoffvgBWlpaOHTokMq8AwYMgKGhofJ9T0pKwsSJE1G7dm2YmZnB3NwcDRs2xG+//ZZpvRl/LwEBAahcuTIMDAzg6uqKixcvQgiBRYsWKT9HLVu2xN27d1Xmb968OWrUqIEzZ86gQYMGMDAwQOnSpfH9998jPT39o9sM5Ow7KCsymQzr1q1DYmKict9k7At1v3/27duHOnXqQF9fX9kr+aGUlBQsXLgQNWrUyFQEZdDR0cHo0aNVtm3dunVo06ZNpiIoQ6VKleDs7KzS1rJlS7Rp0wZz587FmzdvPvo+FGXsESrgIiIiAABOTk7KthMnTqBt27Zwc3ODv78/zMzMsGPHDvTo0QMJCQnKL/UnT56gXr16SE1NxfTp0+Hs7IzY2Fj88ccfePXqFaytrZGQkIBmzZrh8ePHymlu3bqFmTNn4saNG/jzzz+z/Nd4qVKl0KFDB/z666+YPXs2tLT+V1MHBARALpejd+/eAP77I61fvz60tLQwc+ZMVKhQARcuXMC8efPw4MEDBAQEqCx7+fLlcHJywuLFi2FqaopKlSpl+d4IIdClSxccP34c3t7eaNKkCa5fvw4fHx9cuHABFy5cUOlJunr1KsaPH49Zs2bBxsYGW7duxbhx45CSkoJJkyYBgNrvx4EDB3DmzBnMnDkTNjY2sLKyAvDfj9fw4cNRrlw5AMDFixfx7bff4smTJ5g5cyaA/w41duvWDWZmZli1ahUA5Kjn66uvvkKPHj0wePBg3LhxA97e3gCADRs2APivW71jx44IDg7GrFmzlIdq2rZt+8llA8CbN2/QuHFjPHjwAFOnToWbmxvevn2L06dPIyoqClWqVFFOu3LlSlSpUgV+fn4AgO+//x6enp6IiIiAmZmZ8r2oXLkyevbsCXNzc0RFRWH16tWoV68ewsLCYGlpqbL+QYMGoX379ti8eTPevXsHXV1dPH36FBYWFvjhhx9QqlQpvHz5Er/++ivc3NwQGhqKypUr5yi7u7s7jh49irZt22Lw4MEYMmQIACiLo7CwMLi7u6NcuXJYsmQJbGxs8Mcff2Ds2LGIiYmBj4+PSlZvb280bNgQ/v7+0NLSgpWVFaKjozO9p56enkhPT8fChQtRrlw5xMTE4Pz588ofTHU/C9euXUPjxo1haWmJOXPmoFKlSoiKisLBgweRkpKS7bwKhQKdO3fGmTNnMGXKFLi7u+Phw4fw8fFB8+bNERwcDAMDA0ydOhVnzpxB//79ERoaCnt7ewQEBODXX3/FunXrULNmTQBAcnIyXr58iUmTJqF06dJISUnBn3/+iS+//BIBAQGZfpQPHz6M0NBQ/PDDD5DJZJg6dSrat2+P/v374/79+1ixYgXi4uLg5eWFr776ClevXlX5e4uOjkbPnj0xbdo0zJkzB7///jvmzZuHV69eYcWKFdm+X+p+B73vwoULmDt3Lk6cOIG//voLAFChQgW1v3+uXLmC27dv47vvvoOjoyOMjIyyXF9wcDBev36NkSNHZpvpQydOnEBqaiq6dOmS43ky/Pjjj6hTpw4WLVqEOXPmqD1/kSCoQAgICBAAxMWLF0Vqaqp48+aNOHr0qLCxsRFNmzYVqampymmrVKki6tSpo9ImhBAdOnQQtra2Ij09XQghxKBBg4Surq4ICwvLdr2+vr5CS0tLXL58WaV9z549AoAIDAxUttnb24v+/fsrnx88eFAAEMeOHVO2paWlCTs7O/HVV18p24YPHy6MjY3Fw4cPVdaxePFiAUDcunVLCCFERESEACAqVKggUlJSPvWWiaNHjwoAYuHChSrtO3fuFADEL7/8opJdJpOJq1evqkzbunVrYWpqKt69e6f2+wFAmJmZiZcvX340Z3p6ukhNTRVz5swRFhYWQqFQKF+rXr26aNasWaZ5Mt6LgIAAZZuPj0+W2ztq1Cihr6+vXO7vv/8uAIjVq1erTOfr6ysACB8fn4/mnTNnjgAggoKCsp0mI1/NmjVFWlqasv3SpUsCgNi+fXu286alpYm3b98KIyMj8dNPPynbM/4G+vXr99F8GctISUkRlSpVEhMmTFAr+4sXL7J9H9q0aSPKlCkj4uLiVNrHjBkj9PX1lfv6xIkTAoBo2rRppmVkvHbixAkhhBAxMTECgPDz8/voNqnzWWjZsqUoUaKEeP78+UeX+aHt27cLAGLv3r0q7ZcvXxYAxKpVq5RtMTExokyZMqJ+/friypUrwtDQUPTp0+ejy09LSxOpqali8ODBok6dOiqvARA2Njbi7du3yrYDBw4IAKJ27doqfxd+fn4CgLh+/bqyrVmzZgKA+O2331SWO3ToUKGlpaXy/fLh/s3pd1B2+vfvL4yMjFTa1P3+0dbWFv/+++9H1yOEEDt27BAAhL+/f6bXUlNTVR4ZfvjhBwFAHD169JPLF+J/n6lFixYJIYTo3bu3MDIyElFRUUKI/33XvHjxIkfLK+x4aKyAadCgAXR1dWFiYoK2bduiZMmS+O2336Cj81/n3d27d/HPP/8oe1vS0tKUD09PT0RFReHff/8FABw5cgQtWrRA1apVs13f4cOHUaNGDdSuXVtlWW3atPnkmS/t2rWDjY2Nyr+m/vjjDzx9+hSDBg1SWUeLFi1gZ2enso527doBAE6dOqWy3E6dOuVo4F7Gv84+HFz69ddfw8jICMePH1dpr169OmrVqqXS1qtXL8THx+PKlSu5ej9atmyZ5SD2v/76C61atYKZmRm0tbWhq6uLmTNnIjY2Fs+fP//ktn1Mp06dVJ47OzsjKSlJudyM97N79+4q033zzTc5Wv6RI0fg5OSEVq1afXLa9u3bQ1tbWyULAJXDXm/fvsXUqVNRsWJF6OjoQEdHB8bGxnj37h1u376daZlfffVVpra0tDQsWLAA1apVg1wuh46ODuRyOcLDw1WWoU72DyUlJeH48ePo2rUrDA0NM/1tJSUlZTrsl1XWD5mbm6NChQpYtGgRli5ditDQUOXZO7mRkJCAU6dOoXv37sqerJw6fPgwSpQogY4dO6psX+3atWFjY6Py+bawsMDOnTtx5coVZS+Zv79/pmXu3r0bjRo1grGxMXR0dKCrq4v169dnuW9btGih0hOS8d3Url07lZ6fjPYPD5+amJhk+vz36tULCoUCp0+f/uh2q/MdlBPqfv84Ozur9Oyr6/Xr19DV1VV5BAcH53p575s3bx5SU1OzPVxX1LEQKmA2bdqEy5cv46+//sLw4cNx+/ZtlR+wjLE9kyZNyvRHMWrUKABQnvL44sULlClT5qPre/bsGa5fv55pWSYmJhBCfPT0SR0dHfTt2xf79+9XdvFv3LgRtra2aNOmjco6Dh06lGkd1atXV8mbwdbWNkfvVWxsLHR0dDL9GMhkMtjY2CA2Nlal3cbGJtMyMtoyplX3/cgq66VLl+Dh4QEAWLt2Lc6dO4fLly9jxowZAJBpwKK6LCwsVJ5ndL9nLDfjfTE3N1eZztraOkfLz8nnJqdZgP9+qFasWIEhQ4bgjz/+wKVLl3D58mWUKlUqy/ciq/fUy8sL33//Pbp06YJDhw7h77//xuXLl1GrVi2VZaiT/UOxsbFIS0vDzz//nGn/e3p6AsjdZ1Umk+H48eNo06YNFi5ciLp166JUqVIYO3ZsrsZlvHr1Cunp6bnazmfPnuH169eQy+WZtjE6OjrT9rm5uaF69epISkrCyJEjMx3O2bdvH7p3747SpUtjy5YtuHDhAi5fvoxBgwYhKSkp0/o//EzK5fKPtn+4jKw+wx/+DWe33ep8B+WEut8/Of1eyzicnlURePnyZVy+fDnTIdqMeTKGUqjLwcEBo0aNwrp16wrM5VryE8cIFTBVq1ZVDpBu0aIF0tPTsW7dOuzZswfdunVTjqfw9vbGl19+meUyMsZLlCpVCo8fP/7o+iwtLWFgYKAcX5LV6x8zcOBALFq0SDlG6eDBgxg/frxKL4GlpSWcnZ0xf/78LJdhZ2en8jynZwhZWFggLS0NL168UPkyEkIgOjoa9erVU5k+q7EbGW0ZP+jqvh9ZZd2xYwd0dXVx+PBh6OvrK9sPHDiQo+36XBnvy8uXL1V+YLLa/qzk5HOTU3FxcTh8+DB8fHxUBn5mjC3JSlbv6ZYtW9CvXz8sWLBApT0mJgYlSpTQSPaSJUtCW1sbffv2VRmI+j5HR8dPZs2Kvb091q9fDwC4c+cOdu3ahVmzZiElJSXLXpaPMTc3h7a2dq6209LSEhYWFjh69GiWr5uYmKg89/HxwY0bN+Di4oKZM2eiQ4cOKF++vPL1LVu2wNHRETt37lR5Lz41YDu3PjxpBMj8N5wVdb+DckLd75+cflZcXFxQsmRJHDp0SOXzrq2trfxtuHnzpso8LVq0gK6uLg4cOIARI0aovS0A8N1332HDhg2YPn26skAsLtgjVMAtXLgQJUuWxMyZM6FQKFC5cmVUqlQJ165dg6ura5aPjC+zdu3a4cSJE8pDZVnp0KED7t27BwsLiyyXlXHmSnaqVq0KNzc3BAQEYNu2bUhOTs50mn+HDh1w8+ZNVKhQIct15OZLCAC++OILAP99Gb9v7969ePfunfL1DLdu3cK1a9dU2rZt2wYTExPUrVtXmfVz3g8Aygtivl8MJiYmYvPmzZmm1dPT++weog81a9YMALBz506V9qwunJaVdu3a4c6dO8qu/88hk8kghMg0eHfdunU5OtPn/eV8uIzff/8dT548UWnLSfaseq0AwNDQEC1atEBoaCicnZ2z3P8f+7HNKScnJ3z33XeoWbOm8pBsRq6cfBYMDAzQrFkz7N69W+2ejA4dOiA2Nhbp6elZbl/GP6IAICgoCL6+vvjuu+8QFBQEMzMz9OjRAykpKcppZDIZ5HJ5pgHNWZ01pglv3rzBwYMHVdq2bdsGLS0tNG3aNNv58uI7SN3vn5ySy+WYPHkybt68iR9//DFH89jY2Ch7XDdt2pTlNPfu3cP169ezXYaFhQWmTp2KPXv24NKlS7nKXlixR6iAK1myJLy9vTFlyhRs27YNffr0wZo1a9CuXTu0adMGAwYMQOnSpfHy5Uvcvn0bV65cwe7duwEAc+bMwZEjR9C0aVNMnz4dNWvWxOvXr3H06FF4eXmhSpUqGD9+PPbu3YumTZtiwoQJcHZ2hkKhQGRkJI4dO4aJEyfCzc3toxkHDRqE4cOH4+nTp3B3d1f5Ms3IERQUBHd3d4wdOxaVK1dGUlISHjx4gMDAQPj7++eqm79169Zo06YNpk6divj4eDRq1Eh51kadOnXQt29flent7OzQqVMnzJo1C7a2ttiyZQuCgoLw448/wtDQEAA08n60b98eS5cuRa9evTBs2DDExsZi8eLFWZ7JU7NmTezYsQM7d+5E+fLloa+vrzwjJ7fatm2LRo0aYeLEiYiPj4eLiwsuXLig/IJ8/wy/rIwfP1554bVp06ahfv36SExMxKlTp9ChQwe0aNEix1lMTU3RtGlTLFq0CJaWlnBwcMCpU6ewfv16lZ6cT+nQoQM2btyIKlWqwNnZGSEhIVi0aFGmz01OspuYmMDe3h6//fYbvvjiC5ibmyuz/fTTT2jcuDGaNGmCkSNHwsHBAW/evMHdu3dx6NChXBWH169fx5gxY/D111+jUqVKkMvl+Ouvv3D9+nWVXjJ1PgtLly5F48aN4ebmhmnTpqFixYp49uwZDh48iDVr1mTq2cnQs2dPbN26FZ6enhg3bhzq168PXV1dPH78GCdOnEDnzp3RtWtXREVFoU+fPmjWrBl8fHygpaWFnTt3omnTppgyZYryLMGMU8JHjRqFbt264dGjR5g7dy5sbW3z5BCLhYUFRo4cicjISDg5OSEwMBBr167FyJEjlYeHspIX30Hqfv+oY+rUqfjnn38wbdo0nD59Gj169ICDgwOSk5Nx//59rFu3Dtra2srvLeC/z8T9+/cxYMAA/PHHH+jatSusra0RExODoKAgBAQEYMeOHZlOoX/f+PHjsXLlShw5ciTX2QslSYdqk1LGGTMfnq0khBCJiYmiXLlyolKlSsozdK5duya6d+8urKyshK6urrCxsREtW7bMdKbBo0ePxKBBg4SNjY3Q1dUVdnZ2onv37uLZs2fKad6+fSu+++47UblyZSGXy4WZmZmoWbOmmDBhgoiOjlZO9+FZYxni4uKEgYGBACDWrl2b5fa9ePFCjB07Vjg6OgpdXV1hbm4uXFxcxIwZM5RnkXx4JkNOJCYmiqlTpwp7e3uhq6srbG1txciRI8WrV69UprO3txft27cXe/bsEdWrVxdyuVw4ODiIpUuXZlpmTt8PAGL06NFZ5tqwYYOoXLmy0NPTE+XLlxe+vr5i/fr1AoCIiIhQTvfgwQPh4eEhTExMBABhb2+v8l5kddbYh2dyZHx23l/uy5cvxcCBA0WJEiWEoaGhaN26tbh48aIAoHKmVnZevXolxo0bJ8qVKyd0dXWFlZWVaN++vfjnn39U8mW1r/DBGTuPHz8WX331lShZsqQwMTERbdu2FTdv3sz0efrY38CrV6/E4MGDhZWVlTA0NBSNGzcWZ86cEc2aNct0ptWnsgshxJ9//inq1Kkj9PT0BACVHBEREWLQoEGidOnSQldXV5QqVUq4u7uLefPmKafJODNs9+7dmbJ+eNbYs2fPxIABA0SVKlWEkZGRMDY2Fs7OzmLZsmUqZ9yp81kQQoiwsDDx9ddfCwsLCyGXy0W5cuXEgAEDRFJSUqZM70tNTRWLFy8WtWrVEvr6+sLY2FhUqVJFDB8+XISHh4u0tDTRrFkzYW1trTyLKMOiRYsEALF//35l2w8//CAcHByEnp6eqFq1qli7dq3ys/q+rP5esvscZfX+NmvWTFSvXl2cPHlSuLq6Cj09PWFrayumT5+e6QzaDz+DQuTsOyg7WZ01JoT63z/qOnjwoOjYsaOwtrYWOjo6wsTERNSuXVtMnDhR5fOcIS0tTfz666+iZcuWwtzcXOjo6IhSpUqJdu3aiW3btinPKP7Y3+8vv/wiABSrs8ZkQrx3hTeiIsrBwQE1atTA4cOHpY4imW3btqF37944d+4c3N3dpY5DpJbmzZsjJiYm0/gYos/FQ2NERdD27dvx5MkT1KxZE1paWrh48SIWLVqEpk2bsggiInoPCyGiIsjExAQ7duzAvHnz8O7dO9ja2mLAgAGYN2+e1NGIiAoUHhojIiKiYounzxMREVGxxUKIiIiIii0WQkRERFRsFbvB0gqFAk+fPoWJiUmOL3lORERE0hJC4M2bN7Czs/vkhWHVUewKoadPn6Js2bJSxyAiIqJcePToUa5vrpyVYlcIZVx6/tGjRzA1NZU4DREREeVEfHw8ypYtm+0tZHKr2BVCGYfDTE1NWQgREREVMpoe1sLB0kRERFRssRAiIiKiYouFEBERERVbLISIiIio2GIhRERERMUWCyEiIiIqtlgIERERUbHFQoiIiIiKLRZCREREVGyxECIiIqJiS9JC6PTp0+jYsSPs7Owgk8lw4MCBT85z6tQpuLi4QF9fH+XLl4e/v3/eByUiIqIiSdJC6N27d6hVqxZWrFiRo+kjIiLg6emJJk2aIDQ0FNOnT8fYsWOxd+/ePE5KRERERZGkN11t164d2rVrl+Pp/f39Ua5cOfj5+QEAqlatiuDgYCxevBhfffVVHqUkIiKioqpQjRG6cOECPDw8VNratGmD4OBgpKamSpSKiIiICitJe4TUFR0dDWtra5U2a2trpKWlISYmBra2tpnmSU5ORnJysvJ5fHx8nuckIiIizTr4/ZY8WW6h6hECAJlMpvJcCJFlewZfX1+YmZkpH2XLls3zjERERKQ5Mf8+gveKf/Jk2YWqELKxsUF0dLRK2/Pnz6GjowMLC4ss5/H29kZcXJzy8ejRo/yISkRERJ/pUsAxBAz6GZaVy+Lqk+/yZB2FqhBq2LAhgoKCVNqOHTsGV1dX6OrqZjmPnp4eTE1NVR5ERERUcKWnpGJeqzloPug0XsW+AwDoGurnybokHSP09u1b3L17V/k8IiICV69ehbm5OcqVKwdvb288efIEmzZtAgCMGDECK1asgJeXF4YOHYoLFy5g/fr12L59u1SbQERERBqkSEtHG5vJePxOG2e3tEfd3i3zdH2SFkLBwcFo0aKF8rmXlxcAoH///ti4cSOioqIQGRmpfN3R0RGBgYGYMGECVq5cCTs7OyxfvpynzhMRERUBD8/dgn2j6pgy2R2Nh7aBoaVZnq9TJjJGGxcT8fHxMDMzQ1xcHA+TERERFQCvHz7D6GYLcfGJDP++WQAdfXmmafLq97tQjREiIiKiouXMikOoVWExYt8qcC5kVJZFUF5iIURERESSObr9MiZ2LoXA6MWwcS6f7+svVBdUJCIiosIvPCgEE/tuwfoTEzD/3BxJs7BHiIiIiPKFUCiwfsBy1PXYh4qlDWBiay51JPYIERERUf5Y0X0JFux/gT3zXNBmRg+p4wDgWWNSxyEiIiryTv30G1y/aYq0pFSkvEtCqarl1F5GXv1+s0eIiIiI8kRy/DvMaLkA/iHA7wCajessdaRMWAgRERGRxoUHheDrTlugowWEBPZC5Xb1pI6UJRZCREREpDFCoYAiLR1GFqbo4maG6YenQm5sIHWsbPGsMSIiItKIZzcj0MFmIpZ0WQi7upUw6+SsAl0EASyEiIiISAN+n7UVNZ39YaIvw9CVg6SOk2M8NEZERESf5fmtBxg89zqWDLNHn1UjINMqPP0sLISIiIgoV67uPIV/zv2LnsuHIeLFDBiYF77L0hSeko2IiIgKBEVaOhZ38EWjnsfw4M5zACiURRDAHiEiIiJSgyItHZ42kxAep40/13yBhsPaSR3ps7AQIiIiohyJvn4fNs7lMXJYHbQc0x4mdhZSR/psPDRGREREH/U2+iUGO01GY5eVSEtKQecF/YpEEQSwECIiIqKPuBRwDHXKzcf9F6k4cXYIdPTlUkfSKB4aIyIiomxtW34CQ1uZY+KBKdCW60odR+NYCBEREZGKB2dvwrt3AFafngK/UF+p4+QpHhojIiIipa2j/FG7yVaYGWlD16BoHQbLCnuEiIiICACw/KuFmLv/JTZNr45O8/tKHSdfyIQQQuoQ+Sk+Ph5mZmaIi4uDqWnhvPgTERGRJl1cdxS1uzXGuxevkfIuGba1K0gdKZO8+v1mjxAREVExlZqQhNkeC7DsXDqOJKag6bedpI6U71gIERERFUP3T15Dzw4bkZQuw9/7vkKNro2kjiQJFkJERETFiFAoIBQCMi0ZmlczxJxj3tAvYSx1LMmwECIiIiomYsMfY2izJWjqZoPx+6di4SVnqSNJjqfPExERFQN/LtwD5yrLoRBAnx96SR2nwGCPEBERUREXff0+ekwLhm8vOwzdNBYyLfaDZGAhREREVETd+u087l26h07z++LB48lF5kapmsSSkIiIqIgRCgVWdl+M+l1+x7WLEQDAIigb7BEiIiIqQtJTUtGl7BRci9VBoF9jNBvXWepIBRoLISIioiLi5b2nMK9gh17dq2CTVyeUdLSVOlKBx0NjREREhVziy3iMcZ6GhlWXID0lFd/8PJxFUA6xR4iIiKgQu7rzFHr1+w0l9RQ4+ucgaMt1pY5UqLAQIiIiKsRWzfodPRuZYXqgN3T05VLHKXRYCBERERUyT4LvYGavtfjptDfW3PqB1wX6DHzniIiICpG9kzfAuf4GKIQAABZBn4k9QkRERIXEz90WwWffS6wZXwlfLx0sdZwiQSbE/5eUxUR8fDzMzMwQFxcHU1NTqeMQERF90tWdp1C9oxti7z5FamIyyrpVlTpSvsur32/2CBERERVQ6Smp8PX0xYLjKTi6PA5Nv+0kdaQih4UQERFRAfTw3C308VyLF0naOLulPer2bil1pCKJhRAREVEBIxQKJMUnoI6DPn447g1DSzOpIxVZLISIiIgKiNcPn2F0s4Vo3NAOI7dPxPJ29aSOVOTxnDsiIqIC4MyKQ6hVYTFi3yrQ1bur1HGKDRZCREREEnt6JRwdvz2PiZ1LITB6MWycy0sdqdjgoTEiIiKJhAeF4EHIfbSe9jXu3/0W5hXspI5U7LBHiIiIKJ8JhQLrByxHXY99OHvkFgCwCJIIe4SIiIjyUVpSCnpWnIZzUTrYu8AVHt7dpY5UrLEQIiIiyidvnsbCxM4Cbb+wh//0L2FZuazUkYo9HhojIiLKY8nx7zDRdTrcHOdDkZaOIb+OYxFUQLBHiIiIKA/d+u08evXcDV0tYP+BXtDS0ZY6Er2HhRAREVEe+mHCXrSvY4xZx6ZDbmwgdRz6AAshIiIiDXt2MwLze6/Bjyem49c7C9kLVIBxjBAREZEG/T5rK2o6++P5qxSkJiSzCCrg2CNERESkISu+XoQZe15hxXB79Fk1AjIt9jcUdCyEiIiIPtPtw3/DyaMuOnm1h+foVJRvXkvqSJRDLISIiIhySZGWjqVdFsLn97c4+vNzNBnTUepIpCYWQkRERLnwJPgO+nusQsQbHRxf2woNhrSVOhLlAgshIiKiXIh98AyOVrrYf3MaTOwspI5DuST5KK5Vq1bB0dER+vr6cHFxwZkzZz46/datW1GrVi0YGhrC1tYWAwcORGxsbD6lJSKi4uxt9EsMdpqMjUNWwLlbE6z9ZxGLoEJO0kJo586dGD9+PGbMmIHQ0FA0adIE7dq1Q2RkZJbTnz17Fv369cPgwYNx69Yt7N69G5cvX8aQIUPyOTkRERU3lwKOoU65+bj/IhVfDP1C6jikIZIWQkuXLsXgwYMxZMgQVK1aFX5+fihbtixWr16d5fQXL16Eg4MDxo4dC0dHRzRu3BjDhw9HcHBwPicnIqLi5PHlf/HFoFMY2socfz5bhLJuVaWORBoiWSGUkpKCkJAQeHh4qLR7eHjg/PnzWc7j7u6Ox48fIzAwEEIIPHv2DHv27EH79u2zXU9ycjLi4+NVHkRERDnx4OxNnFlxCGXqVUb4tcGYEjgD2nJdqWORBklWCMXExCA9PR3W1tYq7dbW1oiOjs5yHnd3d2zduhU9evSAXC6HjY0NSpQogZ9//jnb9fj6+sLMzEz5KFuWd/slIqJP2zrKH7WabMPR7ZcBADbO5SVORHlB8sHSMplM5bkQIlNbhrCwMIwdOxYzZ85ESEgIjh49ioiICIwYMSLb5Xt7eyMuLk75ePTokUbzExFR0ZKakIReDhMx3v8BtnxXFfPPzZE6EuUhyU6ft7S0hLa2dqben+fPn2fqJcrg6+uLRo0aYfLkyQAAZ2dnGBkZoUmTJpg3bx5sbW0zzaOnpwc9PT3NbwARERU5Sa/fQr+EMdzqWmPpwW7sBSoGJOsRksvlcHFxQVBQkEp7UFAQ3N3ds5wnISEBWh/ct0Vb+7+b2Qkh8iYoEREVeakJSfiu8Uy42X4PRVo6xu2bwiKomJD0gopeXl7o27cvXF1d0bBhQ/zyyy+IjIxUHury9vbGkydPsGnTJgBAx44dMXToUKxevRpt2rRBVFQUxo8fj/r168POzk7KTSEiokIqPCgEvbtuQVK6DFu3fMW7xRczkhZCPXr0QGxsLObMmYOoqCjUqFEDgYGBsLe3BwBERUWpXFNowIABePPmDVasWIGJEyeiRIkSaNmyJX788UepNoGIiAq5GYO2opGTPnz/mgH9EsZSx6F8JhPF7JhSfHw8zMzMEBcXB1NTU6njEBGRBGLDH2NRX3/M+XMGtHS0oaMvlzoSfUJe/X5LftYYERFRfvpz4R44V1mOfx6+Q+LLNyyCijnedJWIiIqNVT2XYOrOl1ja1w5DNo6FTIv9AcUdCyEiIiry7p+8BofGNdBm2Bf4on8qKrerJ3UkKiBYCBERUZElFAqs6rkUU3a/QpD/E7gP95Q6EhUwLISIiKhIenYzAoNaLseNlzoI9GvMIoiyxEKIiIiKpMiQuyhhqIVrf3uhpGPmOw8QASyEiIioCEmIicPkFgvQpEUF9Fw+DFv7t5Y6EhVwHC5PRERFwtWdp+BaejauPkyGW7cGUsehQoKFEBERFXqRF8LQuOcx9GxkhlPPF8KxqbPUkaiQ4KExIiIqtJ4E38HTWw9Rr39r3DrbC/aNqksdiQoZ9ggREVGhtHfyBjjX34A9q04BAIsgyhX2CBERUaGSmpCEEbW/x767OlgzriK6LxsidSQqxFgIERFRoZGakAQdfTnK25vi+uZuKOtWVepIVMjx0BgRERV46SmpmNdqDtxLeUMoBGYEfc8iiDSCPUJERFSgPTh7E3081yEmWRvbNnSElo621JGoCGEhREREBdr4r9ejZlk9LDk1HYaWZlLHoSKGh8aIiKjAiYt8jrlfzEF6Sip2/jsPq2/9yCKI8gQLISIiKlDOrDiEWuUX4ty1V3gb/Qp6pkZSR6IijIUQEREVGKu/WYK2316EV2crBEYvhlk5K6kjURHHMUJERCS5x5f/RWmXSmj2TSP83T0dNbo2kjoSFRMshIiISDJCocCGQSsw/tdnOLamMRoOayd1JCpmWAgREZEkYsMfY2izJbjwTBd7F7iyCCJJsBAiIiJJhP0RCgC4EfYtLCuXlTgNFVcshIiIKN8kx7/DjJYL0LRNFXSa3xdNxnSUOhIVczxrjIiI8kXYwYtws/4OJ28noHLjKlLHIQLAQoiIiPLBg7M3Ub/zIXjWMcb5ZwtQuV09qSMRAeChMSIiykPPbkbg2T+P4dytCUICu7AAogKHPUJERJQnDs/cgprO/tj0w1EAYBFEBRJ7hIiISKNS3iZiQsNZ2HxTGyuH26PPqhFSRyLKVq4KobS0NJw8eRL37t1Dr169YGJigqdPn8LU1BTGxsaazkhERIVEekoqdA31YGYix9UT3VC+eS2pIxF9lNqF0MOHD9G2bVtERkYiOTkZrVu3homJCRYuXIikpCT4+/vnRU4iIirAFGnpWNplIX478wynXy3FgvNzpY5ElCNqjxEaN24cXF1d8erVKxgYGCjbu3btiuPHj2s0HBERFXxPgu/Aw2oiVv8Ri4WL2kCmxeGnVHio3SN09uxZnDt3DnK5XKXd3t4eT5480VgwIiIqHIZ6rkZZCx3sv+kNEzsLqeMQqUXtsl2hUCA9PT1T++PHj2FiYqKRUEREVLC9jX6JpZ1/gCItHbtvzkRA+GIWQVQoqV0ItW7dGn5+fsrnMpkMb9++hY+PDzw9PTWZjYiICqBLAcdQp9x8HDodjTdPY2FkVVLqSES5JhNCCHVmePr0KVq0aAFtbW2Eh4fD1dUV4eHhsLS0xOnTp2FlZZVXWTUiPj4eZmZmiIuLg6mpqdRxiIgKlV/6+GHC1heY5WmEib9NhZaOttSRqJjIq99vtQshAEhMTMSOHTsQEhIChUKBunXronfv3iqDpwsqFkJEROp7cTsSpaqWQ+j2kxAKBer2bil1JCpmCkwhdPr0abi7u0NHR3WcdVpaGs6fP4+mTZtqLFxeYCFERKSeraP8MXr1Qxzb0AL1B3pIHYeKqbz6/VZ7jFCLFi3w8uXLTO1xcXFo0aKFRkIREZH04iKfo7fDRIz3f4BN06uxCKIiSe3T54UQkMlkmdpjY2NhZGSkkVBERCS9yztO4+U7BW5cHQYb5/JSxyHKEzkuhL788ksA/50lNmDAAOjp6SlfS09Px/Xr1+Hu7q75hERElG9SE5Iw22MBmndyRqsp3fDFpC95gUQq0nJcCJmZmQH4r0fIxMREZWC0XC5HgwYNMHToUM0nJCKifBEeFILeXbcgKV2GnhNtAYBFEBV5OS6EAgICAAAODg6YNGkSD4MRERUh909eQ12PfRha1wALjk+HfgneQJuKh1ydPl+Y8awxIqL/iQ1/jJi7UXBq44Jru8+gdo9mUkciylJe/X6rPVgaAPbs2YNdu3YhMjISKSkpKq9duXJFI8GIiChv/blwD/p7X0KP2jpY2q4eiyAqltQ++Lt8+XIMHDgQVlZWCA0NRf369WFhYYH79++jXbt2eZGRiIg0KDUhCZNcZ6DL1FD4fGOHJZfnSR2JSDJqF0KrVq3CL7/8ghUrVkAul2PKlCkICgrC2LFjERcXlxcZiYhIQ4RCAW25LlLTFAgJ7IJhW8ZzQDQVa2p/+iMjI5WnyRsYGODNmzcAgL59+2L79u2aTUdERBohFAqs7L4YbUp5QaYlw09XfVG5XT2pYxFJTu1CyMbGBrGxsQAAe3t7XLx4EQAQERGBYjbumoioUHh2MwIdbCbix33PMGNmC/YAEb1H7cHSLVu2xKFDh1C3bl0MHjwYEyZMwJ49exAcHKy86CIRERUc/Zr/hJKGWrgW7oWSjrZSxyEqUNQ+fV6hUEChUChvurpr1y6cPXsWFStWxIgRIyCXy/MkqKbw9HkiKg4SX8Zj07frMWzzOMQ/joFpGUv2BFGhVmDuPv8xT548QenSpTW1uDzBQoiIirqrO0+hV7/fUEKuwJFb02FWzkrqSESfrcDcfT4r0dHR+Pbbb1GxYkVNLI6IiHJpw8DlaNTzGHq4m+H0i4Usgog+IceF0OvXr9G7d2+UKlUKdnZ2WL58ORQKBWbOnIny5cvj4sWL2LBhQ15mJSKibMRFPgcAVG1YCX+uaQyfEz7Q0S/YQxWICoIcD5aePn06Tp8+jf79++Po0aOYMGECjh49iqSkJBw5cgTNmvGKpEREUtg7eQOGLbmDY5tao+EwXtiWSB05LoR+//13BAQEoFWrVhg1ahQqVqwIJycn+Pn55WE8IiLKztvolxjX1Bf77+pgzfhKcOnzhdSRiAqdHBdCT58+RbVq1QAA5cuXh76+PoYMGZJnwYiI6ONO+R9BxItUXLswCGXdqkodh6hQynEhpFAooKurq3yura0NIyOjPAlFRERZS09JxQ/tf0CzrnXQflZveM78hqfFE32GHBdCQggMGDAAenp6AICkpCSMGDEiUzG0b98+zSYkIiIAwIOzN9G3/Tq8SNKG5yBjAGARRPSZcvwX1L9/f1hZWcHMzAxmZmbo06cP7OzslM8zHupatWoVHB0doa+vDxcXF5w5c+aj0ycnJ2PGjBmwt7eHnp4eKlSowLPViKjICw8KQe0mW1GjjB6uPJmJOt80lzoSUZGQ4x6hgIAAja98586dGD9+PFatWoVGjRphzZo1aNeuHcLCwlCuXLks5+nevTuePXuG9evXo2LFinj+/DnS0tI0no2IqCB4/fAZXj18hopf1EGg/zO4D/eUOhJRkaLRK0ury83NDXXr1sXq1auVbVWrVkWXLl3g6+ubafqjR4+iZ8+euH//PszNzXO1Tl5ZmogKizMrDqHP+NP40lkHy65k/k4kKk4K9JWlcyMlJQUhISHw8PBQaffw8MD58+eznOfgwYNwdXXFwoULUbp0aTg5OWHSpElITEzMj8hERPkiNSEJ3zWeibbfXsTEzqWw5NI8qSMRFVlq331eU2JiYpCeng5ra2uVdmtra0RHR2c5z/3793H27Fno6+tj//79iImJwahRo/Dy5ctsxwklJycjOTlZ+Tw+Pl5zG0FEpGFCoYBMSwvRLxLx974uqNG1kdSRiIo0yU83kMlkKs+FEJnaMigUCshkMmzduhX169eHp6cnli5dio0bN2bbK+Tr66symLts2bIa3wYios8lFAqsH7AcX5aZCG25Dtb9u4hFEFE+kKwQsrS0hLa2dqben+fPn2fqJcpga2uL0qVLq5ydVrVqVQgh8Pjx4yzn8fb2RlxcnPLx6NEjzW0EEZEGxIY/Rreyk/Dd5scY+W1DnhJPlI9y9de2efNmNGrUCHZ2dnj48CEAwM/PD7/99luOlyGXy+Hi4oKgoCCV9qCgILi7u2c5T6NGjfD06VO8fftW2Xbnzh1oaWmhTJkyWc6jp6cHU1NTlQcRUUHSw20x0hUCN8K+hYd3d6njEBUrahdCq1evhpeXFzw9PfH69Wukp6cDAEqUKKH2fce8vLywbt06bNiwAbdv38aECRMQGRmJESNGAPivN6dfv37K6Xv16gULCwsMHDgQYWFhOH36NCZPnoxBgwbBwMBA3U0hIpJMcvw7bBm5GkKhwPZzXtj/ZAksK/PQPVF+U7sQ+vnnn7F27VrMmDED2traynZXV1fcuHFDrWX16NEDfn5+mDNnDmrXro3Tp08jMDAQ9vb2AICoqChERkYqpzc2NkZQUBBev34NV1dX9O7dGx07dsTy5cvV3QwiIsnc+u083Ky/g9+mO3jzNBalqpbj4TAiiah9HSEDAwP8888/sLe3h4mJCa5du4by5csjPDwczs7OBf5Udl5HiIik9OvQlRi17inGNdTCrGPTITdmbzZRThSY6wg5Ojri6tWrmdqPHDmivDs9ERGpSoiJAwDYVy+NQL/6WHB+LosgogJA7esITZ48GaNHj0ZSUhKEELh06RK2b98OX19frFu3Li8yEhEVar/P2orBc6/j6DZPNB/fReo4RPQetQuhgQMHIi0tDVOmTEFCQgJ69eqF0qVL46effkLPnj3zIiMRUaGU+DIek5svwOYbWvh5aDnU+rqJ1JGI6AO5urL00KFDMXToUMTExEChUMDKykrTuYiICr2jP+5D6IMkXD01CI5NnaWOQ0RZUHuM0OzZs3Hv3j0A/10UkUUQEdH/KNLSsaSjL4I3/YmuPw7A6ZhFLIKICjC1C6G9e/fCyckJDRo0wIoVK/DixYu8yEVEVOg8Cb4DD6uJWHU0Fhkn5GrLdSVORUQfo3YhdP36dVy/fh0tW7bE0qVLUbp0aXh6emLbtm1ISEjIi4xERAXenT+C4Vx/A8pa6ODqQ2/U699a6khElANqX0foQ+fOncO2bduwe/duJCUlFfi7u/M6QkSkSW+jXyLucQxsa1fAiWUH8MXkr6SORFQkFZjrCH3IyMgIBgYGkMvlSE1N1UQmIqJC4VLAMdQpNx+LhgZAS0ebRRBRIZSrQigiIgLz589HtWrV4OrqiitXrmDWrFmZ7iRPRFQUpaekYn7ruWg+6DSGtjLHkr/nSB2JiHJJ7dPnGzZsiEuXLqFmzZoYOHCg8jpCRETFRVpSCm78+wpnt3RA3d4tpY5DRJ9B7UKoRYsWWLduHapXr54XeYiICqyto/xx5Eg4Nt9bhB2RS6WOQ0QaoHYhtGDBgrzIQURUYL1++Ayjmy3EsUhdbJhRm3eKJypCclQIeXl5Ye7cuTAyMoKXl9dHp126lP9KIqKipWttX+hpy3Dj6jDYOJeXOg4RaVCOCqHQ0FDlGWGhoaF5GoiIqCBITUjC4dk70PXHAdgSNAq2tStAS0db6lhEpGGffR2hwobXESKiTwkPCkHvrluQlC7DuXszYGJnIXUkomKvwFxHaNCgQXjz5k2m9nfv3mHQoEEaCUVEJJVto/1R12MfGjnp41LUHBZBREWc2oXQr7/+isTExEztiYmJ2LRpk0ZCERHlt+T4dwCAktZm2DPPGcuu+EK/hLHEqYgor+X4rLH4+HgIISCEwJs3b6Cvr698LT09HYGBgbwTPREVSn8u3INB0//G4R2d0G7mN1LHIaJ8lONCqESJEpDJZJDJZHBycsr0ukwmw+zZszUajogoLyXHv8OMlgvgHwIs7V0aNb9sJHUkIspnOS6ETpw4ASEEWrZsib1798Lc3Fz5mlwuh729Pezs7PIkJBFRXtj/3VacvJ2AkMBeqNyuntRxiEgCap819vDhQ5QrVw4ymSyvMuUpnjVGVLwJhQKrei5F897uqNaxAdKSUqBrqP/pGYlIUnn1+52jHqHr16+jRo0a0NLSQlxcHG7cuJHttM7OzhoLR0SkSc9uRmBQy+W48VIHLh7xkGlpsQgiKuZyVAjVrl0b0dHRsLKyQu3atSGTyZBVR5JMJkN6errGQxIRfa5/j1xGk/Z70LKMDNfCvVDS0VbqSERUAOSoEIqIiECpUqWU/09EVFgkxMTh7bNXqNCiFtbP+AcdZvfmvcKISIlXliaiIuvqzlPo1e83tKmuh2VXfKWOQ0SfocBcWfrXX3/F77//rnw+ZcoUlChRAu7u7nj48KHGghER5ZYiLR2LO/iiUc9j6NnIDIvO89IeRJQ1tQuhBQsWwMDAAABw4cIFrFixAgsXLoSlpSUmTJig8YBEROpKjn+HU5ef4/jaJpj5lw909OVSRyKiAirH1xHK8OjRI1SsWBEAcODAAXTr1g3Dhg1Do0aN0Lx5c03nIyLKsX1TAhD0+z9YfetHHHq2TOo4RFQIqN0jZGxsjNjYWADAsWPH0KpVKwCAvr5+lvcgIyLKa2+jX2Kw02QMXnwHLTwqSR2HiAoRtXuEWrdujSFDhqBOnTq4c+cO2rdvDwC4desWHBwcNJ2PiOiTOladAwC4fmEQyrpVlTgNERUmavcIrVy5Eg0bNsSLFy+wd+9eWFhYAABCQkLwzTe8WSER5Y/0lFT8MX8nAGDDb4Pw57NFLIKISG08fZ6ICp0HZ2+ij+c6xCZrIfjR9zCyKil1JCLKY5LeYuNDr1+/xvr163H79m3IZDJUrVoVgwcPhpmZmcaCERFlZdeEdRjqdx+9qulhyanpMLTk9w4R5Z7ah8aCg4NRoUIFLFu2DC9fvkRMTAyWLVuGChUq4MqVK3mRkYgIaUkpAAAdXW1snl4Vq2/9yCKIiD6b2ofGmjRpgooVK2Lt2rXQ0fmvQyktLQ1DhgzB/fv3cfr06TwJqik8NEZU+JxZcQiDvE7itz1fo1qnBlLHISIJFJhDY8HBwSpFEADo6OhgypQpcHV11VgwIqLUhCTM9liAZefS4fulNap41pM6EhEVMWoXQqampoiMjESVKlVU2h89egQTExONBSMi2uG1AQdD3uLini9R86vGUschoiJI7UKoR48eGDx4MBYvXgx3d3fIZDKcPXsWkydP5unzRPTZhEKBgMEr0KRXI/ReMRxf/5AI/RLGUscioiJK7UJo8eLFkMlk6NevH9LS0gAAurq6GDlyJH744QeNBySi4iM2/DGGNluCC890sad+NCq11mYRRER5KtfXEUpISMC9e/cghEDFihVhaGio6Wx5goOliQqmf49cRssOu1HPKhXrTnrBsnJZqSMRUQGSV7/fOT59PiEhAaNHj0bp0qVhZWWFIUOGwNbWFs7OzoWmCCKigic5/h1eRUTBsUkNLBvrhP1PlrAIIqJ8k+NCyMfHBxs3bkT79u3Rs2dPBAUFYeTIkXmZjYiKuLCDF+Fm/R3mdvsZcmMDdF82BDIttS9vRkSUazkeI7Rv3z6sX78ePXv2BAD06dMHjRo1Qnp6OrS1tfMsIBEVPUKhwKqeSzFl9yuMbWCM2UHTpY5ERMVUjv/p9ejRIzRp0kT5vH79+tDR0cHTp0/zJBgRFV0JMXHYE/QYvy+rB98LcyE3NpA6EhEVUznuEUpPT4dcLledWUdHeeYYEdGn/D5rK04cDsPi4Pk48cpP6jhERDkvhIQQGDBgAPT09JRtSUlJGDFiBIyMjJRt+/bt02xCIir0EmLiMLnFAmy5qY2fh5aWOg4RkVKOC6H+/ftnauvTp49GwxBR0SMUCnhW9EGqArh6ahAcmzpLHYmISCnX1xEqrHgdIaL8oUhLxzn/QDQZ0xH/BF5CxZa1oaMv//SMRERZKDA3XSUi+pQnwXfQ32MVHr7VxrWeTVHFs77UkYiIssQLdhCRRh3w/hXO9TegjLkOQu5Pg6GlmdSRiIiyxR4hItIIRVo6tHS08fZ1AlaPq4juy4ZIHYmI6JNYCBHRZ7sUcAyDRx7F3t96oc9qXnGeiAoPHhojolxLT0nFvFZz0HzQafRtaYEKLWpJHYmISC25KoQ2b96MRo0awc7ODg8fPgQA+Pn54bffftNoOCIq2DaN8MeWM3E4u6UlpgTOgLZcV+pIRERqUbsQWr16Nby8vODp6YnXr18jPT0dAFCiRAn4+flpOh8RFUDbv12DyAth6Oc/AleezETd3i2ljkRElCtqF0I///wz1q5dixkzZqjcbNXV1RU3btzQaDgiKljiIp+jt8NEjF0ZgQfBd6Et1+VZYURUqKk9WDoiIgJ16tTJ1K6np4d3795pJBQRFTz/HrmMNh13okoJBa5fGQrb2hWkjkRE9NnU7hFydHTE1atXM7UfOXIE1apV00QmIipAUhOS8OZpLMq5VYZPP3sERi9mEURERYbaPUKTJ0/G6NGjkZSUBCEELl26hO3bt8PX1xfr1q3Li4xEJJHwoBD07roFzaoaYtHl+Ri44VupIxERaZTaPUIDBw6Ej48PpkyZgoSEBPTq1Qv+/v746aef0LNnT7UDrFq1Co6OjtDX14eLiwvOnDmTo/nOnTsHHR0d1K5dW+11EtHHCYUC6wcsR12PfWhc2QBzg7yljkRElCc+66arMTExUCgUsLKyytX8O3fuRN++fbFq1So0atQIa9aswbp16xAWFoZy5cplO19cXBzq1q2LihUr4tmzZ1keqssOb7pK9GlvnsaildM8zJ3REB7e3aWOQ0SUZ7/fkt593s3NDXXr1sXq1auVbVWrVkWXLl3g6+ub7Xw9e/ZEpUqVoK2tjQMHDrAQItKQPxfuwbkjt+BzwgdCoYBMi9dcJaKCocDcfd7R0REymSzb1+/fv5+j5aSkpCAkJATTpk1Taffw8MD58+eznS8gIAD37t3Dli1bMG/evE+uJzk5GcnJycrn8fHxOcpHVJwkx7/DjJYL4B8CLO1dCgBYBBFRsaB2ITR+/HiV56mpqQgNDcXRo0cxefLkHC8nJiYG6enpsLa2Vmm3trZGdHR0lvOEh4dj2rRpOHPmDHR0chbd19cXs2fPznEuouJGKBRoZz8D8SkyhAT2QuV29aSORESUb9QuhMaNG5dl+8qVKxEcHKx2gA97l4QQWfY4paeno1evXpg9ezacnJxyvHxvb294eXkpn8fHx6Ns2bJq5yQqaoRCgZAtf8G1Xyss9e+Kau3rQ25sIHUsIqJ8pbG+73bt2mHv3r05nt7S0hLa2tqZen+eP3+eqZcIAN68eYPg4GCMGTMGOjo60NHRwZw5c3Dt2jXo6Ojgr7/+ynI9enp6MDU1VXkQFXfPbkagg81EdB98FIkv41G7RzMWQURULGmsENqzZw/Mzc1zPL1cLoeLiwuCgoJU2oOCguDu7p5pelNTU9y4cQNXr15VPkaMGIHKlSvj6tWrcHNz++xtICoOAmdvQ01nf5joyxByZyIMzPmPAyIqvtQ+NFanTh2VQ1dCCERHR+PFixdYtWqVWsvy8vJC37594erqioYNG+KXX35BZGQkRowYAeC/w1pPnjzBpk2boKWlhRo1aqjMb2VlBX19/UztRJRZxllgj8OfY8kwe/RZNYIDoomo2FO7EOrSpYvKcy0tLZQqVQrNmzdHlSpV1FpWjx49EBsbizlz5iAqKgo1atRAYGAg7O3tAQBRUVGIjIxUNyIRfeDqzlMYNvgAdhwegGFbxksdh4iowFDrOkJpaWnYunUr2rRpAxsbm7zMlWd4HSEqThRp6VjaZSF8fn+LKc3lmHHEGzr6cqljERGpLa9+v9XqF9fR0cHIkSNVrstDRAXXhsErsPqPWPy5pjF8TviwCCIi+oDaAwTc3NwQGhqaF1mISEP2T92IqKv30H/1cIRGTEXDYe2kjkREVCCpPUZo1KhRmDhxIh4/fgwXFxcYGRmpvO7s7KyxcESknrfRLzGuqS/23dXBftsSsK1dAbqG+lLHIiIqsHI8RmjQoEHw8/NDiRIlMi9EJlNeCDE9PV3TGTWKY4SoqLrzRzDad9yOMkbp2HR0OMq6VZU6EhGRxkh+01VtbW1ERUUhMTHxo9NlnPFVULEQoqImPSUVyfEJUKSlY9P4AAzfNBbacl2pYxERaZTkN13NqJcKeqFDVJw8OHsTfduvQ6Oqxvjh4jyM2jFR6khERIWKWoOlP3bXeSLKX1tH+aN2k62oUUYP3x9kAURElBtqDZZ2cnL6ZDH08uXLzwpERJ8WF/kcvhvuYNP0Oug0v6/UcYiICi21CqHZs2fDzMwsr7IQ0SecWXEIfx+9iUmHvXH97SJo6WhLHYmIqFBTqxDq2bMnrKys8ioLEWUjNSEJsz0WYNm5dPzwVQkAYBFERKQBOS6EOD6ISBpCoUC7MtPwPFELf+/7CjW6NpI6EhFRkZHjwdJq3JKMiDRAKBS49dt5yLS0MH9RO1yKmsMiiIhIw3LcI6RQKPIyBxG9Jzb8MYY1X4orz7XwT2wtuA1uI3UkIqIiSe17jRFR3jq+aC+cqyxHukLg8s1x0DM1+vRMRESUK2rfa4yI8tb1c+Hw+cYOQzeNhUyL/1YhIspLLISICoBbv53HqP67sPnIMEw4ME3qOERExQb/uUkkIaFQYMXXi1C/y+9oVM0ENjUdpY5ERFSssEeISEK/9P0JC/c/R6BfYzQb11nqOERExU6O7z5fVPDu81QQHJ23A/V6NIZRqRJIfPUGJR1tpY5ERFSg5dXvNw+NEeWjxJfxGOM8DT2+v47rhy5Dv4QxiyAiIgnx0BhRPgkPCkHnDltRUk+Bq6cGwbGps9SRiIiKPRZCRHlMkZaO1IQklHIqg0GtS2H8nonQ0ZdLHYuIiMBDY0R56knwHXhYTcRczx9Rwt4akw57swgiIipAWAgR5ZG9kzegZv0AlLXQwdRd46SOQ0REWeChMaI88PrhM0z1u4U146vh66WDpY5DRETZYCFEpEGXAo4h5NgNjNw+Ef+88eVhMCKiAo6Hxog0ID0lFfNbz0XzQaeR8DYFAFgEEREVAuwRIvpMQqGAp91kPHyjjTObPeHS5wupIxERUQ6xECL6DPf+uooKLWvD+7vmqNerGYysSkodiYiI1MBCiCgXXj98htHNFuLcYxnuvK6M5uO7SB2JiIhygWOEiNR0ZsUh1KqwGLFvFbh4ZRTkxgZSRyIiolxiIUSkplMHQjGxcykERi+GjXN5qeMQEdFn4KExohwIDwrBuN5bsO7oKHz350yp4xARkYawR4joI4RCgfUDlqOuxz5UKWsA8/K8UzwRUVHCHiGij1jTxw+zd0ZjzzwXtJnRQ+o4RESkYTIhhJA6RH6Kj4+HmZkZ4uLiYGpqKnUcKqBOLN2Put0aQUdfFwmxb1CqajmpIxERFWt59fvNHiGi9yTHv8OMlgvgHwL8lq7AF5O/4rWBiIiKMBZCRP/v3l9X8VX7X6GjBYQE9kLldvWkjkRERHmMhRAVe0KhQFpSCkxtzfGVe0lM/W0yrw1ERFRM8KwxKtae3YxAB5uJWND+R5SqWg7fH5/JIoiIqBhhIUTF1u+ztqKmsz9M9GUYu2GY1HGIiEgCPDRGxdLLe08xfO5VLBnmiD6rRkCmxX8TEBEVRyyEqFi5uvMUrv15E/3Xjsa9V7OgZ2okdSQiIpIQ/xlMxYIiLR2LO/iiUc9jePLwJQCwCCIiIvYIUdEnFAp0sJuEf19p4881X6DhsHZSRyIiogKChRAVaY8v/4sy9Srj2zH10XiIB0zsLKSOREREBQgPjVGR9Db6JQY7TUbjhmuR8jYR7WZ+wyKIiIgyYSFERc6lgGOoU24+7r9IxZlzg3ldICIiyhYPjVGRs/+XMxjayhwTD0yBtlxX6jhERFSAsRCiIuHB2ZuY1HMDVgeNh++FuVLHISKiQoKHxqjQ2zrKH7WbbEUpM10YWphIHYeIiAoR9ghRoebfaym+3/Ecm6ZXR6f5faWOQ0REhYxMCCGkDpGf4uPjYWZmhri4OJiamkodh3Lp/JpA1OraEGlJqUh4+Qa2tStIHYmIiPJQXv1+s0eICpXUhCTM9liAZefScehtElpO/BJm5aykjkVERIUUCyEqNCJOX0cPzwAkpcvw976vUKNrI6kjERFRIcdCiAo8oVBAkZYOPWMDfFHTGD5HpkK/hLHUsYiIqAjgWWNUoMWGP8ZXZSZiYccfYVe3EnwvzGURREREGsNCiAqsPxfugXOV5VAIYOjy/lLHISKiIoiHxqhAivn3EXpPu4y5vewwdNNYyLRYsxMRkeZJ/uuyatUqODo6Ql9fHy4uLjhz5ky20+7btw+tW7dGqVKlYGpqioYNG+KPP/7Ix7SU1279dh67JqyDZeWyuB89DcO2jGcRREREeUbSX5idO3di/PjxmDFjBkJDQ9GkSRO0a9cOkZGRWU5/+vRptG7dGoGBgQgJCUGLFi3QsWNHhIaG5nNy0jShUGBl98Wo3+V33L76BABgZFVS4lRERFTUSXpBRTc3N9StWxerV69WtlWtWhVdunSBr69vjpZRvXp19OjRAzNnzszR9LygYsGjSEtH17KTEPpCB5uXNEazcZ2ljkRERAVMXv1+S9YjlJKSgpCQEHh4eKi0e3h44Pz58zlahkKhwJs3b2Bubp7tNMnJyYiPj1d5UMHx4nYktHS00a9PTVwL92IRRERE+UqyQigmJgbp6emwtrZWabe2tkZ0dHSOlrFkyRK8e/cO3bt3z3YaX19fmJmZKR9ly5b9rNykGYkv4zHGeRrqOy9HakISvlo0CCUdbaWORURExYzko1BlMpnKcyFEprasbN++HbNmzcLOnTthZZX9LRa8vb0RFxenfDx69OizM9PnubrzFFxsZyH0QRL+Ot4Puob6UkciIqJiSrLT5y0tLaGtrZ2p9+f58+eZeok+tHPnTgwePBi7d+9Gq1atPjqtnp4e9PT0PjsvaU6A71H0bGSG6YHe0NGXSx2HiIiKMcl6hORyOVxcXBAUFKTSHhQUBHd392zn2759OwYMGIBt27ahffv2eR2TNORJ8B30qzAJrx8+g9+V+Zj5lw+LICIikpykh8a8vLywbt06bNiwAbdv38aECRMQGRmJESNGAPjvsFa/fv2U02/fvh39+vXDkiVL0KBBA0RHRyM6OhpxcXFSbQLlwN7JG+BcfwO0tQBtXR1eF4iIiAoMSa8s3aNHD8TGxmLOnDmIiopCjRo1EBgYCHt7ewBAVFSUyjWF1qxZg7S0NIwePRqjR49Wtvfv3x8bN27M7/iUA/69lsJ7xwusGVcR3ZcNkToOERGRCkmvIyQFXkcof1zZ+heqta+Pt89eIfH1W5R1qyp1JCIiKsSK3HWEqGhKT0nFvFZz0LjPXzi//hgsK5dlEURERAUWb7pKGhN5IQy92/6CF0naOLulPer2bil1JCIioo9iIUQaIRQKKNIVcClvgAVB02BoaSZ1JCIiok9iIUSf5fXDZxjdbCFcapWC12/T4Beas3vEERERFQQcI0S5dmbFIdSusAixbxXoNTf725wQEREVVCyEKFde3I5E57Hn4dXZCoHRi2HjXF7qSERERGrjoTFSS3hQCO6c+wftZ/VGxIMJMCuX/X3eiIiICjr2CFGOCIUC6wcsR12Pfbjw578AwCKIiIgKPfYI0Scp0tLRw2EyzkbpYO8CV3h4czwQEREVDSyE6KPiIp/DrJwVOnWoiNUTOsKyclmpIxEREWkMD41RlpLj32Gi63S4VPgRaUkp6Os/ikUQEREVOewRokzCDl5Erx47oaMFBB7uDR19udSRiIiI8gQLIcrEb+o+eNYxxqxj0yE3NpA6DhERUZ5hIUQAgGc3IzCrhz8WHZ+KNbd+gEyLR02JiKjo468d4fdZW1HT2R+v3qQiPSWNRRARERUb7BEq5tb0XoYp215gxXB79Fk1gkUQEREVKyyEiqlbv52HU+u66DS5E1oPfYvyzWtJHYmIiCjfsRAqZhRp6VjaZSF8fn+LQ4uj0XLil1JHIiIikgwLoWLkSfAd9PNYhQdvdHB8bSs0GNJW6khERESSYiFUTAiFAm9fxKGitRwHbk6FiZ2F1JGIiIgkx0KoiHsb/RLjmvrCpa4NRu2YiDXt6kkdiYiIqMDgKUJF2KWAY6hTbj7uv0hFxwmeUschIiIqcFgIFVHPbkag9aCTGNrKHH8+W4SyblWljkRERFTg8NBYEfPg7E3cu/Avvpj8Fe6GjUCpquWkjkRERFRgsUeoCNk6yh+1mmxD0N5QAGARRERE9AnsESoC0lNS0c9pGo5F6mLLd9XRcW5fqSMREREVCiyECrmEmDgYWpqhaaMyWHKwM2ycy0sdiYiIqNDgobFCKjUhCd81ngmX0rORnpKK4VsnsAgiIiJSE3uECqHwoBD07roFSeky7Nr2JbTlulJHIiIiKpRYCBVCc0dsRyMnffj+NQP6JYyljkNERFRosRAqJGLDH2PBN6sw79g0BNz2ZS8QERGRBrAQKgT+XLgH/b0voZ5VKpLfJMLA3FTqSETFihACaWlpSE9PlzoKUZGmq6sLbW3tfF0nC6EC7pc+fpi49QWW9rXDkI1jIdPi+Hai/JSSkoKoqCgkJCRIHYWoyJPJZChTpgyMjfNv2AcLoQLq7vFQODapgbajPdCs9ztU5s1SifKdQqFAREQEtLW1YWdnB7lcDplMJnUsoiJJCIEXL17g8ePHqFSpUr71DLEQKmCEQoFVPZdiyu5X+H3ZQzQf30XqSETFVkpKChQKBcqWLQtDQ0Op4xAVeaVKlcKDBw+QmprKQqg4enYzAoNaLseNlzoI9GuMZuM6Sx2JiABo8ZA0Ub6QoseVhVAB8uyfxzA31sK1v71Q0tFW6jhERERFHgshiSXExGFyiwVwrVcGAzd8i83dmkgdiYiIqNhgf6+Eru48BdfSs3H1YTKaD2gmdRwiomIvNjYWVlZWePDggdRRipwVK1agU6dOUsfIhIWQRKKu3kOTnsfQs5EZTj1fCMemzlJHIqIiYsCAAZDJZJDJZNDR0UG5cuUwcuRIvHr1KtO058+fh6enJ0qWLAl9fX3UrFkTS5YsyfKaSSdOnICnpycsLCxgaGiIatWqYeLEiXjy5El+bFa+8PX1RceOHeHg4CB1lDxz6tQpuLi4QF9fH+XLl4e/v/8n58n4PL3/+HC+GzduoFmzZjAwMEDp0qUxZ84cCCGUrw8dOhSXL1/G2bNnNb5Nn4OFUD57EnwH51b/DtvaFXD7Uj/M/MsHOvpyqWMRURHTtm1bREVF4cGDB1i3bh0OHTqEUaNGqUyzf/9+NGvWDGXKlMGJEyfwzz//YNy4cZg/fz569uyp8iO2Zs0atGrVCjY2Nti7dy/CwsLg7++PuLg4LFmyJN+2KyUlJc+WnZiYiPXr12PIkCGftZy8zPi5IiIi4OnpiSZNmiA0NBTTp0/H2LFjsXfv3k/OGxAQgKioKOWjf//+ytfi4+PRunVr2NnZ4fLly/j555+xePFiLF26VDmNnp4eevXqhZ9//jlPti3XRDETFxcnAIi4uLh8X/eeSeuFuWyq8HLxzvd1E5H6EhMTRVhYmEhMTJQ6ilr69+8vOnfurNLm5eUlzM3Nlc/fvn0rLCwsxJdffplp/oMHDwoAYseOHUIIIR49eiTkcrkYP358lut79epVtllevXolhg4dKqysrISenp6oXr26OHTokBBCCB8fH1GrVi2V6ZctWybs7e0zbcuCBQuEra2tsLe3F9OmTRNubm6Z1lWzZk0xc+ZM5fMNGzaIKlWqCD09PVG5cmWxcuXKbHMKIcTevXuFpaWlSltaWpoYNGiQcHBwEPr6+sLJyUn4+fmpTJNVRiGEePz4sejevbsoUaKEMDc3F506dRIRERHK+S5duiRatWolLCwshKmpqWjatKkICQn5aMbPNWXKFFGlShWVtuHDh4sGDRp8dD4AYv/+/dm+vmrVKmFmZiaSkpKUbb6+vsLOzk4oFApl28mTJ4VcLhcJCQlZLudjf3N59fvNHqF8kJaUgsFOkzFkSThWj6uIJcELpI5ERJ8jORmIj//fIzHxv/bERNX25OT/2t+9U23P6DF4+1a1PS3tv/b32+Ljgc+8tcf9+/dx9OhR6Or+7x6Fx44dQ2xsLCZNmpRp+o4dO8LJyQnbt28HAOzevRspKSmYMmVKlssvUaJElu0KhQLt2rXD+fPnsWXLFoSFheGHH35Q+/owx48fx+3btxEUFITDhw+jd+/e+Pvvv3Hv3j3lNLdu3cKNGzfQu3dvAMDatWsxY8YMzJ8/H7dv38aCBQvw/fff49dff812PadPn4arq2umbShTpgx27dqFsLAwzJw5E9OnT8euXbs+mjEhIQEtWrSAsbExTp8+jbNnz8LY2Bht27ZV9hi9efMG/fv3x5kzZ3Dx4kVUqlQJnp6eePPmTbYZt27dCmNj448+tm7dmu38Fy5cgIeHh0pbmzZtEBwcjNTU1GznA4AxY8bA0tIS9erVg7+/PxQKhcpymzVrBj09PZXlPn36VGW8laurK1JTU3Hp0qWPris/8ayxPJYc/w56pkaoVtkcszZ3QVm3qlJHIqLP5esLzJ79v+eDBwPr1gHffgusX/+/dh8fYNYs4MsvgWPH/te+di0wZAjg5gaEhf2v/ehRoE0boEwZ4P0fw5s3gerV1Yp4+PBhGBsbIz09HUlJSQCgcpjizp07AICqVbP+TqpSpYpymvDwcJiamsLWVr3Levz555+4dOkSbt++DScnJwBA+fLl1VoGABgZGWHdunWQy/83jMDZ2Rnbtm3D999/D+C/AqFevXrK9cydOxdLlizBl19+CQBwdHREWFgY1qxZo3JI530PHjyAnZ2dSpuuri5mv7evHR0dcf78eezatQvdu3fPNuOGDRugpaWFdevWKa+NExAQgBIlSuDkyZPw8PBAy5YtVda1Zs0alCxZEqdOnUKHDh2yzNipUye4ubl99P2ytrbO9rXo6OhMr1tbWyMtLQ0xMTHZ7uO5c+fiiy++gIGBAY4fP46JEyciJiYG3333nXK5H46rylhPdHQ0HB0dAfz3PpUoUQIPHjxAs2YF4yQhFkJ5JD0lFb6evth17jVC437ExEPeUkciIk3x9ga8vP73PKOn5eefgfeKDWT863jfPtVeHX39//7799/Ae/+qRsbVqx8/Vl2fkZHaEVu0aIHVq1cjISEB69atw507d/Dtt99mmk68Nw7ow/aMH/D3/18dV69eRZkyZZTFSW7VrFlTpQgCgN69e2PDhg34/vvvIYTA9u3bMX78eADAixcv8OjRIwwePBhDhw5VzpOWlgYzM7Ns15OYmAj9jH3zHn9/f6xbtw4PHz5EYmIiUlJSULt27Y9mDAkJwd27d2FiYqIyXVJSkrIn6/nz55g5cyb++usvPHv2DOnp6UhISEBkZGS2GU1MTDItU10f7suMz8DH9nFGwQNAue1z5sxRac/pcg0MDArUvftYCOWBB2dvoo/nOsQka2Pbhg7Qlut+eiYiKjz09P5X5LzPwOC/x4eyK2Syu7GkqWnusylXaYSKFSsCAJYvX44WLVpg9uzZmDt3LgAoi5Pbt2/D3d090/z//PMPqlWrppw2Li4OUVFRavUKGWT1XrxHS0srUyGW1eEZoyzev169emHatGm4cuUKEhMT8ejRI/Ts2RMAlIds1q5dm6n35GOH5SwtLTOdWbdr1y5MmDABS5YsQcOGDWFiYoJFixbh77///mhGhUIBFxeXLA9TlSpVCsB/Z/e9ePECfn5+sLe3h56eHho2bPjRwdZbt27F8OHDs30d+K9nKeMQ4YdsbGwQHR2t0vb8+XPo6OjAwsLio8t9X4MGDRAfH49nz57B2to62+UCmXuoXr58qXwPCgIWQnlgaq8NqFlWD0tOTYehZfb/+iAiyi8+Pj5o164dRo4cCTs7O3h4eMDc3BxLlizJVAgdPHgQ4eHhyqKpW7dumDZtGhYuXIhly5ZlWvbr16+zHCfk7OyMx48f486dO1n2CpUqVQrR0dEqPU5Xr17N0faUKVMGTZs2xdatW5GYmIhWrVopf3Ctra1RunRp3L9/P9uCICt16tTBli1bVNrOnDkDd3d3lTPu3h+blJ26deti586dsLKygmk2he2ZM2ewatUqeHp6AgAePXqEmJiYjy73cw+NNWzYEIcOHVJpO3bsGFxdXVXGkH1KaGgo9PX1lfu9YcOGmD59OlJSUpQ9Y8eOHYOdnZ3KIbN79+4hKSkJderUyfG68pxGh14XAnk16vz1w2fi+yYzRfKbBJHyrnCdYUJEWStKZ40JIYSLi4sYPXq08vnu3buFtra2GDp0qLh27ZqIiIgQ69atEyVLlhTdunVTOdtn5cqVQiaTiUGDBomTJ0+KBw8eiLNnz4phw4YJLy+vbLM0b95c1KhRQxw7dkzcv39fBAYGiiNHjgghhAgLCxMymUz88MMP4u7du2LFihWiZMmSWZ41lpVffvlF2NnZCUtLS7F582aV19auXSsMDAyEn5+f+Pfff8X169fFhg0bxJIlS7LNev36daGjoyNevnypbPPz8xOmpqbi6NGj4t9//xXfffedMDU1VTnbLauM7969E5UqVRLNmzcXp0+fFvfv3xcnT54UY8eOFY8ePRJCCFG7dm3RunVrERYWJi5evCiaNGkiDAwMxLJly7LN+Lnu378vDA0NxYQJE0RYWJhYv3690NXVFXv27FFOs2/fPlG5cmXl84MHD4pffvlF3LhxQ9y9e1esXbtWmJqairFjxyqnef36tbC2thbffPONuHHjhti3b58wNTUVixcvVll/QECAKF++fLb5pDhrjIWQBpz++aCw154o2liMFy/vP9XYcolIWkWtENq6dauQy+UiMjJS2Xb69GnRtm1bYWZmJuRyuahWrZpYvHixSEtLyzR/UFCQaNOmjShZsqTQ19cXVapUEZMmTRJPn2b/vRcbGysGDhwoLCwshL6+vqhRo4Y4fPiw8vXVq1eLsmXLCiMjI9GvXz8xf/78HBdCr169Enp6esLQ0FC8efMmy+2tXbu2kMvlomTJkqJp06Zi37592WYVQogGDRoIf39/5fOkpCQxYMAAYWZmJkqUKCFGjhwppk2b9slCSAghoqKiRL9+/YSlpaXQ09MT5cuXF0OHDlX+/ly5ckW4uroKPT09UalSJbF7925hb2+fp4WQEP+dwl6nTh0hl8uFg4ODWL16tcrrAQEB4v1+kiNHjojatWsLY2NjYWhoKGrUqCH8/PxEamqqynzXr18XTZo0EXp6esLGxkbMmjVLpZgWQggPDw/h6+ubbTYpCiGZENmMlCui4uPjYWZmhri4uGy7K9Wxtp8fxm9+Ad8vzTBm50Ro6ah3WigRFVxJSUmIiIiAo6NjloNoqegJDAzEpEmTcPPmTWhp8QozmnTz5k188cUXuHPnTraD1j/2N6fp3+8MHCOUS5EXwlCmXmW06N8Mf3dNQI2ujaSOREREn8nT0xPh4eF48uQJypYtK3WcIuXp06fYtGnTR8/ckwILITUJhQIbBq3A+F+f4bBffTQb11nqSEREpEHjxo2TOkKR9OGFHAsKFkJqiA1/jKHNluDCM13sXeDKIoiIiKiQYyGkhvvnb0NLS4YbYd/CsjK7TImIiAo7FkKfkBz/DjNaLoCruz16Lh+GPf1bSx2JiPJZMTunhEgyUvytcUj8R4QdvAg36+9w8nYC6rQrQBd/IqJ8kXGBuYJ0OwCioizjqtrq3pj3c7BHKBtPgu/ArfMhfNvQGLOOTYfc+OOXiieiokdbWxslSpRQ3irA0NAwV/fcIqJPUygUePHiBQwNDaGjk3/lCQuhDzy7GYHHV+/Dpc8XCP2zGyp+wZ4gouLMxsYGwP/um0REeUdLSwvlypXL139wsBB6z+GZWzBo3g30qqUFlz5fsAgiIshkMtja2sLKyirLG4ISkebI5fJ8v5Cl5IXQqlWrsGjRIkRFRaF69erw8/NDkyZNsp3+1KlT8PLywq1bt2BnZ4cpU6ZgxIgRn5UhLSkF4+p9j803tbFyuD36rPq85RFR0aOtrZ2v4xaIKH9IOlh6586dGD9+PGbMmIHQ0FA0adIE7dq1Q2RkZJbTR0REwNPTE02aNEFoaCimT5+OsWPHYu/evbnOkJaUAm25DqxLGeLqiR7o6z8KMl5WnYiIqFiQ9F5jbm5uqFu3LlavXq1sq1q1Krp06QJfX99M00+dOhUHDx7E7du3lW0jRozAtWvXcOHChRytM+NeJa9iX2JdP3/sOvkcF18v5j3CiIiICrC8uteYZF0fKSkpCAkJyXTJbQ8PD5w/fz7LeS5cuJBp+jZt2iA4OFjtY/ddKkzH6j9i8dNSDxZBRERExZRkY4RiYmKQnp4Oa2trlXZra2tER0dnOU90dHSW06elpSEmJga2traZ5klOTkZycrLyeVxcHACglJkCWy+OgYmtOeLj4z93c4iIiCgPZfxWa/pAluSDpT88RU4I8dHT5rKaPqv2DL6+vpg9e3am9j0Pf8GeKr+oG5eIiIgkFBsbq9E72EtWCFlaWkJbWztT78/z588z9fpksLGxyXJ6HR0dWFhYZDmPt7c3vLy8lM9fv34Ne3t7REZGavSNpNyJj49H2bJl8ejRI40e8yX1cV8UHNwXBQf3RcERFxeHcuXKwdzcXKPLlawQksvlcHFxQVBQELp27apsDwoKQufOWd/VvWHDhjh06JBK27Fjx+Dq6qq8FP6H9PT0oKenl6ndzMyMH+oCxNTUlPujgOC+KDi4LwoO7ouCQ9PXGZL0PHEvLy+sW7cOGzZswO3btzFhwgRERkYqrwvk7e2Nfv36KacfMWIEHj58CC8vL9y+fRsbNmzA+vXrMWnSJKk2gYiIiAoxSccI9ejRA7GxsZgzZw6ioqJQo0YNBAYGwt7eHgAQFRWlck0hR0dHBAYGYsKECVi5ciXs7OywfPlyfPXVV1JtAhERERVikg+WHjVqFEaNGpXlaxs3bszU1qxZM1y5ciXX69PT04OPj0+Wh8so/3F/FBzcFwUH90XBwX1RcOTVvpD0gopEREREUuK9JIiIiKjYYiFERERExRYLISIiIiq2WAgRERFRsVUkC6FVq1bB0dER+vr6cHFxwZkzZz46/alTp+Di4gJ9fX2UL18e/v7++ZS06FNnX+zbtw+tW7dGqVKlYGpqioYNG+KPP/7Ix7RFn7p/GxnOnTsHHR0d1K5dO28DFiPq7ovk5GTMmDED9vb20NPTQ4UKFbBhw4Z8Slu0qbsvtm7dilq1asHQ0BC2trYYOHAgYmNj8ylt0XX69Gl07NgRdnZ2kMlkOHDgwCfn0cjvtyhiduzYIXR1dcXatWtFWFiYGDdunDAyMhIPHz7Mcvr79+8LQ0NDMW7cOBEWFibWrl0rdHV1xZ49e/I5edGj7r4YN26c+PHHH8WlS5fEnTt3hLe3t9DV1RVXrlzJ5+RFk7r7I8Pr169F+fLlhYeHh6hVq1b+hC3icrMvOnXqJNzc3ERQUJCIiIgQf//9tzh37lw+pi6a1N0XZ86cEVpaWuKnn34S9+/fF2fOnBHVq1cXXbp0yefkRU9gYKCYMWOG2Lt3rwAg9u/f/9HpNfX7XeQKofr164sRI0aotFWpUkVMmzYty+mnTJkiqlSpotI2fPhw0aBBgzzLWFyouy+yUq1aNTF79mxNRyuWcrs/evToIb777jvh4+PDQkhD1N0XR44cEWZmZiI2NjY/4hUr6u6LRYsWifLly6u0LV++XJQpUybPMhZHOSmENPX7XaQOjaWkpCAkJAQeHh4q7R4eHjh//nyW81y4cCHT9G3atEFwcDBSU1PzLGtRl5t98SGFQoE3b95o/AZ7xVFu90dAQADu3bsHHx+fvI5YbORmXxw8eBCurq5YuHAhSpcuDScnJ0yaNAmJiYn5EbnIys2+cHd3x+PHjxEYGAghBJ49e4Y9e/agffv2+RGZ3qOp32/JryytSTExMUhPT89093pra+tMd63PEB0dneX0aWlpiImJga2tbZ7lLcpysy8+tGTJErx79w7du3fPi4jFSm72R3h4OKZNm4YzZ85AR6dIfVVIKjf74v79+zh79iz09fWxf/9+xMTEYNSoUXj58iXHCX2G3OwLd3d3bN26FT169EBSUhLS0tLQqVMn/Pzzz/kRmd6jqd/vItUjlEEmk6k8F0JkavvU9Fm1k/rU3RcZtm/fjlmzZmHnzp2wsrLKq3jFTk73R3p6Onr16oXZs2fDyckpv+IVK+r8bSgUCshkMmzduhX169eHp6cnli5dio0bN7JXSAPU2RdhYWEYO3YsZs6ciZCQEBw9ehQRERHKm4VT/tLE73eR+meepaUltLW1M1Xyz58/z1Q1ZrCxsclyeh0dHVhYWORZ1qIuN/siw86dOzF48GDs3r0brVq1ysuYxYa6++PNmzcIDg5GaGgoxowZA+C/H2MhBHR0dHDs2DG0bNkyX7IXNbn527C1tUXp0qVhZmambKtatSqEEHj8+DEqVaqUp5mLqtzsC19fXzRq1AiTJ08GADg7O8PIyAhNmjTBvHnzeBQhH2nq97tI9QjJ5XK4uLggKChIpT0oKAju7u5ZztOwYcNM0x87dgyurq7Q1dXNs6xFXW72BfBfT9CAAQOwbds2HnPXIHX3h6mpKW7cuIGrV68qHyNGjEDlypVx9epVuLm55Vf0Iic3fxuNGjXC06dP8fbtW2XbnTt3oKWlhTJlyuRp3qIsN/siISEBWlqqP53a2toA/tcbQflDY7/fag2tLgQyToVcv369CAsLE+PHjxdGRkbiwYMHQgghpk2bJvr27aucPuP0uwkTJoiwsDCxfv16nj6vIerui23btgkdHR2xcuVKERUVpXy8fv1aqk0oUtTdHx/iWWOao+6+ePPmjShTpozo1q2buHXrljh16pSoVKmSGDJkiFSbUGSouy8CAgKEjo6OWLVqlbh37544e/ascHV1FfXr15dqE4qMN2/eiNDQUBEaGioAiKVLl4rQ0FDlpQzy6ve7yBVCQgixcuVKYW9vL+Ryuahbt644deqU8rX+/fuLZs2aqUx/8uRJUadOHSGXy4WDg4NYvXp1PicuutTZF82aNRMAMj369++f/8GLKHX/Nt7HQkiz1N0Xt2/fFq1atRIGBgaiTJkywsvLSyQkJORz6qJJ3X2xfPlyUa1aNWFgYCBsbW1F7969xePHj/M5ddFz4sSJj/4G5NXvt0wI9uURERFR8VSkxggRERERqYOFEBERERVbLISIiIio2GIhRERERMUWCyEiIiIqtlgIERERUbHFQoiIiIiKLRZCRKRi48aNKFGihNQxcs3BwQF+fn4fnWbWrFmoXbt2vuQhooKNhRBRETRgwADIZLJMj7t370odDRs3blTJZGtri+7duyMiIkIjy798+TKGDRumfC6TyXDgwAGVaSZNmoTjx49rZH3Z+XA7ra2t0bFjR9y6dUvt5RTmwpSooGMhRFREtW3bFlFRUSoPR0dHqWMB+O+mrlFRUXj69Cm2bduGq1evolOnTkhPT//sZZcqVQqGhoYfncbY2Fitu1Pn1vvb+fvvv+Pdu3do3749UlJS8nzdRJQzLISIiig9PT3Y2NioPLS1tbF06VLUrFkTRkZGKFu2LEaNGqVyV/MPXbt2DS1atICJiQlMTU3h4uKC4OBg5evnz59H06ZNYWBggLJly2Ls2LF49+7dR7PJZDLY2NjA1tYWLVq0gI+PD27evKnssVq9ejUqVKgAuVyOypUrY/PmzSrzz5o1C+XKlYOenh7s7OwwduxY5WvvHxpzcHAAAHTt2hUymUz5/P1DY3/88Qf09fXx+vVrlXWMHTsWzZo109h2urq6YsKECXj48CH+/fdf5TQf2x8nT57EwIEDERcXp+xZmjVrFgAgJSUFU6ZMQenSpWFkZAQ3NzecPHnyo3mIKDMWQkTFjJaWFpYvX46bN2/i119/xV9//YUpU6ZkO33v3r1RpkwZXL58GSEhIZg2bRp0dXUBADdu3ECbNm3w5Zdf4vr169i5cyfOnj2LMWPGqJXJwMAAAJCamor9+/dj3LhxmDhxIm7evInhw4dj4MCBOHHiBABgz549WLZsGdasWYPw8HAcOHAANWvWzHK5ly9fBgAEBAQgKipK+fx9rVq1QokSJbB3715lW3p6Onbt2oXevXtrbDtfv36Nbdu2AYDy/QM+vj/c3d3h5+en7FmKiorCpEmTAAADBw7EuXPnsGPHDly/fh1ff/012rZti/Dw8BxnIiKgSN59nqi469+/v9DW1hZGRkbKR7du3bKcdteuXcLCwkL5PCAgQJiZmSmfm5iYiI0bN2Y5b9++fcWwYcNU2s6cOSO0tLREYmJilvN8uPxHjx6JBg0aiDJlyojk5GTh7u4uhg4dqjLP119/LTw9PYUQQixZskQ4OTmJlJSULJdvb28vli1bpnwOQOzfv19lGh8fH1GrVi3l87Fjx4qWLVsqn//xxx9CLpeLly9fftZ2AhBGRkbC0NBQeSftTp06ZTl9hk/tDyGEuHv3rpDJZOLJkycq7V988YXw9vb+6PKJSJWOtGUYEeWVFi1aYPXq1crnRkZGAIATJ05gwYIFCAsLQ3x8PNLS0pCUlIR3794pp3mfl5cXhgwZgs2bN6NVq1b4+uuvUaFCBQBASEgI7t69i61btyqnF0JAoVAgIiICVatWzTJbXFwcjI2NIYRAQkIC6tati3379kEul+P27dsqg50BoFGjRvjpp58AAF9//TX8/PxQvnx5tG3bFp6enujYsSN0dHL/dda7d280bNgQT58+hZ2dHbZu3QpPT0+ULFnys7bTxMQEV65cQVpaGk6dOoVFixbB399fZRp19wcAXLlyBUIIODk5qbQnJyfny9gnoqKEhRBREWVkZISKFSuqtD18+BCenp4YMWIE5s6dC3Nzc5w9exaDBw9GampqlsuZNWsWevXqhd9//x1HjhyBj48PduzYga5du0KhUGD48OEqY3QylCtXLttsGQWClpYWrK2tM/3gy2QyledCCGVb2bJl8e+//yIoKAh//vknRo0ahUWLFuHUqVMqh5zUUb9+fVSoUAE7duzAyJEjsX//fgQEBChfz+12amlpKfdBlSpVEB0djR49euD06dMAcrc/MvJoa2sjJCQE2traKq8ZGxurte1ExR0LIaJiJDg4GGlpaViyZAm0tP4bIrhr165Pzufk5AQnJydMmDAB33zzDQICAtC1a1fUrVsXt27dylRwfcr7BcKHqlatirNnz6Jfv37KtvPnz6v0uhgYGKBTp07o1KkTRo8ejSpVquDGjRuoW7dupuXp6urm6Gy0Xr16YevWrShTpgy0tLTQvn175Wu53c4PTZgwAUuXLsX+/fvRtWvXHO0PuVyeKX+dOnWQnp6O58+fo0mTJp+Viai442BpomKkQoUKSEtLw88//4z79+9j8+bNmQ7VvC8xMRFjxozByZMn8fDhQ5w7dw6XL19WFiVTp07FhQsXMHr0aFy9ehXh4eE4ePAgvv3221xnnDx5MjZu3Ah/f3+Eh4dj6dKl2Ldvn3KQ8MaNG7F+/XrcvHlTuQ0GBgawt7fPcnkODg44fvw4oqOj8erVq2zX27t3b1y5cgXz589Ht27doK+vr3xNU9tpamqKIUOGwMfHB0KIHO0PBwcHvH37FsePH0dMTAwSEhLg5OSE3r17o1+/fti3bx8iIiJw+fJl/PjjjwgMDFQrE1GxJ+UAJSLKG/379xedO3fO8rWlS5cKW1tbYWBgINq0aSM2bdokAIhXr14JIVQH5yYnJ4uePXuKsmXLCrlcLuzs7MSYMWNUBghfunRJtG7dWhgbGwsjIyPh7Ows5s+fn222rAb/fmjVqlWifPnyQldXVzg5OYlNmzYpX9u/f79wc3MTpqamwsjISDRo0ED8+eefytc/HCx98OBBUbFiRaGjoyPs7e2FEJkHS2eoV6+eACD++uuvTK9pajsfPnwodHR0xM6dO4UQn94fQggxYsQIYWFhIQAIHx8fIYQQKSkpYubMmcLBwUHo6uoKGxsb0bVrV3H9+vVsMxFRZjIhhJC2FCMiIiKSBg+NERERUbHFQoiIiIiKLRZCREREVGyxECIiIqJii4UQERERFVsshIiIiKjYYiFERERExRYLISIiIiq2WAgRERFRscVCiIiIiIotFkJERERUbLEQIiIiomLr/wB4b9zLVDFkqwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing-loop;\n",
    "\n",
    "predictions = []\n",
    "probabilities = []\n",
    "truths = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(train_loader): \n",
    "        \n",
    "        # Grab graph 1 inputs\n",
    "        X_1, Y_1, EI_1  = graph_1.x, graph_1.y, graph_1.edge_index\n",
    "        B_1 = graph_1.batch\n",
    "\n",
    "        # Grab graph 2 inputs\n",
    "        X_2, Y_2, EI_2  = graph_2.x, graph_2.y, graph_2.edge_index\n",
    "        B_2 = graph_2.batch\n",
    "\n",
    "        # Compute model outputs\n",
    "        logits = model(\n",
    "            x_1=X_1, x_2=X_2, edge_index_1=EI_1, edge_index_2=EI_2,\n",
    "            batch_1=B_1, batch_2=B_2).flatten()\n",
    "\n",
    "        acc, pred, probas = binary_acc(logits, Y_1)\n",
    "\n",
    "        # Append data\n",
    "        predictions.append(pred)\n",
    "        probabilities.append(probas)\n",
    "        truths.append(Y_1)\n",
    "\n",
    "# Format\n",
    "p = np.hstack(predictions)\n",
    "t = np.hstack(truths)\n",
    "prob = np.array(torch.concat(probabilities))\n",
    "\n",
    "# AUC/ROC\n",
    "fpr, tpr, _ = roc_curve(t, prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotting\n",
    "lw = 0.8\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, \"r--\", lw=lw, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example for GCN\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91480398e29c201d85f830141776dbac7675dbf1ea4e71a85e6e607707f70528"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
