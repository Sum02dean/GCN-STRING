{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sys.path.append(\"../\")\n",
    "import sys\n",
    "from utilities.gcn_utills import *\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import networkx as nx\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.utils import convert\n",
    "from torch_geometric.data import InMemoryDataset, download_url, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from utilities.gcn_utills import GraphMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define useful methods and objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMaker:\n",
    "    \"\"\"\n",
    "    Main class to generate graphs\n",
    "    \"\"\" \n",
    "    def __init__(self, anndata_path='./adata.csv'):\n",
    "        self.anndata_path = anndata_path\n",
    "        self.anndata = pd.read_csv(anndata_path, sep='\\t')\n",
    "        self.D = {}\n",
    "   \n",
    "    def collect_data(self, x):\n",
    "        \"\"\"Call as a lambda function on each row of a pandas data frame.\n",
    "        Remeber to instantaite D = {} as as a global var in the main script.\n",
    "\n",
    "        :param x: each row of a pandas.core.DataFrame\n",
    "        :type x: list\n",
    "        \"\"\"\n",
    "\n",
    "        # Feature lists\n",
    "        dca_score = []\n",
    "        pos_1 = []\n",
    "        pos_2 = []\n",
    "\n",
    "        # Grab name\n",
    "        name_1 = x[0]\n",
    "        name_2 = x[1]\n",
    "        combined_name = \"and\".join([name_1, name_2])\n",
    "        \n",
    "        # Extract dca scores and positions\n",
    "        for i in range(2, len(x), 3):\n",
    "            dca_score.append(x[i])\n",
    "            pos_1.append(x[i+1])\n",
    "            pos_2.append(x[i+2])\n",
    "\n",
    "        if combined_name not in self.D.values():\n",
    "            # Add the data to the named entry\n",
    "            self.D[combined_name] = {'dca': dca_score, 'pos_1': pos_1, 'pos_2': pos_2}\n",
    "\n",
    "            # Reset the feature lists\n",
    "            dca_score = []\n",
    "            pos_1 = []\n",
    "            pos_2 = []\n",
    "        \n",
    "    def extract_data(self, df):\n",
    "        \"\"\"Modifies a globally defined dictionary with protein names,\n",
    "        DCA values, and residue positions \n",
    "\n",
    "        :param df: Tao's new data\n",
    "        :type df: pandas.core.DataFrame\n",
    "        \n",
    "        :return: There is not return type. Global D (dict) will be modified.\n",
    "        :rtype: None\n",
    "        \"\"\"\n",
    "        _ = df.apply(lambda x : self.collect_data(x), axis=1)\n",
    "        return None\n",
    "\n",
    "    def get_position_wise_df(self, x, protein_1, protein_2):\n",
    "        \n",
    "        # Intialise D dict\n",
    "        _ = self.extract_data(x, )\n",
    "        \n",
    "        dca_dict = {}\n",
    "        protein_pair = self.D[\"and\".join([protein_1, protein_2])]\n",
    "\n",
    "        # Get the top 20 dca stats, if none available set to zero\n",
    "        pos_1 = protein_pair['pos_1']\n",
    "        pos_2 = protein_pair['pos_2']\n",
    "        dca_raw = protein_pair['dca']\n",
    "        \n",
    "        # Scale DCA values\n",
    "        dca = GM.process_dca(dca_raw, max_value=1)\n",
    "        dca_bridges = list(zip(pos_1, pos_2))\n",
    "        l = list(zip(pos_1, dca))\n",
    "        \n",
    "        for pos, score in l:    \n",
    "            if pos not in dca_dict.keys():\n",
    "                dca_dict[pos]=[score]\n",
    "            else:\n",
    "                dca_dict[pos].append(score)\n",
    "\n",
    "        # Take the max value\n",
    "        dca_dict = {}\n",
    "        for k, v in dca_dict.items():\n",
    "            dca_dict[k] = max(v)\n",
    "\n",
    "        df = pd.DataFrame({'pos_1': pos_1, 'pos_2': pos_2, 'dca': dca})\n",
    "\n",
    "        return df, dca, dca_raw, dca_bridges\n",
    "\n",
    "    def generate_alpha_fold_structures(self, string_to_af, pair_1, pair_2):\n",
    "        \"\"\"Queries alphs-fold predictions for a given protein sequnece and returns\n",
    "         alpha-fld predicted structures.\n",
    "        :param string_to_af: maping path between string-alphaFold\n",
    "        :type string_to_af: string\n",
    "        :param pair_1: protein name 1\n",
    "        :type pair_1: string\n",
    "        :param pair_2: protein name 2\n",
    "        :type pair_2: string\n",
    "        :return: alphaFold structures for each protein\n",
    "        :rtype: objects\n",
    "        \"\"\"\n",
    "\n",
    "        # Map from STRING to Alpha-Fold\n",
    "        ecoli_maps = pd.read_csv(\n",
    "            string_to_af, sep='\\t', engine='python', header=None)\n",
    "        map_1 = ecoli_maps[ecoli_maps[0] == pair_1]\n",
    "        map_2 = ecoli_maps[ecoli_maps[0] == pair_2]\n",
    "\n",
    "        # Save and import map files\n",
    "        test_file_1 = map_1.iloc[0, -1]\n",
    "        test_file_1 = test_file_1.replace('.gz', '')\n",
    "        test_file_2 = map_2.iloc[0, -1]\n",
    "        test_file_2 = test_file_2.replace('.gz', '')\n",
    "\n",
    "        # Create sloppy parser\n",
    "        sloppy_parser = PDBParser(\n",
    "            structure_builder=SloppyStructureBuilder())\n",
    "        protein_1 = sloppy_parser.get_structure(id=None, file=test_file_1)\n",
    "        protein_2 = sloppy_parser.get_structure(id=None, file=test_file_2)\n",
    "\n",
    "        # Structure 1\n",
    "        sloppyio_1 = SloppyPDBIO()\n",
    "        sloppyio_1.set_structure(protein_1)\n",
    "\n",
    "        # Structure 2\n",
    "        sloppyio_2 = SloppyPDBIO()\n",
    "        sloppyio_2.set_structure(protein_2)\n",
    "\n",
    "        # Get protein residue structures\n",
    "        residues_1 = [x for x in sloppyio_1.structure.get_residues()]\n",
    "        residues_2 = [x for x in sloppyio_2.structure.get_residues()]\n",
    "        return residues_1, residues_2\n",
    "\n",
    "    def calculate_residue_dist(self, seq_1, seq_2):\n",
    "        \"\"\"Calculates the euclidean distance between two residues in 3D space.\n",
    "        :param residue_one: reference residue\n",
    "        :type residue_one:  object\n",
    "        :param residue_two: target residue\n",
    "        :type residue_two: object\n",
    "        :return: sqaured euclidean distance\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        diff_vector = seq_1[\"CA\"].coord - seq_2[\"CA\"].coord\n",
    "        sq_dist = np.sqrt(np.sum(diff_vector * diff_vector))\n",
    "        return sq_dist\n",
    "\n",
    "    def calculate_dist_matrix(self, seq_1, seq_2):\n",
    "        \"\"\"Calculates the distance matrix for all pairwise residues\n",
    "        :param seq_1: protein sequence 1\n",
    "        :type seq_1: string\n",
    "        :param seq_2: protein sequence 2\n",
    "        :type seq_2: string\n",
    "        :return: an nd array which encodes pairwise residue distances\n",
    "        :rtype: np.array\n",
    "        \"\"\"\n",
    "        d_mat = np.zeros((len(seq_1), len(seq_2)), np.float)\n",
    "        for row, residue_one in enumerate(seq_1):\n",
    "            for col, residue_two in enumerate(seq_2):\n",
    "                euclidean_dist = self.calculate_residue_dist(\n",
    "                    residue_one, residue_two)\n",
    "                d_mat[row, col] = euclidean_dist\n",
    "        return d_mat\n",
    "\n",
    "    def generate_proximity_matrix(self, seq_1, seq_2, angstroms=10, show=False):\n",
    "        \"\"\"Creates an adacency matrix for points within n angstroms of each other\n",
    "        :param seq_1: protein sequence 1\n",
    "        :type seq_1: string\n",
    "        :param seq_2: protein sequence 2\n",
    "        :type seq_2: sting\n",
    "        :param angstroms: max distance threshold , defaults to 10\n",
    "        :type angstroms: int, optional\n",
    "        :param show: to plot matrix, defaults to False\n",
    "        :type show: bool, optional\n",
    "        :return: a proximity matrix for points considered less than n angstroms apart\n",
    "        :rtype: np.array\n",
    "        \"\"\"\n",
    "\n",
    "        # Select the residues from maps that are less than 'n' angstoms apart\n",
    "        contact_map = self.calculate_dist_matrix(seq_1, seq_2)\n",
    "        adjacency_matrix = np.zeros(np.shape(contact_map))\n",
    "        adjacency_matrix[contact_map < angstroms] = 1\n",
    "\n",
    "        if show:\n",
    "            plt.subplots(figsize=(12, 12))\n",
    "            sns.heatmap(contact_map)\n",
    "            plt.show()\n",
    "\n",
    "            plt.subplots(figsize=(12, 12))\n",
    "            sns.heatmap(adjacency_matrix)\n",
    "            plt.show()\n",
    "\n",
    "        return adjacency_matrix, contact_map\n",
    "\n",
    "    def generate_graphs(self, adjacency_matrix_1, adjacency_matrix_2, show=False):\n",
    "        \"\"\"Generates the initial graphs from provided adjacency matrices.\n",
    "        :param adjacency_matrix_1: proximity matrix for protein 1\n",
    "        :type adjacency_matrix_1: np.array\n",
    "        :param adjacency_matrix_2: proximity matrix for protein 2\n",
    "        :type adjacency_matrix_2: np.array\n",
    "        :param show: plot graphs, defaults to False\n",
    "        :type show: bool, optional\n",
    "        :return: returns networkX graphs corrresponding to each adjacency matrix\n",
    "        :rtype: tuple of networkX objects\n",
    "        \"\"\"\n",
    "        # Generate graphs\n",
    "        G_1 = nx.from_numpy_matrix(adjacency_matrix_1)\n",
    "        G_2 = nx.from_numpy_matrix(adjacency_matrix_2)\n",
    "\n",
    "        if show:\n",
    "            # Plot the graphs\n",
    "            plt.subplots(figsize=(12, 12))\n",
    "            nx.draw(G_1, with_labels=False, edge_color=\"black\",\n",
    "                    node_size=10, width=0.2)\n",
    "            plt.show()\n",
    "\n",
    "            plt.subplots(figsize=(12, 12))\n",
    "            nx.draw(G_2, with_labels=False, edge_color=\"black\",\n",
    "                    node_size=10, node_color='green', width=0.2)\n",
    "            plt.show()\n",
    "        return G_1, G_2\n",
    "\n",
    "    def populate_graph_features(self, graph_1, graph_2, protein_1, protein_2, netsurf_path_dict):\n",
    "        \"\"\" Populates each node (residue) with its respective net-surf feature vector\n",
    "\n",
    "        :param graph_1: graph for protein 1\n",
    "        :type graph_1: networkX graph object\n",
    " \n",
    "        :param graph_2: graph for protein 2\n",
    "        :type graph_2: networkX graph object\n",
    " \n",
    "        :return: graph1 and graph2 populated with node features\n",
    "        :rtype: tuple of networkX graphs\n",
    "        \"\"\"\n",
    "        # Get netsurfp features for protein 1\n",
    "        path_1 = netsurf_path_dict[protein_1]\n",
    "        x_1 = pd.read_csv(path_1)\n",
    "\n",
    "        # Get netsurfp features for protein 2\n",
    "        path_2 = netsurf_path_dict[protein_2]\n",
    "        x_2 = pd.read_csv(path_2)\n",
    "\n",
    "        # Protein-1\n",
    "        vars_to_keep = [x for x in x_1.columns if x not in [\n",
    "            'id', 'seq', 'n', 'q3', 'q8']]\n",
    "        features_p1 = x_1.loc[:, vars_to_keep]\n",
    "\n",
    "\n",
    "        # Protein-2\n",
    "        vars_to_keep = [x for x in x_2.columns if x not in [\n",
    "            'id', 'seq', 'n', 'q3', 'q8']]\n",
    "        features_p2 = x_2.loc[:, vars_to_keep]\n",
    "\n",
    "        # Populate node features before making Union on graphs\n",
    "        G_1_features = {}\n",
    "        for i, node in enumerate(graph_1.nodes):\n",
    "            feature_array = {'x': features_p1.iloc[i, :].values}\n",
    "            G_1_features[node] = feature_array\n",
    "\n",
    "\n",
    "        G_2_features = {}\n",
    "        for i, node in enumerate(graph_2.nodes):\n",
    "            feature_array = {'x': features_p2.iloc[i, :].values}\n",
    "            G_2_features[node] = feature_array\n",
    "\n",
    "        # Set the node attributes\n",
    "        nx.set_node_attributes(graph_1, G_1_features)\n",
    "        nx.set_node_attributes(graph_2, G_2_features)\n",
    "\n",
    "        return graph_1, graph_2\n",
    "\n",
    "    def link_graphs(self, graph_1, graph_2, dca_bridges, show=False):\n",
    "        \"\"\"Linkes the two protein graphs on their top 'n' DCA connections (bridges)\n",
    "        :param graph_1: graph for protein 1\n",
    "        :type graph_1: networkX graph object\n",
    "        :param graph_2: graph for protein 2\n",
    "        :type graph_2: networkX graph object\n",
    "        :param dca_bridges: dca connections\n",
    "        :type dca_bridges: list\n",
    "        :param msa_coder_1: msa-seq coder for protein 1\n",
    "        :type msa_coder_1: dict\n",
    "        :param msa_coder_2: sa-seq coder for protein 2\n",
    "        :type msa_coder_2: dict\n",
    "        :param show: to plot graphs, defaults to False\n",
    "        :type show: bool, optional\n",
    "        :return: Union of the two protein graphs    \n",
    "        :rtype: networkX graph object\n",
    "        \"\"\"\n",
    "\n",
    "        # Connect the graphs together - use map-encoder for -b\n",
    "        U = nx.union(graph_1, graph_2, rename=('a-', 'b-'))\n",
    "\n",
    "        for (b1, b2) in dca_bridges:\n",
    "            try:\n",
    "                U.add_edge('a-' + str(b1),\n",
    "                           'b-' + str(b2),\n",
    "                           color='red')\n",
    "            except Exception as e:\n",
    "                print(\"something went wrong during graph-linking.\")\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        # Colour the DCA edges\n",
    "        edge_color_list = []\n",
    "        for (e1, e2) in U.edges:\n",
    "            if e1[0] != e2[0]:\n",
    "                edge_color_list.append('red')\n",
    "            else:\n",
    "                edge_color_list.append('black')\n",
    "\n",
    "        node_color_list = []\n",
    "        for node in U.nodes:\n",
    "            if node[0] == 'a':\n",
    "                node_color_list.append('blue')\n",
    "            else:\n",
    "                node_color_list.append('green')\n",
    "\n",
    "        if show:\n",
    "            f, ax = plt.subplots(figsize=(12, 12))\n",
    "            nx.draw(U, edge_color=edge_color_list,\n",
    "                    node_color=node_color_list, node_size=10, width=0.2)\n",
    "            plt.show()\n",
    "        return U\n",
    "\n",
    "    def populate_edge_dca(self, graph, x, protein_1, protein_2, feature_name='dca'):\n",
    "        \n",
    "        # make data into a dataframe\n",
    "        df, _, _, _ = self.get_position_wise_df(x, protein_1, protein_2)\n",
    "    \n",
    "        for edge in U.edges:\n",
    "            if ('a' in edge[0]) and ('b' in edge[1]):\n",
    "\n",
    "                # Pull out the edges with DCA connection (max DCA)\n",
    "                e_1 = int(edge[0].split('-')[-1])\n",
    "                e_2 = int(edge[1].split('-')[-1])\n",
    "\n",
    "                # Extract and join on the DCA scores\n",
    "                dca_score = df[(df['pos_1']==e_1) & (df['pos_2']==e_2)]['dca'].values\n",
    "\n",
    "                # Set dca edge type to max dca score\n",
    "                attrs = {(edge[0], edge[1]): {feature_name: float(dca_score)}}\n",
    "                nx.set_edge_attributes(graph, attrs)  \n",
    "                \n",
    "            else:\n",
    "                # Set dca edge type to 0\n",
    "                attrs = {(edge[0], edge[1]): {feature_name: 0.0}}\n",
    "                nx.set_edge_attributes(graph, attrs)   \n",
    "\n",
    "        return graph\n",
    "\n",
    "    def save_graph_data(self, graph, protein_1, protein_2, label):\n",
    "\n",
    "         # Create graph_data dir if not present\n",
    "        graph_name = \"and\".join([protein_1, protein_2])\n",
    "        graph_folder_name = 'dca_graph_data'\n",
    "        labels_folder_name = 'dca_graph_labels'\n",
    "        \n",
    "        # Graph dir\n",
    "        isExist = os.path.exists(graph_folder_name)\n",
    "        if not isExist:\n",
    "            os.makedirs(graph_folder_name)\n",
    "            print(\"{} directory created.\".format(graph_folder_name))\n",
    "\n",
    "        # Label dir\n",
    "        isExist = os.path.exists(labels_folder_name)\n",
    "        if not isExist:\n",
    "            # Create it\n",
    "            os.makedirs(labels_folder_name)\n",
    "            print(\"{} directory created.\".format(labels_folder_name))\n",
    "\n",
    "        nx.write_gpickle(graph, os.path.join(\n",
    "            graph_folder_name, graph_name + \".gpickle\"))\n",
    "\n",
    "        # Create labels\n",
    "        if label == 'P':\n",
    "            bin_label = '1'\n",
    "        else:\n",
    "            bin_label = '0'\n",
    "\n",
    "        # Format data to save on the fly\n",
    "        labels_fn = os.path.join(labels_folder_name, 'labels.csv')\n",
    "        fieldnames = ['protein_1', 'protein_2', 'label']\n",
    "        row = {'protein_1': protein_1,\n",
    "                'protein_2': protein_2, 'label': bin_label}\n",
    "\n",
    "        # Open the file to append data to - only save new entries\n",
    "        with open(labels_fn, 'a') as fd:\n",
    "            writer = csv.DictWriter(fd, fieldnames=fieldnames)\n",
    "\n",
    "            # Open file using seperate reader, and check the rows\n",
    "            with open(labels_fn, 'r') as file1:\n",
    "                existing_lines = [\n",
    "                    line for line in csv.reader(file1, delimiter=',')]\n",
    "                row_check = [x for x in row.values()]\n",
    "\n",
    "                # If header already present, don't write\n",
    "                if fieldnames not in existing_lines:\n",
    "                    writer.writeheader()\n",
    "                # If row already present, don't write\n",
    "                if row_check not in existing_lines:\n",
    "                    writer.writerow(row)\n",
    "\n",
    "    def populate_edge_proximity(self, graph, edge_dict):\n",
    "        \"\"\"Populate none dca edges with proximity values\n",
    "\n",
    "        :param graph: Union graph of G1 and G2\n",
    "        :type graph: nx object\n",
    "\n",
    "        :param x: edge_dict, containing {edge_id: values} as {k:v} pairs\n",
    "        :type x: dictions\n",
    "        \n",
    "        :return: graph U containing edge features\n",
    "        :rtype: networkx graph\n",
    "        \"\"\"\n",
    "        name = 'proximity'\n",
    "        for _, edge in enumerate(graph.edges):\n",
    "            if edge[0][0] == edge[1][0]:\n",
    "                attrs = {(edge[0], edge[1]): {name: float(edge_dict[edge])}}\n",
    "            else:\n",
    "                attrs = {(edge[0], edge[1]): {name: 0.0}}\n",
    "            nx.set_edge_attributes(graph, attrs)  \n",
    "        return graph\n",
    "\n",
    "    def process_proximity(self, x, max_value=10, mask=None, invert=True):\n",
    "    \n",
    "        # Scale proximity values to max_value\n",
    "        x = copy.deepcopy(x)\n",
    "        x_array = np.array(x) / max_value\n",
    "\n",
    "        # To masl background edges (geater than 10 angstroms)\n",
    "        if mask is None:\n",
    "            mask = np.ones(np.shape(x))\n",
    "        \n",
    "        # Apply mask\n",
    "        x_array = mask * x_array \n",
    "\n",
    "        # Invert the small scores should become large\n",
    "        if invert:\n",
    "            x_array = 1 - x_array\n",
    "        return x_array\n",
    "        \n",
    "    def get_proximity_dict(self, x, graph_name='a'):\n",
    "        row, col = x.shape\n",
    "        edge_d = {}\n",
    "        for r in range(row):\n",
    "            for c in range(col):\n",
    "                key = ('{}-{}'.format(graph_name, r)), ('{}-{}'.format(graph_name, c))\n",
    "                if key not in edge_d.keys():\n",
    "                    val = x[r,c]\n",
    "                    edge_d[key] = val\n",
    "        return edge_d\n",
    "\n",
    "    def process_dca(self, x, max_value=1):\n",
    "        # Scale DCA values\n",
    "        x = copy.deepcopy(x)\n",
    "        x_array = np.array(x)\n",
    "        x_array[x_array > 1] = max_value\n",
    "        return x_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to new data\n",
    "root= '/mnt/mnemo6/tao/PPI_Coevolution/CoEvo_data_STRING11.5/511145_EggNOGmaxLevel1224_eggNOGfilteredData/STRINGPhyBalancePhyla_Benchmark/' \n",
    "meta = 'fixedNegVSposRratio_metadata.csv'\n",
    "phyla = 'fixedNegVSposRratio_WithPhylaintegration_InSubjectOriPos_listDict_allPPs.csv'\n",
    "no_phyla = 'fixedNegVSposRratio_WithoutPhylaintegration_InSubjectOriPos_listDict_allPPs.csv'\n",
    "\n",
    "\n",
    "# Annotation file\n",
    "anndata_path = ('/mnt/mnemo6/tao/PPI_Coevolution/CoEvo_data_STRING11.5/'\n",
    "                '511145_EggNOGmaxLevel1224_eggNOGfilteredData/STRINPhyPPI_Benchmark/allPPI_allInfo_frame.csv')\n",
    "# Netsurf data\n",
    "netsurf_path = \"/mnt/mnemo6/tao/PPI_Coevolution/STRING_data_11.5/511145_netsurfp2_output/\"\n",
    "\n",
    "# ALPHA-Fold paths\n",
    "string_to_af = \"/mnt/mnemo6/damian/STRING_derived_v11.5/alphafold/mapping/83333.511145.tsv\"\n",
    "string_to_pdb = '/mnt/mnemo6/damian/STRING_derived_v11.5/pdb/pdb2string.blastp.best_score.tsv'\n",
    "pdb_files_for_PDB = '/mnt/mnemo6/damian/STRING_freeze_v11.5/pdb/data/biounit/coordinates/divided/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "new_data = pd.read_csv(os.path.join(root, no_phyla), sep='\\t', header=None)\n",
    "phyla_data = pd.read_csv(os.path.join(root, phyla), sep='\\t', header=None)\n",
    "meta_data = pd.read_csv(os.path.join(root, meta), sep='\\t', header=0)\n",
    "\n",
    "# Netsurf outputs\n",
    "netsurf = glob.glob(os.path.join(netsurf_path, \"*.csv\"))\n",
    "netsurf.sort()\n",
    "\n",
    "# Generate map between protein names and netsurfp file paths\n",
    "seq_names = [x.split(\"/\")[-1].replace(\".csv\", \"\") for x in netsurf]\n",
    "netsurf_d = dict(zip(seq_names, netsurf))\n",
    "\n",
    "# Load meta\n",
    "meta_data = pd.read_csv(os.path.join(root, meta), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 2 graphs from single obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the graph maker class\n",
    "GM = GraphMaker(anndata_path=os.path.join(root, meta))\n",
    "anndata = GM.anndata\n",
    "rows, cols = np.shape(anndata)\n",
    "\n",
    "# Loop over all instances in the anndata file\n",
    "for i in range(rows):\n",
    "    obs = anndata.iloc[i, :]\n",
    "    pair_1 = obs['STRING_ID1']\n",
    "    pair_2 = obs['STRING_ID2']\n",
    "    label = obs['benchmark_status']\n",
    "\n",
    "    # Get alpha-fold structures\n",
    "    residue_1, residue_2 = GM.generate_alpha_fold_structures(\n",
    "        string_to_af, pair_1, pair_2)\n",
    "    \n",
    "    # Get proximity matrices\n",
    "    proximity_mask_1, dist_map_1 = GM.generate_proximity_matrix(\n",
    "        seq_1=residue_1, seq_2=residue_1, \n",
    "        angstroms=10, show=False)\n",
    "    \n",
    "    proximity_mask_2, dist_map_2 = GM.generate_proximity_matrix(\n",
    "        seq_1=residue_2, seq_2=residue_2, \n",
    "        angstroms=10,show=False)\n",
    "\n",
    "    # Generate graphs\n",
    "    G_1, G_2 = GM.generate_graphs(\n",
    "        adjacency_matrix_1=proximity_mask_1, \n",
    "        adjacency_matrix_2=proximity_mask_2)\n",
    "\n",
    "    # Populate node attributes with netsurfp features\n",
    "    G_1, G_2 = GM.populate_graph_features(\n",
    "        graph_1=G_1, graph_2=G_2, \n",
    "        protein_1=pair_1, protein_2=pair_2,\n",
    "        netsurf_path_dict=netsurf_d)\n",
    "\n",
    "    # Get DCA bridge connections\n",
    "    df, dca, dca_raw, dca_bridges = GM.get_position_wise_df(\n",
    "        x=new_data, protein_1=pair_1, \n",
    "        protein_2=pair_2)\n",
    "\n",
    "    # Make union of the graphs on dca brides\n",
    "    U = GM.link_graphs(\n",
    "        graph_1=G_1, graph_2=G_2,\n",
    "         dca_bridges=dca_bridges, show=False)\n",
    "\n",
    "    # Populate edge attributes\n",
    "    U = GM.populate_edge_dca(\n",
    "        graph=U, x=new_data,\n",
    "        protein_1=pair_1, protein_2=pair_2,\n",
    "        feature_name='dca')\n",
    "\n",
    "    # Invert distance matrices\n",
    "    inv_dit_map_1 = GM.process_proximity(\n",
    "        x=dist_map_1, max_value=10, \n",
    "        mask=proximity_mask_1, invert=True)\n",
    "\n",
    "    inv_dit_map_2 = GM.process_proximity(\n",
    "        x=dist_map_2, max_value=10, \n",
    "        mask=proximity_mask_2, invert=True)\n",
    "\n",
    "    # Generate proximity matrices\n",
    "    d_1 = GM.get_proximity_dict(x=inv_dit_map_1, graph_name='a')\n",
    "    d_2 = GM.get_proximity_dict(x=inv_dit_map_2, graph_name='b')\n",
    "\n",
    "    # Combine the two dicts\n",
    "    d_1.update(d_2)\n",
    "\n",
    "    # Finally populate the prixmity edge features\n",
    "    U = GM.populate_edge_proximity(U, d_1)\n",
    "    \n",
    "    # Save the graph to file\n",
    "    GM.save_graph_data(graph=U, protein_1=pair_1, protein_2=pair_2, label=label)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges: ('a-5', 'b-83') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-13', 'b-86') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-16', 'b-79') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-18', 'b-4') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-21', 'b-8') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-21', 'b-4') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-21', 'b-7') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-22', 'b-69') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-24', 'b-8') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-28', 'b-11') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-28', 'b-54') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-29', 'b-16') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-30', 'b-89') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-33', 'b-13') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-34', 'b-93') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-34', 'b-50') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-35', 'b-89') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-43', 'b-79') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-46', 'b-45') ----- DCA: 1.0 ,  Prox:0.0\n",
      "edges: ('a-56', 'b-76') ----- DCA: 1.0 ,  Prox:0.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\" DCA score is capped at 1.0 (should be > 0 for a-b connections)...\n",
    "    The score for provimity for nodes connecting graphs (should be 0.0 for a-b connections)\n",
    "    \"\"\"\n",
    "# Inspect edge attributes\n",
    "for edge in U.edges:\n",
    "    if ('a' in edge[0][0]) and ('b' in edge[1][0]):\n",
    "        print(\n",
    "            'edges: {} -----'.format(edge), \n",
    "            'DCA: {}'.format( nx.get_edge_attributes(U, 'dca')[edge]),\n",
    "            ', ', \n",
    "            'Prox:{}'.format(nx.get_edge_attributes(U, 'proximity')[edge]),\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: a-0 \n",
      " Graph: a \n",
      " Featurs: \n",
      "[ 6.95151031e-01  1.39099721e+02  8.65582202e-04  5.66634699e-05\n",
      "  9.99077797e-01  4.94130254e-05  3.86691478e-04  3.10334912e-07\n",
      "  1.12930997e-04  1.47105957e-05  8.12538899e-04  3.47032677e-04\n",
      "  9.98276353e-01 -8.26831589e+01  1.44031662e+02  4.56831902e-01]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" I need to normlise these vales across all nodes, over all graphs!\"\"\"\n",
    "# Print node attributes for a single node\n",
    "graph_id = 'a'\n",
    "for node in U.nodes:\n",
    "    if (graph_id in node[0]):\n",
    "        print('Node: {} \\n'.format(node), \n",
    "        'Graph: {} \\n'.format(graph_id),\n",
    "        'Features: \\n{}'.format(nx.get_node_attributes(U, 'x')[node]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91480398e29c201d85f830141776dbac7675dbf1ea4e71a85e6e607707f70528"
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
