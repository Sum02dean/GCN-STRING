{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sys.path.append(\"../\")\n",
    "import sys\n",
    "from utilities.gcn_utills import *\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import networkx as nx\n",
    "import glob\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.utils import convert\n",
    "from torch_geometric.data import InMemoryDataset, download_url, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from utilities.gcn_utills import GraphMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define useful methods and objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMaker:\n",
    "    \"\"\"\n",
    "    Main class to generate graphs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, anndata_path='./adata.csv'):\n",
    "        self.anndata_path = anndata_path\n",
    "        self.anndata = pd.read_csv(anndata_path, sep='\\t')\n",
    "\n",
    "    def __get_top_ranking_bet_value_dict(self, record=None, top_num=20):\n",
    "        \"\"\"This is a function written by Tao to break down the DCA matrix and fetch the\n",
    "         top DCA-scoring pairs and their associated DCA scores\"\"\"\n",
    "\n",
    "        query_pro1, query_pro2, l1, l2, coevo_path, suffix = record\n",
    "        data_file_name = coevo_path + query_pro1 + \"and\" + query_pro2 + suffix + \".npz\"\n",
    "        data_array_dig = np.load(data_file_name)['arr_0']\n",
    "        data_array = data_array_dig.T + data_array_dig\n",
    "        np.fill_diagonal(data_array, 0)\n",
    "        bet_data_array = data_array[:l1, l1:]\n",
    "        ascending_bet_data_array = np.sort(bet_data_array.flatten())\n",
    "        descending_bet_data_array = ascending_bet_data_array[::-1]\n",
    "        return_list = [query_pro1, query_pro2]\n",
    "        esisted_top_values = set()\n",
    "\n",
    "        scores = []\n",
    "        pairs_1 = []\n",
    "        pairs_2 = []\n",
    "\n",
    "        for j in range(top_num):\n",
    "            top_value = descending_bet_data_array[j]\n",
    "            if top_value not in esisted_top_values:\n",
    "                top_idx = np.where(bet_data_array == top_value)\n",
    "                for i in range(len(top_idx[0])):\n",
    "                    top_row, top_col = top_idx[0][i], top_idx[1][i]\n",
    "                    top_col += l1\n",
    "                    if len(return_list) < (2 + top_num * 3):\n",
    "                        return_list.extend((top_value, top_row, top_col))\n",
    "                        scores.append(top_value)\n",
    "                        pairs_1.append(top_row)\n",
    "                        pairs_2.append(top_col)\n",
    "\n",
    "                esisted_top_values.add(top_value)\n",
    "            if len(return_list) > (2 + top_num * 3):\n",
    "                break\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            {'pair_1': pairs_1, 'pair_2': pairs_2, 'scores': scores})\n",
    "        return df, (return_list), query_pro1, query_pro1\n",
    "\n",
    "    def generate_top_dca_scores(self, pair_1, pair_2, len_1, len_2, coevo_path, n_dca=20,\n",
    "                                fn_suffix='_pydcaFNAPC_array'):\n",
    "        \"\"\"Extracts the top _dca scores between two protein pairs\n",
    "        :param pair_1: name of protein 1\n",
    "        :type pair_1: string\n",
    "        :param pair_2: name of protein 2\n",
    "        :type pair_2: string\n",
    "        :param len_1: length of protein 1\n",
    "        :type len_1: int\n",
    "        :param len_2: length of protein 2\n",
    "        :type len_2: int\n",
    "        :param coevo_path: path to coevolutionary data\n",
    "        :type coevo_path: string\n",
    "        :param n_dca: number of top dca scores to include, defaults to 20\n",
    "        :type n_dca: int, optional\n",
    "        :param fn_suffix: suffix of the coevolutionary file, defaults to '_pydcaFNAPC_array'\n",
    "        :type fn_suffix: str, optional\n",
    "        :return: top-10 dca for a given protein pair\n",
    "        :rtype: list\n",
    "        \"\"\"\n",
    "        record = [pair_1, pair_2, len_1, len_2, coevo_path, fn_suffix]\n",
    "        dca_stats, _, _, _ = self.__get_top_ranking_bet_value_dict(\n",
    "            record, top_num=n_dca)\n",
    "        return dca_stats\n",
    "\n",
    "    def generate_dca_bridges(self, coevo_path, pair_1, pair_2, len_1, len_2, n_dca=20):\n",
    "        \"\"\"Extracts the residue names corresponding to the top dca scores. These are used to connect the two\n",
    "        protein graphs together on \"bridges\".\n",
    "        :param coevo_path: path to coevolutionary data\n",
    "        :type coevo_path: string\n",
    "        :param pair_1: protein pair 1\n",
    "        :type pair_1: string\n",
    "        :param pair_2: protein pair 2\n",
    "        :type pair_2: string\n",
    "        :param len_1: protein length 1\n",
    "        :type len_1: int\n",
    "        :param len_2: protein length 2\n",
    "        :type len_2: int\n",
    "        :param n_dca: number of top dcas, defaults to 20\n",
    "        :type n_dca: int, optional\n",
    "        :return: list containing the tuple of sorted top ranking pairs\n",
    "        :rtype: list\n",
    "        \"\"\"\n",
    "        dca_stats = self.generate_top_dca_scores(pair_1=pair_1,\n",
    "                                                 pair_2=pair_2,\n",
    "                                                 len_1=len_1,\n",
    "                                                 len_2=len_2,\n",
    "                                                 n_dca=n_dca,\n",
    "                                                 coevo_path=coevo_path)\n",
    "\n",
    "        # Subset the residues\n",
    "        res_1 = [int(x) for x in dca_stats.values[:, 0]]\n",
    "        res_2 = [int(x) for x in dca_stats.values[:, 1]]\n",
    "\n",
    "        # Get top 20-dca pairs, generate bridges\n",
    "        res_a = res_1[0:n_dca]\n",
    "        res_b = res_2[0:n_dca]\n",
    "        scores = dca_stats['scores'].iloc[:n_dca]\n",
    "        bridges = list(zip(res_a, res_b))\n",
    "        return bridges\n",
    "\n",
    "    def generate_alpha_fold_structures(self, string_to_af, pair_1, pair_2):\n",
    "        \"\"\"Queries alphs-fold predictions for a given protein sequnece and returns\n",
    "         alpha-fld predicted structures.\n",
    "        :param string_to_af: maping path between string-alphaFold\n",
    "        :type string_to_af: string\n",
    "        :param pair_1: protein name 1\n",
    "        :type pair_1: string\n",
    "        :param pair_2: protein name 2\n",
    "        :type pair_2: string\n",
    "        :return: alphaFold structures for each protein\n",
    "        :rtype: objects\n",
    "        \"\"\"\n",
    "\n",
    "        # Map from STRING to Alpha-Fold\n",
    "        ecoli_maps = pd.read_csv(\n",
    "            string_to_af, sep='\\t', engine='python', header=None)\n",
    "        map_1 = ecoli_maps[ecoli_maps[0] == pair_1]\n",
    "        map_2 = ecoli_maps[ecoli_maps[0] == pair_2]\n",
    "\n",
    "        # Save and import map files\n",
    "        test_file_1 = map_1.iloc[0, -1]\n",
    "        test_file_1 = test_file_1.replace('.gz', '')\n",
    "        test_file_2 = map_2.iloc[0, -1]\n",
    "        test_file_2 = test_file_2.replace('.gz', '')\n",
    "\n",
    "        # Create sloppy parser\n",
    "        sloppy_parser = PDBParser(\n",
    "            structure_builder=SloppyStructureBuilder())\n",
    "        protein_1 = sloppy_parser.get_structure(id=None, file=test_file_1)\n",
    "        protein_2 = sloppy_parser.get_structure(id=None, file=test_file_2)\n",
    "\n",
    "        # Structure 1\n",
    "        sloppyio_1 = SloppyPDBIO()\n",
    "        sloppyio_1.set_structure(protein_1)\n",
    "\n",
    "        # Structure 2\n",
    "        sloppyio_2 = SloppyPDBIO()\n",
    "        sloppyio_2.set_structure(protein_2)\n",
    "\n",
    "        # (Optional) save the sloppyIO files\n",
    "        # sloppyio_1.save(\"sloppyio_1.pdb\")\n",
    "        # sloppyio_2.save(\"sloppyio_2.pdb\")\n",
    "\n",
    "        # Get protein residue structures\n",
    "        residues_1 = [x for x in sloppyio_1.structure.get_residues()]\n",
    "        residues_2 = [x for x in sloppyio_2.structure.get_residues()]\n",
    "        return residues_1, residues_2\n",
    "\n",
    "    def calculate_residue_dist(self, seq_1, seq_2):\n",
    "        \"\"\"Calculates the euclidean distance between two residues in 3D space.\n",
    "        :param residue_one: reference residue\n",
    "        :type residue_one:  object\n",
    "        :param residue_two: target residue\n",
    "        :type residue_two: object\n",
    "        :return: sqaured euclidean distance\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        diff_vector = seq_1[\"CA\"].coord - seq_2[\"CA\"].coord\n",
    "        sq_dist = np.sqrt(np.sum(diff_vector * diff_vector))\n",
    "        return sq_dist\n",
    "\n",
    "    def calculate_dist_matrix(self, seq_1, seq_2):\n",
    "        \"\"\"Calculates the distance matrix for all pairwise residues\n",
    "        :param seq_1: protein sequence 1\n",
    "        :type seq_1: string\n",
    "        :param seq_2: protein sequence 2\n",
    "        :type seq_2: string\n",
    "        :return: an nd array which encodes pairwise residue distances\n",
    "        :rtype: np.array\n",
    "        \"\"\"\n",
    "        d_mat = np.zeros((len(seq_1), len(seq_2)), np.float)\n",
    "        for row, residue_one in enumerate(seq_1):\n",
    "            for col, residue_two in enumerate(seq_2):\n",
    "                euclidean_dist = self.calculate_residue_dist(\n",
    "                    residue_one, residue_two)\n",
    "                d_mat[row, col] = euclidean_dist\n",
    "        return d_mat\n",
    "\n",
    "    def generate_proximity_matrix(self, seq_1, seq_2, angstroms=10, show=False):\n",
    "        \"\"\"Creates an adacency matrix for points within n angstroms of each other\n",
    "        :param seq_1: protein sequence 1\n",
    "        :type seq_1: string\n",
    "        :param seq_2: protein sequence 2\n",
    "        :type seq_2: sting\n",
    "        :param angstroms: max distance threshold , defaults to 10\n",
    "        :type angstroms: int, optional\n",
    "        :param show: to plot matrix, defaults to False\n",
    "        :type show: bool, optional\n",
    "        :return: a proximity matrix for points considered less than n angstroms apart\n",
    "        :rtype: np.array\n",
    "        \"\"\"\n",
    "\n",
    "        # Select the residues from maps that are less than 'n' angstoms apart\n",
    "        contact_map = self.calculate_dist_matrix(seq_1, seq_2)\n",
    "        adjacency_matrix = np.zeros(np.shape(contact_map))\n",
    "        adjacency_matrix[contact_map < angstroms] = 1\n",
    "\n",
    "        if show:\n",
    "            plt.subplots(figsize=(12, 12))\n",
    "            sns.heatmap(contact_map)\n",
    "            plt.show()\n",
    "\n",
    "            plt.subplots(figsize=(12, 12))\n",
    "            sns.heatmap(adjacency_matrix)\n",
    "            plt.show()\n",
    "\n",
    "        return adjacency_matrix\n",
    "\n",
    "    def generate_graphs(self, adjacency_matrix_1, adjacency_matrix_2, show=False):\n",
    "        \"\"\"Generates the initial graphs from provided adjacency matrices.\n",
    "        :param adjacency_matrix_1: proximity matrix for protein 1\n",
    "        :type adjacency_matrix_1: np.array\n",
    "        :param adjacency_matrix_2: proximity matrix for protein 2\n",
    "        :type adjacency_matrix_2: np.array\n",
    "        :param show: plot graphs, defaults to False\n",
    "        :type show: bool, optional\n",
    "        :return: returns networkX graphs corrresponding to each adjacency matrix\n",
    "        :rtype: tuple of networkX objects\n",
    "        \"\"\"\n",
    "        # Generate graphs\n",
    "        G_1 = nx.from_numpy_matrix(adjacency_matrix_1)\n",
    "        G_2 = nx.from_numpy_matrix(adjacency_matrix_2)\n",
    "\n",
    "        if show:\n",
    "            # Plot the graphs\n",
    "            plt.subplots(figsize=(12, 12))\n",
    "            nx.draw(G_1, with_labels=False, edge_color=\"black\",\n",
    "                    node_size=10, width=0.2)\n",
    "            plt.show()\n",
    "\n",
    "            plt.subplots(figsize=(12, 12))\n",
    "            nx.draw(G_2, with_labels=False, edge_color=\"black\",\n",
    "                    node_size=10, node_color='green', width=0.2)\n",
    "            plt.show()\n",
    "        return G_1, G_2\n",
    "\n",
    "    def map_net_surf_to_graphs(self, graph_2, pair_1, pair_2, ns_path_msa, ns_path_seq, suffix='_map2MSA.csv'):\n",
    "        \"\"\"Maps the graphs node labels to the corresponding points from MSA, and returns net-surf residue \n",
    "        features at these points.\n",
    "        :param graph_2: graph for protein 2\n",
    "        :type graph_2: networkX object\n",
    "        :param pair_1: protein 1 name\n",
    "        :type pair_1: string\n",
    "        :param pair_2: protein 2 name\n",
    "        :type pair_2: string\n",
    "        :param ns_path_msa: net-surf path\n",
    "        :type ns_path_msa: string\n",
    "        :param ns_path_seq: net-surf path for protein sequence\n",
    "        :type ns_path_seq: string\n",
    "        :param suffix: file ending for MSA, defaults to '_map2MSA.csv'\n",
    "        :type suffix: str, optional\n",
    "        :return: mapping between msa to sequence, new node labels, and net-surf features for both proteins.\n",
    "        :rtype: tuple\n",
    "        \"\"\"\n",
    "\n",
    "        # -------- MSA-Seq Mapping ----------\n",
    "\n",
    "        # Get the seq-MSA mapped feature matrix\n",
    "        net = pair_1 + suffix\n",
    "        fn = os.path.join(ns_path_msa, net)\n",
    "        net_surf_1 = pd.read_csv(fn)\n",
    "\n",
    "        # Get the seq-MSA mapped feature matrix\n",
    "        net = pair_2 + suffix\n",
    "        fn = os.path.join(ns_path_msa, net)\n",
    "        net_surf_2 = pd.read_csv(fn)\n",
    "\n",
    "        # -------- SEQUENCE ----------\n",
    "        net = pair_1 + '.csv'\n",
    "        fn = os.path.join(ns_path_seq, net)\n",
    "        x_net_surf_1 = pd.read_csv(fn)\n",
    "\n",
    "        net = pair_2 + '.csv'\n",
    "        fn = os.path.join(ns_path_seq, net)\n",
    "        x_net_surf_2 = pd.read_csv(fn)\n",
    "\n",
    "        # Get new graph labels\n",
    "        graph_1_labels = list(set([x for x in net_surf_1.seqPos.values]))\n",
    "\n",
    "        # sequence and MSA maps for protein-1\n",
    "        seq_pos_p1 = net_surf_1.seqPos\n",
    "        msa_pos_p1 = net_surf_1.MSAPos\n",
    "        msa_2_seq_p1 = dict(zip(msa_pos_p1, seq_pos_p1))\n",
    "        seq_2_msa_p1 = dict(zip(seq_pos_p1, msa_pos_p1))\n",
    "\n",
    "        # sequence and MSA maps for protein-2\n",
    "        seq_pos_p2 = [x + (seq_pos_p1.values[-1] + 1)\n",
    "                      for x in net_surf_2.seqPos]\n",
    "        msa_pos_p2 = [x + (msa_pos_p1.values[-1] + 1)\n",
    "                      for x in net_surf_2.MSAPos]\n",
    "        msa_2_seq_p2 = dict(zip(msa_pos_p2, seq_pos_p2))\n",
    "        seq_2_msa_p2 = dict(zip(seq_pos_p2, msa_pos_p2))\n",
    "\n",
    "        # Reset G2 labels\n",
    "        g2_labels = [x + (graph_1_labels[-1]) for x in x_net_surf_2.n.values]\n",
    "        G_2_labels = dict(zip(graph_2.nodes, g2_labels))\n",
    "\n",
    "        return msa_2_seq_p1, msa_2_seq_p2, G_2_labels, x_net_surf_1, x_net_surf_2\n",
    "\n",
    "    def relabel_graph_nodes(self, graph, new_labels):\n",
    "        \"\"\"Overwrites node labels in a graph with new_labels.\n",
    "        :param graph: networkX graph object\n",
    "        :type graph: object\n",
    "        :param new_labels: new labels to provide\n",
    "        :type new_labels: list\n",
    "        :return: graph object with renamed node labels\n",
    "        :rtype: networkx object\n",
    "        \"\"\"\n",
    "        # Relabel nodes\n",
    "        new_graph = nx.relabel_nodes(graph, new_labels)\n",
    "        return new_graph\n",
    "\n",
    "    def check_bridge_connections(self, msa_coder_1, msa_coder_2, graph_1, graph_2, bridges):\n",
    "        \"\"\"Test if all bridge nodes are contained within their respective graphs - should be! \n",
    "        :param msa_coder_1: msa-seq coder for protein 1\n",
    "        :type msa_coder_1: dict\n",
    "        :param msa_coder_2: msa-seq coder for protein 2\n",
    "        :type msa_coder_2: dict\n",
    "        :param graph_1: networkx graph 1    \n",
    "        :type graph_1: object\n",
    "        :param graph_2: networkX graph 2    \n",
    "        :type graph_2: object\n",
    "        :param bridges: list of dca bridges\n",
    "        :type bridges: list\n",
    "        :return: 0 if tests passed, else 1\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "\n",
    "        g1_e = set(sorted([x[1] for x in graph_1.edges]))\n",
    "        g2_e = [x for x in set(sorted([x[1] for x in graph_2.edges]))]\n",
    "\n",
    "        for i, (b1, b2) in enumerate(bridges):\n",
    "            if (msa_coder_1[b1] not in g1_e):\n",
    "                print('failed with exit status: 1')\n",
    "                return 1\n",
    "\n",
    "            if (msa_coder_2[b2] not in g2_e):\n",
    "                print('failed with exit status: 1')\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    def populate_graph_features(self, graph_1, graph_2, x_net_surf_1, x_net_surf_2):\n",
    "        \"\"\" Populates each node (residue) with its respective net-surf feature vector\n",
    "        :param graph_1: graph for protein 1\n",
    "        :type graph_1: networkX graph object\n",
    "        :param graph_2: graph for protein 2\n",
    "        :type graph_2: networkX graph object\n",
    "        :param x_net_surf_1: net-surf feautures for protein 1\n",
    "        :type x_net_surf_1: pandas dataframe\n",
    "        :param x_net_surf_2: net-surf features for protein 2\n",
    "        :type x_net_surf_2: pandas dataframe\n",
    "        :return: graph1 and graph2 populated with node features\n",
    "        :rtype: tuple of networkX graphs\n",
    "        \"\"\"\n",
    "\n",
    "        # Protein-1\n",
    "        vars_to_keep = [x for x in x_net_surf_1.columns if x not in [\n",
    "            'id', 'seq', 'n', 'q3', 'q8']]\n",
    "        features_p1 = x_net_surf_1.loc[:, vars_to_keep]\n",
    "\n",
    "        # Protein-2\n",
    "        vars_to_keep = [x for x in x_net_surf_2.columns if x not in [\n",
    "            'id', 'seq', 'n', 'q3', 'q8']]\n",
    "        features_p2 = x_net_surf_2.loc[:, vars_to_keep]\n",
    "\n",
    "        # Populate node features before making Union on graphs\n",
    "        G_1_features = {}\n",
    "        for i, node in enumerate(graph_1.nodes):\n",
    "            feature_array = {'x': features_p1.iloc[i, :].values}\n",
    "            G_1_features[node] = feature_array\n",
    "\n",
    "        G_2_features = {}\n",
    "        for i, node in enumerate(graph_2.nodes):\n",
    "            feature_array = {'x': features_p2.iloc[i, :].values}\n",
    "            G_2_features[node] = feature_array\n",
    "\n",
    "        # Set the node attributes\n",
    "        nx.set_node_attributes(graph_1, G_1_features)\n",
    "        nx.set_node_attributes(graph_2, G_2_features)\n",
    "        return graph_1, graph_2\n",
    "\n",
    "    def link_graphs(self, graph_1, graph_2, bridges, msa_coder_1, msa_coder_2, show=False):\n",
    "        \"\"\"Linkes the two protein graphs on their top 'n' DCA connections (bridges)\n",
    "        :param graph_1: graph for protein 1\n",
    "        :type graph_1: networkX graph object\n",
    "        :param graph_2: graph for protein 2\n",
    "        :type graph_2: networkX graph object\n",
    "        :param bridges: dca connections\n",
    "        :type bridges: list\n",
    "        :param msa_coder_1: msa-seq coder for protein 1\n",
    "        :type msa_coder_1: dict\n",
    "        :param msa_coder_2: sa-seq coder for protein 2\n",
    "        :type msa_coder_2: dict\n",
    "        :param show: to plot graphs, defaults to False\n",
    "        :type show: bool, optional\n",
    "        :return: Union of the two protein graphs    \n",
    "        :rtype: networkX graph object\n",
    "        \"\"\"\n",
    "\n",
    "        # Connect the graphs together - use map-encoder for -b\n",
    "        U = nx.union(graph_1, graph_2, rename=('a-', 'b-'))\n",
    "\n",
    "        for (b1, b2) in bridges:\n",
    "            try:\n",
    "                U.add_edge('a-' + str(msa_coder_1[b1]),\n",
    "                           'b-' + str(msa_coder_2[b2]),\n",
    "                           color='red')\n",
    "            except Exception as e:\n",
    "                print(\"something went wrong during graph-linking.\")\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        # Colour the DCA edges\n",
    "        edge_color_list = []\n",
    "        for (e1, e2) in U.edges:\n",
    "            if e1[0] != e2[0]:\n",
    "                edge_color_list.append('red')\n",
    "            else:\n",
    "                edge_color_list.append('black')\n",
    "\n",
    "        node_color_list = []\n",
    "        for node in U.nodes:\n",
    "            if node[0] == 'a':\n",
    "                node_color_list.append('blue')\n",
    "            else:\n",
    "                node_color_list.append('green')\n",
    "\n",
    "        if show:\n",
    "            f, ax = plt.subplots(figsize=(12, 12))\n",
    "            nx.draw(U, edge_color=edge_color_list,\n",
    "                    node_color=node_color_list, node_size=10, width=0.2)\n",
    "            plt.show()\n",
    "        return U\n",
    "\n",
    "    def get_computational_graph(self, string_to_af, ns_path_msa, ns_path_seq,\n",
    "                                coevo_path, n_samples=2, n_dca=20, show=False):\n",
    "        \"\"\"High level method to generate graphs from annotation file on all proteins.\n",
    "        :param string_to_af: path that maps STRING to AlphaFold\n",
    "        :type string_to_af: string\n",
    "        :param ns_path_msa: net-surf path for MSA\n",
    "        :type ns_path_msa: string\n",
    "        :param ns_path_seq: net-surf path for protein seq\n",
    "        :type ns_path_seq: string   \n",
    "        :param coevo_path: path to co-evolution data\n",
    "        :type coevo_path: string\n",
    "        :param n_samples: number of graphs to produce, defaults to 2\n",
    "        :type n_samples: int, optional\n",
    "        :param n_dca: number of top ranked dca scores to consder, defaults to 20\n",
    "        :type n_dca: int, optional\n",
    "        :param show: plot all , defaults to False\n",
    "        :type show: bool, optional\n",
    "        :return: tuple containing list of graphs and list of labels\n",
    "        :rtype: tuple\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. Loop over all observations in anndata file\n",
    "        graphs = []\n",
    "        labels = []\n",
    "        for (pair_1, pair_2) in tqdm(self.anndata.iloc[:n_samples, 0:2].values):\n",
    "            try:\n",
    "                len_1 = int(self.anndata.loc[(self.anndata['STRING_ID1'] == pair_1) & (\n",
    "                    self.anndata['STRING_ID2'] == pair_2)].len1)\n",
    "                len_2 = int(self.anndata.loc[(self.anndata['STRING_ID1'] == pair_1) & (\n",
    "                    self.anndata['STRING_ID2'] == pair_2)].len2)\n",
    "                label = self.anndata.loc[(self.anndata['STRING_ID1'] == pair_1) & (\n",
    "                    self.anndata['STRING_ID2'] == pair_2)].benchmark_status.values\n",
    "                labels.append(label)\n",
    "\n",
    "                # 2. Generate_dca_bridges(self, n=20)\n",
    "                bridges = self.generate_dca_bridges(pair_1=pair_1,\n",
    "                                                    pair_2=pair_2,\n",
    "                                                    len_1=len_1,\n",
    "                                                    len_2=len_2,\n",
    "                                                    n_dca=n_dca,\n",
    "                                                    coevo_path=coevo_path)\n",
    "                # 3. Generate alpha-fold residues\n",
    "                residue_1, residue_2 = self.generate_alpha_fold_structures(string_to_af,\n",
    "                                                                           pair_1=pair_1,\n",
    "                                                                           pair_2=pair_2)\n",
    "\n",
    "                # 4. Generate proximity adjacency matrices\n",
    "                am_1 = self.generate_proximity_matrix(\n",
    "                    seq_1=residue_1, seq_2=residue_1, angstroms=10, show=show)\n",
    "\n",
    "                am_2 = self.generate_proximity_matrix(\n",
    "                    seq_1=residue_2, seq_2=residue_2, angstroms=10, show=show)\n",
    "\n",
    "                # 5. Build graph\n",
    "                G_1, G_2 = self.generate_graphs(am_1, am_2, show=show)\n",
    "\n",
    "                # 6. Parse net_surf\n",
    "                outputs = self.map_net_surf_to_graphs(ns_path_msa=ns_path_msa,\n",
    "                                                      ns_path_seq=ns_path_seq,\n",
    "                                                      pair_1=pair_1,\n",
    "                                                      pair_2=pair_2,\n",
    "                                                      graph_2=G_2,\n",
    "                                                      suffix='_map2MSA.csv')\n",
    "\n",
    "                # 7. Collect outputs\n",
    "                msa_2_seq_p1, msa_2_seq_p2, G_2_labels, x_net_surf_1, x_net_surf_2 = outputs\n",
    "\n",
    "                # 8. Re-label graph\n",
    "                G_2 = self.relabel_graph_nodes(graph=G_2,\n",
    "                                               new_labels=G_2_labels)\n",
    "\n",
    "                # 9. Check bridge stability\n",
    "                self.check_bridge_connections(msa_coder_1=msa_2_seq_p1,\n",
    "                                              msa_coder_2=msa_2_seq_p2,\n",
    "                                              graph_1=G_1,\n",
    "                                              graph_2=G_2,\n",
    "                                              bridges=bridges)\n",
    "\n",
    "                # 10. Populate features\n",
    "                G_1, G_2 = self.populate_graph_features(graph_1=G_1,\n",
    "                                                        graph_2=G_2,\n",
    "                                                        x_net_surf_1=x_net_surf_1,\n",
    "                                                        x_net_surf_2=x_net_surf_2)\n",
    "\n",
    "                # 11. Link graphs\n",
    "                U = self.link_graphs(graph_1=G_1,\n",
    "                                     graph_2=G_2,\n",
    "                                     bridges=bridges,\n",
    "                                     msa_coder_1=msa_2_seq_p1,\n",
    "                                     msa_coder_2=msa_2_seq_p2,\n",
    "                                     show=show)\n",
    "\n",
    "                # 12. Save and return graphs\n",
    "                graphs.append(U)\n",
    "                graph_name = \"and\".join([pair_1, pair_2])\n",
    "\n",
    "                # Create graph_data dir if not present\n",
    "                graph_folder_name = 'graph_data'\n",
    "                isExist = os.path.exists(graph_folder_name)\n",
    "                if not isExist:\n",
    "                    # Create it\n",
    "                    os.makedirs(graph_folder_name)\n",
    "                    print(\"{} directory created.\".format(graph_folder_name))\n",
    "\n",
    "                labels_folder_name = 'graph_labels'\n",
    "                isExist = os.path.exists(labels_folder_name)\n",
    "                if not isExist:\n",
    "                    # Create it\n",
    "                    os.makedirs(labels_folder_name)\n",
    "                    print(\"{} directory created.\".format(labels_folder_name))\n",
    "\n",
    "                nx.write_gpickle(U, os.path.join(\n",
    "                    graph_folder_name, graph_name + \".gpickle\"))\n",
    "\n",
    "                # Create labels\n",
    "                if label == 'P':\n",
    "                    bin_label = '1'\n",
    "                else:\n",
    "                    bin_label = '0'\n",
    "\n",
    "                # Format data to save on the fly\n",
    "                labels_fn = os.path.join(labels_folder_name, 'labels.csv')\n",
    "                fieldnames = ['protein_1', 'protein_2', 'label']\n",
    "                row = {'protein_1': pair_1,\n",
    "                       'protein_2': pair_2, 'label': bin_label}\n",
    "\n",
    "                # Open the file to append data to - only save new entries\n",
    "                with open(labels_fn, 'a') as fd:\n",
    "                    writer = csv.DictWriter(fd, fieldnames=fieldnames)\n",
    "\n",
    "                    # Open file using seperate reader, and check the rows\n",
    "                    with open('graph_labels/labels.csv', 'r') as file1:\n",
    "                        existing_lines = [\n",
    "                            line for line in csv.reader(file1, delimiter=',')]\n",
    "                        row_check = [x for x in row.values()]\n",
    "\n",
    "                        # If header already present, don't write\n",
    "                        if fieldnames not in existing_lines:\n",
    "                            writer.writeheader()\n",
    "                        # If row already present, don't write\n",
    "                        if row_check not in existing_lines:\n",
    "                            writer.writerow(row)\n",
    "\n",
    "            # If something breaks - pass\n",
    "            except Exception as e:\n",
    "                print('Skipped')\n",
    "                print(e)\n",
    "                pass\n",
    "        return graphs, labels\n",
    "\n",
    "def populate_graph_features(graph_1, graph_2, x_net_surf_1, x_net_surf_2):\n",
    "        \"\"\" Populates each node (residue) with its respective net-surf feature vector\n",
    "\n",
    "        :param graph_1: graph for protein 1\n",
    "        :type graph_1: networkX graph object\n",
    "        :param graph_2: graph for protein 2\n",
    "        :type graph_2: networkX graph object\n",
    "        :param x_net_surf_1: net-surf feautures for protein 1\n",
    "        :type x_net_surf_1: pandas dataframe\n",
    "        :param x_net_surf_2: net-surf features for protein 2\n",
    "        :type x_net_surf_2: pandas dataframe\n",
    "        :return: graph1 and graph2 populated with node features\n",
    "        :rtype: tuple of networkX graphs\n",
    "        \"\"\"\n",
    "\n",
    "        # Protein-1\n",
    "        vars_to_keep = [x for x in x_net_surf_1.columns if x not in [\n",
    "            'id', 'seq', 'n', 'q3', 'q8']]\n",
    "        netsurf_features_p1 = x_net_surf_1.loc[:, vars_to_keep]\n",
    "\n",
    "\n",
    "        # Protein-2\n",
    "        vars_to_keep = [x for x in x_net_surf_2.columns if x not in [\n",
    "            'id', 'seq', 'n', 'q3', 'q8']]\n",
    "        netsurf_features_p1 = x_net_surf_2.loc[:, vars_to_keep]\n",
    "\n",
    "        # Populate node features before making Union on graphs\n",
    "        G_1_features = {}\n",
    "        for i, node in enumerate(graph_1.nodes):\n",
    "            feature_array = {'x': netsurf_features_p1.iloc[i, :].values}\n",
    "            G_1_features[node] = feature_array\n",
    "\n",
    "\n",
    "        G_2_features = {}\n",
    "        for i, node in enumerate(graph_2.nodes):\n",
    "            feature_array = {'x': netsurf_features_p1.iloc[i, :].values}\n",
    "            G_2_features[node] = feature_array\n",
    "\n",
    "        # Set the node attributes\n",
    "        nx.set_node_attributes(graph_1, G_1_features)\n",
    "        nx.set_node_attributes(graph_2, G_2_features)\n",
    "        return graph_1, graph_2\n",
    "        \n",
    "def link_graphs(graph_1, graph_2, bridges,show=False):\n",
    "        \"\"\"Linkes the two protein graphs on their top 'n' DCA connections (bridges)\n",
    "        :param graph_1: graph for protein 1\n",
    "        :type graph_1: networkX graph object\n",
    "        :param graph_2: graph for protein 2\n",
    "        :type graph_2: networkX graph object\n",
    "        :param bridges: dca connections\n",
    "        :type bridges: list\n",
    "        :param msa_coder_1: msa-seq coder for protein 1\n",
    "        :type msa_coder_1: dict\n",
    "        :param msa_coder_2: sa-seq coder for protein 2\n",
    "        :type msa_coder_2: dict\n",
    "        :param show: to plot graphs, defaults to False\n",
    "        :type show: bool, optional\n",
    "        :return: Union of the two protein graphs    \n",
    "        :rtype: networkX graph object\n",
    "        \"\"\"\n",
    "\n",
    "        # Connect the graphs together - use map-encoder for -b\n",
    "        U = nx.union(graph_1, graph_2, rename=('a-', 'b-'))\n",
    "\n",
    "        for (b1, b2) in bridges:\n",
    "            try:\n",
    "                U.add_edge('a-' + str(b1),\n",
    "                           'b-' + str(b2),\n",
    "                           color='red')\n",
    "            except Exception as e:\n",
    "                print(\"something went wrong during graph-linking.\")\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        # Colour the DCA edges\n",
    "        edge_color_list = []\n",
    "        for (e1, e2) in U.edges:\n",
    "            if e1[0] != e2[0]:\n",
    "                edge_color_list.append('red')\n",
    "            else:\n",
    "                edge_color_list.append('black')\n",
    "\n",
    "        node_color_list = []\n",
    "        for node in U.nodes:\n",
    "            if node[0] == 'a':\n",
    "                node_color_list.append('blue')\n",
    "            else:\n",
    "                node_color_list.append('green')\n",
    "\n",
    "        if show:\n",
    "            f, ax = plt.subplots(figsize=(12, 12))\n",
    "            nx.draw(U, edge_color=edge_color_list,\n",
    "                    node_color=node_color_list, node_size=10, width=0.2)\n",
    "            plt.show()\n",
    "        return U\n",
    "        \n",
    "def collect_data(x):\n",
    "    \"\"\"Call as a lambda function on each row of a pandas data frame.\n",
    "       Remeber to instantaite D = {} as as a global var in the main script.\n",
    "\n",
    "    :param x: each row of a pandas.core.DataFrame\n",
    "    :type x: list\n",
    "    \"\"\"\n",
    "\n",
    "    # Feature lists\n",
    "    dca_score = []\n",
    "    pos_1 = []\n",
    "    pos_2 = []\n",
    "    \n",
    "    # Ref global dict\n",
    "    global D\n",
    "\n",
    "    # Grab name\n",
    "    name_1 = x[0]\n",
    "    name_2 = x[1]\n",
    "    combined_name = \"and\".join([name_1, name_2])\n",
    "    \n",
    "    # Extract dca scores and positions\n",
    "    for i in range(2, len(x), 3):\n",
    "        dca_score.append(x[i])\n",
    "        pos_1.append(x[i+1])\n",
    "        pos_2.append(x[i+2])\n",
    "\n",
    "    if combined_name not in D.values():\n",
    "        # Add the data to the named entry\n",
    "        D[combined_name] = {'dca': dca_score, 'pos_1': pos_1, 'pos_2': pos_2}\n",
    "\n",
    "        # Reset the feature lists\n",
    "        dca_score = []\n",
    "        pos_1 = []\n",
    "        pos_2 = []\n",
    "\n",
    "def extract_data(df):\n",
    "    \"\"\"Modifies a globally defined dictionary with protein names,\n",
    "       DCA values, and residue positions \n",
    "\n",
    "    :param df: Tao's new data from: 'fixedNegVSposRratio_WithPhylaintegration_InSubjectOriPos_listDict_allPPs.csv'\n",
    "    :type df: pandas.core.DataFrame\n",
    "    :return: There is not return type. Global D (dict) will be modified.\n",
    "    :rtype: None\n",
    "    \"\"\"\n",
    "    _ = df.apply(lambda x : collect_data(x), axis=1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to new data\n",
    "root= '/mnt/mnemo6/tao/PPI_Coevolution/CoEvo_data_STRING11.5/511145_EggNOGmaxLevel1224_eggNOGfilteredData/STRINGPhyBalancePhyla_Benchmark/' \n",
    "meta = 'fixedNegVSposRratio_metadata.csv'\n",
    "phyla = 'fixedNegVSposRratio_WithPhylaintegration_InSubjectOriPos_listDict_allPPs.csv'\n",
    "no_phyla = 'fixedNegVSposRratio_WithoutPhylaintegration_InSubjectOriPos_listDict_allPPs.csv'\n",
    "\n",
    "\n",
    "# Annotation file\n",
    "anndata_path = ('/mnt/mnemo6/tao/PPI_Coevolution/CoEvo_data_STRING11.5/'\n",
    "                '511145_EggNOGmaxLevel1224_eggNOGfilteredData/STRINPhyPPI_Benchmark/allPPI_allInfo_frame.csv')\n",
    "# Netsurf data\n",
    "netsurf_path = \"/mnt/mnemo6/tao/PPI_Coevolution/STRING_data_11.5/511145_netsurfp2_output/\"\n",
    "\n",
    "# ALPHA-Fold paths\n",
    "string_to_af = \"/mnt/mnemo6/damian/STRING_derived_v11.5/alphafold/mapping/83333.511145.tsv\"\n",
    "string_to_pdb = '/mnt/mnemo6/damian/STRING_derived_v11.5/pdb/pdb2string.blastp.best_score.tsv'\n",
    "pdb_files_for_PDB = '/mnt/mnemo6/damian/STRING_freeze_v11.5/pdb/data/biounit/coordinates/divided/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "new_data = pd.read_csv(os.path.join(root, no_phyla), sep='\\t', header=None)\n",
    "phyla_data = pd.read_csv(os.path.join(root, phyla), sep='\\t', header=None)\n",
    "meta_data = pd.read_csv(os.path.join(root, meta), sep='\\t', header=0)\n",
    "\n",
    "# Netsurf outputs\n",
    "netsurf = glob.glob(os.path.join(netsurf_path, \"*.csv\"))\n",
    "netsurf.sort()\n",
    "\n",
    "# Generate map between protein names and netsurfp file paths\n",
    "seq_names = [x.split(\"/\")[-1].replace(\".csv\", \"\") for x in netsurf]\n",
    "netsurf_d = dict(zip(seq_names, netsurf))\n",
    "\n",
    "# Load meta\n",
    "meta_data = pd.read_csv(os.path.join(root, meta), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 2 graphs from single obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do for 1 example only!\n",
    "GM = GraphMaker(anndata_path=os.path.join(root, meta))\n",
    "\n",
    "n_dca = 20\n",
    "obs =  GM.anndata.iloc[0, :]\n",
    "\n",
    "# Get names\n",
    "protein_1 = obs['STRING_ID1']\n",
    "protein_2 = obs['STRING_ID2']\n",
    "\n",
    "# Get protein lengths\n",
    "protein_1_len = obs['len1']\n",
    "protein_2_len = obs['len2']\n",
    "\n",
    "# Get residue objects from alpha-fold\n",
    "res_1, res_2 = GM.generate_alpha_fold_structures(string_to_af=string_to_af, pair_1=protein_1, pair_2=protein_2)\n",
    "\n",
    "# Get distance matrix\n",
    "dm_1 = GM.calculate_dist_matrix(seq_1=res_1, seq_2=res_1)\n",
    "dm_2 = GM.calculate_dist_matrix(seq_1=res_2, seq_2=res_2)\n",
    "\n",
    "# Get proximty matrix\n",
    "pm_1 = GM.generate_proximity_matrix(seq_1=res_1, seq_2=res_1)\n",
    "pm_2 = GM.generate_proximity_matrix(seq_1=res_2, seq_2=res_2)\n",
    "\n",
    "# Geneate single graphs\n",
    "G_1, G_2 = GM.generate_graphs(adjacency_matrix_1=pm_1, adjacency_matrix_2=pm_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformat Taos data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variable D and populate with key information\n",
    "D = {}\n",
    "_ = extract_data(new_data)\n",
    "\n",
    "# Explore some values for  a single\n",
    "pp1 = D[\"and\".join([protein_1, protein_2])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 20 dca stats, if none available set to zero\n",
    "pos_1 = pp1['pos_1']\n",
    "pos_2 = pp1['pos_2']\n",
    "\n",
    "dca = pp1['dca']\n",
    "bridges = list(zip(pos_1, pos_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{21: 7.3076, 5: 1.6527, 28: 1.5302, 56: 1.4725, 29: 1.4675, 35: 1.4628, 30: 1.4225, 43: 1.4054, 33: 1.3803, 13: 1.2834, 34: 1.2774, 22: 1.1718, 18: 1.1529, 16: 1.1315, 24: 1.0893, 46: 1.0786}\n"
     ]
    }
   ],
   "source": [
    "dd = {}\n",
    "l = list(zip(pos_1, dca))\n",
    "\n",
    "for pos, score in l:    \n",
    "    if pos not in dd.keys():\n",
    "        dd[pos]=[score]\n",
    "    else:\n",
    "        dd[pos].append(score)\n",
    "\n",
    "# Take the max value\n",
    "for k, v in dd.items():\n",
    "    dd[k] = max(v)\n",
    "print(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get netsurfp features for protein 1\n",
    "p1 = netsurf_d[protein_1]\n",
    "x_net_surf_1 = pd.read_csv(p1)\n",
    "\n",
    "# Get netsurfp features for protein 2\n",
    "p2 = netsurf_d[protein_2]\n",
    "x_net_surf_2 = pd.read_csv(p2)\n",
    "\n",
    "# Popualte node features and make graph union \n",
    "G_1, G_2 = populate_graph_features(G_1, G_2 , x_net_surf_1, x_net_surf_2)\n",
    "U = link_graphs(G_1, G_2, bridges, show=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.3076,\n",
       " 1.6527,\n",
       " 1.5302,\n",
       " 1.4725,\n",
       " 1.4675,\n",
       " 1.4628,\n",
       " 1.4225,\n",
       " 1.4054,\n",
       " 1.3803,\n",
       " 1.3528,\n",
       " 1.2834,\n",
       " 1.2774,\n",
       " 1.2206,\n",
       " 1.1718,\n",
       " 1.1529,\n",
       " 1.1412,\n",
       " 1.1315,\n",
       " 1.0893,\n",
       " 1.0803,\n",
       " 1.0786]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize dca values\n",
    "ss = MinMaxScaler()\n",
    "dca = np.array(dca)\n",
    "dca_scaled = ss.fit_transform(dca.reshape(-1, 1))\n",
    "dca_final = dca_scaled.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_1</th>\n",
       "      <th>pos_2</th>\n",
       "      <th>dca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>83</td>\n",
       "      <td>0.092166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>0.072500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>76</td>\n",
       "      <td>0.063236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>0.062434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>89</td>\n",
       "      <td>0.061679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>89</td>\n",
       "      <td>0.055210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>43</td>\n",
       "      <td>79</td>\n",
       "      <td>0.052464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>0.048435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.044020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "      <td>0.032878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>34</td>\n",
       "      <td>93</td>\n",
       "      <td>0.031915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>0.022797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22</td>\n",
       "      <td>69</td>\n",
       "      <td>0.014962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0.011928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>0.010050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>79</td>\n",
       "      <td>0.008493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pos_1  pos_2       dca\n",
       "0      21      8  1.000000\n",
       "1       5     83  0.092166\n",
       "2      28     11  0.072500\n",
       "3      56     76  0.063236\n",
       "4      29     16  0.062434\n",
       "5      35     89  0.061679\n",
       "6      30     89  0.055210\n",
       "7      43     79  0.052464\n",
       "8      33     13  0.048435\n",
       "9      21      4  0.044020\n",
       "10     13     86  0.032878\n",
       "11     34     93  0.031915\n",
       "12     34     50  0.022797\n",
       "13     22     69  0.014962\n",
       "14     18      4  0.011928\n",
       "15     21      7  0.010050\n",
       "16     16     79  0.008493\n",
       "17     24      8  0.001718\n",
       "18     28     54  0.000273\n",
       "19     46     45  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a-5', 'b-83') 0.09216567667362335\n",
      "('a-13', 'b-86') 0.03287847166479371\n",
      "('a-16', 'b-79') 0.008492534917322186\n",
      "('a-18', 'b-4') 0.011928078343233256\n",
      "('a-21', 'b-8') 1.0\n",
      "('a-21', 'b-4') 0.0440199068871408\n",
      "('a-21', 'b-7') 0.010049767217851974\n",
      "('a-22', 'b-69') 0.014962273238079943\n",
      "('a-24', 'b-8') 0.001717771712955507\n",
      "('a-28', 'b-11') 0.07249959865146893\n",
      "('a-28', 'b-54') 0.00027291700112377915\n",
      "('a-29', 'b-16') 0.06243377749237439\n",
      "('a-30', 'b-89') 0.05520950393321561\n",
      "('a-33', 'b-13') 0.04843474072884893\n",
      "('a-34', 'b-93') 0.03191523519023923\n",
      "('a-34', 'b-50') 0.022796596564456567\n",
      "('a-35', 'b-89') 0.061679242253973365\n",
      "('a-43', 'b-79') 0.05246427998073527\n",
      "('a-46', 'b-45') 0.0\n",
      "('a-56', 'b-76') 0.06323647455450312\n"
     ]
    }
   ],
   "source": [
    "INSPECT = True\n",
    "\n",
    "# Normalize dca values\n",
    "ss = MinMaxScaler()\n",
    "dca = np.array(dca)\n",
    "dca_scaled = ss.fit_transform(dca.reshape(-1, 1))\n",
    "dca_scaled\n",
    "\n",
    "# make data into a dataframe\n",
    "df = pd.DataFrame({'pos_1': pos_1, 'pos_2': pos_2, 'dca': dca_final})\n",
    "display(df)\n",
    "\n",
    "for edge in U.edges:\n",
    "    if ('a' in edge[0]) and ('b' in edge[1]):\n",
    "\n",
    "        # Pull out the edges with DCA connection (max DCA)\n",
    "        e_1 = int(edge[0].split('-')[-1])\n",
    "        e_2 = int(edge[1].split('-')[-1])\n",
    "\n",
    "        # Extract and join on the DCA scores\n",
    "        dca_score = df[(df['pos_1']==e_1) & (df['pos_2']==e_2)]['dca'].values\n",
    "\n",
    "        # Set dca edge type to max dca score\n",
    "        attrs = {(edge[0], edge[1]): {\"dca\": float(dca_score)}}\n",
    "        nx.set_edge_attributes(U, attrs)  \n",
    "        \n",
    "        # Set peptide edge type to zero\n",
    "        attrs = {(edge[0], edge[1]): {\"peptide\": 0.0}}\n",
    "        nx.set_edge_attributes(U, attrs)   \n",
    "\n",
    "        # Inspect changed edges\n",
    "        if INSPECT:\n",
    "            print(edge, nx.get_edge_attributes(U, 'dca')[(edge[0], edge[1])])      \n",
    "        \n",
    "    else:\n",
    "        # Set dca edge type to 0\n",
    "        attrs = {(edge[0], edge[1]): {\"dca\": 0.0}}\n",
    "        nx.set_edge_attributes(U, attrs)   \n",
    "\n",
    "        # Set peptides edge type to 1\n",
    "        attrs = {(edge[0], edge[1]): {\"peptide\": 1.0}}\n",
    "        nx.set_edge_attributes(U, attrs)        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a-5', 'b-83') 0.0\n",
      "('a-13', 'b-86') 0.0\n",
      "('a-16', 'b-79') 0.0\n",
      "('a-18', 'b-4') 0.0\n",
      "('a-21', 'b-8') 0.0\n",
      "('a-21', 'b-4') 0.0\n",
      "('a-21', 'b-7') 0.0\n",
      "('a-22', 'b-69') 0.0\n",
      "('a-24', 'b-8') 0.0\n",
      "('a-28', 'b-11') 0.0\n",
      "('a-28', 'b-54') 0.0\n",
      "('a-29', 'b-16') 0.0\n",
      "('a-30', 'b-89') 0.0\n",
      "('a-33', 'b-13') 0.0\n",
      "('a-34', 'b-93') 0.0\n",
      "('a-34', 'b-50') 0.0\n",
      "('a-35', 'b-89') 0.0\n",
      "('a-43', 'b-79') 0.0\n",
      "('a-46', 'b-45') 0.0\n",
      "('a-56', 'b-76') 0.0\n"
     ]
    }
   ],
   "source": [
    "for edge in U.edges:\n",
    "    if ('a' in edge[0]) and ('b' in edge[1]):\n",
    "        print(edge, nx.get_edge_attributes(U, 'peptide')[(edge[0], edge[1])])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91480398e29c201d85f830141776dbac7675dbf1ea4e71a85e6e607707f70528"
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
