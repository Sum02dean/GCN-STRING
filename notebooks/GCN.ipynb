{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import networkx as nx\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in label by name\n",
    "def get_label(file, labels):\n",
    "    pair_1 = file.split('/')[-1]\n",
    "    pair_1, pair_2 = pair_1.split(\"and\")\n",
    "    pair_1 = pair_1.replace(\".gpickle\", \"\")\n",
    "    pair_2 = pair_2.replace(\".gpickle\", \"\")\n",
    "    l = int(labels.loc[(labels.protein_1 == pair_1)& (labels.protein_2 == pair_2)].label)\n",
    "    return file, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        download_url(url, self.raw_dir)\n",
    "        ...\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = [...]\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "graph_dir_path = '/home/cluster/dsumne/data/geometric/graph_data'\n",
    "labels_dir_path = '/home/cluster/dsumne/data/geometric/graph_labels'\n",
    "\n",
    "graph_files = glob.glob(os.path.join(graph_dir_path, '*'))\n",
    "graph_labels = glob.glob(os.path.join(labels_dir_path, '*'))\n",
    "graph_labels = pd.read_csv(graph_labels[0])\n",
    "\n",
    "# Create positive and negative sets\n",
    "positives = []\n",
    "pos_labels = []\n",
    "\n",
    "negatives = []\n",
    "neg_labels = []\n",
    "\n",
    "for i, file in enumerate(graph_files):\n",
    "    obs, label = get_label(file,labels)\n",
    "    \n",
    "    if label == 1:\n",
    "        positives.append(obs)\n",
    "        pos_labels.append([1,0])\n",
    "    else:\n",
    "        negatives.append(obs)\n",
    "        neg_labels.append([0,1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
