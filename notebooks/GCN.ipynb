{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import networkx as nx\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in label by name\n",
    "def get_label(file, labels):\n",
    "    pair_1 = file.split('/')[-1]\n",
    "    pair_1, pair_2 = pair_1.split(\"and\")\n",
    "    pair_1 = pair_1.replace(\".gpickle\", \"\")\n",
    "    pair_2 = pair_2.replace(\".gpickle\", \"\")\n",
    "    l = int(labels.loc[(labels.protein_1 == pair_1)& (labels.protein_2 == pair_2)].label)\n",
    "    return file, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        download_url(url, self.raw_dir)\n",
    "        ...\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = [...]\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "graph_dir_path = '/home/cluster/dsumne/data/geometric/graph_data'\n",
    "labels_dir_path = '/home/cluster/dsumne/data/geometric/graph_labels'\n",
    "\n",
    "graph_files = glob.glob(os.path.join(graph_dir_path, '*'))\n",
    "graph_labels = glob.glob(os.path.join(labels_dir_path, '*'))\n",
    "graph_labels = pd.read_csv(graph_labels[0])\n",
    "\n",
    "# Create positive and negative sets\n",
    "positives = []\n",
    "pos_labels = []\n",
    "\n",
    "negatives = []\n",
    "neg_labels = []\n",
    "\n",
    "for i, file in enumerate(graph_files):\n",
    "    obs, label = get_label(file,labels)\n",
    "    \n",
    "    if label == 1:\n",
    "        positives.append(obs)\n",
    "        pos_labels.append([1,0])\n",
    "    else:\n",
    "        negatives.append(obs)\n",
    "        neg_labels.append([0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5456\n",
      "5456\n"
     ]
    }
   ],
   "source": [
    "# Create positive and negative sets\n",
    "positives = []\n",
    "pos_labels = []\n",
    "\n",
    "negatives = []\n",
    "neg_labels = []\n",
    "\n",
    "for i, file in enumerate(graph_files):\n",
    "    obs, label = get_label(file,labels)\n",
    "    \n",
    "    if label == 1:\n",
    "        positives.append(obs)\n",
    "        pos_labels.append([1,0])\n",
    "    else:\n",
    "        negatives.append(obs)\n",
    "        neg_labels.append([0,1])\n",
    "        \n",
    "print(len(pos_labels))\n",
    "print(len(positives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance negative examples to len of positive examples\n",
    "import random\n",
    "negatives_sample = random.sample(negatives, len(positives))\n",
    "neg_labels_sample = random.sample(neg_labels, len(positives))\n",
    "\n",
    "# Combine files and labels into single lists\n",
    "files = positives + negatives_sample\n",
    "class_labels = pos_labels + neg_labels_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in a single graph example and examine all names\n",
    "G = nx.read_gpickle(positives[0])\n",
    "d = np.array([np.array(list(x[1].values())) for x in G.nodes.data()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MyDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/net/cephfs/data/dsumne/tmp/4929432/ipykernel_3617723/3570337153.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instantaite bi-molecular graph dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'MyDataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantaite bi-molecular graph dataset\n",
    "dataset = MyDataset(n_samples=len(files), files=files, class_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/net/cephfs/data/dsumne/tmp/4929432/ipykernel_3617723/3595443388.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check that the dataset labels are balanced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Check that the dataset labels are balanced\n",
    "plt.hist([x.y[0] for x in dataset])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(x_files):\n",
    "    G = nx.read_gpickle(file)\n",
    "    G_labels = labels.iloc[i].label\n",
    "    m = nx.to_scipy_sparse_matrix(G, format='coo')\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantaite bi-molecular graph dataset\n",
    "dataset = MyDataset(n_samples=len(files), files=files, class_labels=class_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
